--------------------0.py
#!/usr/bin/env python3


import os
import sys
import gc
import hashlib
import marshal

#gc.set_debug(gc.DEBUG_LEAK)


def check_ver():
    vi = sys.version_info

    if vi.major >= 3 and vi.minor >= 8:
        return

    for x in ('/root/python/bin:/Users/pg/18/bin:' + os.environ.get('PATH', '/bin:/usr/bin:/usr/local/bin')).split(':'):
        for v in ('3.8', '3.9', '3.10'):
            path = x + '/python' + v

            if os.path.isfile(path):
                os.execvp(path, [path] + sys.argv)

    raise Exception('we need python 3.8')


check_ver()


def find_me(g):
    for f in (lambda: __file__, lambda: sys.argv[0], lambda: os.path.abspath(os.getcwd()) + '/cli'):
        p = os.path.abspath(f())

        if os.path.isfile(p):
            return p

    raise Exception('can not find myself')


class Globals(dict):
    def __init__(self, cache):
        self.__dict__ = self
        self.cache = cache
        self.md5 = hashlib.md5
        self.dumps = marshal.dumps
        self.do_compile = compile
        self.hit = 0
        self.miss = 0
        
    def key(self, data):
        return self.md5(self.dumps(data)).hexdigest()
        
    def compile(self, a, b, c):
        key = self.key([a, b, c])

        if key not in self.cache:
            self.miss += 1
            self.cache[key] = self.do_compile(a, b, c)
        else:
            self.hit += 1
            
        return self.cache[key]
        

def real_main():
    file_data = None
    #REPLACEME

    if file_data:
        g = Globals(fd['compile_cache'])
    else:
        g = Globals({})

    g.script_path = find_me(g)
    g.script_dir = os.path.dirname(g.script_path)
    g.file_data = file_data
    
    if g.file_data:
        data = dict((x['name'], x) for x in g.file_data)['ut/stagea.py']['data']
    else:
        with open(g.script_dir + '/ut/stagea.py') as f:
            data = f.read()

    ctx = {'_globals': g}
    exec(compile(data +'\nmain(_globals)\n', '__main__', 'exec'), ctx)
    ctx.clear()


if __name__ == '__main__':
    real_main()

+++++++++++++++++++
#!/usr/bin/env python3


import os
import sys
import gc
import hashlib
import marshal

#gc.set_debug(gc.DEBUG_LEAK)


def check_ver():
    vi = sys.version_info

    if vi.major >= 3 and vi.minor >= 8:
        return

    for x in ('/root/python/bin:/Users/pg/18/bin:' + os.environ.get('PATH', '/bin:/usr/bin:/usr/local/bin')).split(':'):
        for v in ('3.8', '3.9', '3.10'):
            path = x + '/python' + v

            if os.path.isfile(path):
                os.execvp(path, [path] + sys.argv)

    raise Exception('we need python 3.8')


check_ver()


def find_me(g):
    for f in (lambda: __file__, lambda: sys.argv[0], lambda: os.path.abspath(os.getcwd()) + '/cli'):
        p = os.path.abspath(f())

        if os.path.isfile(p):
            return p

    raise Exception('can not find myself')


class Globals(dict):
    def __init__(self, cache):
        self.__dict__ = self
        self.cache = cache
        self.md5 = hashlib.md5
        self.dumps = marshal.dumps
        self.do_compile = compile
        self.hit = 0
        self.miss = 0
        
    def key(self, data):
        return self.md5(self.dumps(data)).hexdigest()
        
    def compile(self, a, b, c):
        key = self.key([a, b, c])

        if key not in self.cache:
            self.miss += 1
            self.cache[key] = self.do_compile(a, b, c)
        else:
            self.hit += 1
            
        return self.cache[key]
        

def real_main():
    file_data = None
    #REPLACEME

    if file_data:
        g = Globals(fd['compile_cache'])
    else:
        g = Globals({})

    g.script_path = find_me(g)
    g.script_dir = os.path.dirname(g.script_path)
    g.file_data = file_data
    
    if g.file_data:
        data = dict((x['name'], x) for x in g.file_data)['ut/stagea.py']['data']
    else:
        with open(g.script_dir + '/ut/stagea.py') as f:
            data = f.read()

    ctx = {'_globals': g}
    exec(compile(data +'\nmain(_globals)\n', '__main__', 'exec'), ctx)
    ctx.clear()


if __name__ == '__main__':
    real_main()

--------------------0/ut/mod_load.py
import sys
import random


class Mod(dict):
   def __init__(self, name, loader):
      self.__dict__ = self
      self.__yid__ = str(int(random.random() * 1000000000))
      self.__name__ = name
      self.__loader__ = loader
      self.__file__ = self.__name__
      self.__pkg__ = None
      self.__ytext__ = ''
      self.__ylineco__ = 0
      self.__ycode__ = []
      self.__yexec__ = self.exec_data
      self.__last_reindex__ = 0
      self.__sub__ = {}
  
      def get_log():
         log = self.y.logging.getLogger(self.__name__)

         self.__ylog__ = lambda: log

         return self.__ylog__()
 
      self.__ylog__ = get_log
  
      try:
         self.y = loader.get_y()
      except Exception:
         pass

      self.__loader__.register_module(self)
      self.exec_text_part(self.builtin_data())

   def ycompile(self, a, b, c, **kwargs):
      print('--------------------' + b + '\n' + a)
      ap = self.__loader__._preproc(a)
      print('+++++++++++++++++++\n' + ap)
      
      return self.__loader__._g.compile('\n' * kwargs.get('firstlineno', 0) + ap, b, c)

   def vname(self):
      return self.__name__[len(self.__loader__.root_module().__name__) + 1:]
  
   def create_sub_module(self, name):
      if (pos := name.find('.')) > 0:
         return self.create_sub_module_0(name[:pos]).create_sub_module(name[pos + 1:])

      return self.create_sub_module_0(name)

   def create_sub_module_0(self, name):
      if name not in self.__sub__:
         self.__sub__[name] = Mod(self.full_name(name), self.__loader__)

      return self.__sub__[name]
  
   def self_exec(self):
      self.exec_text_part(self.pop('__ynext_part__', ''))

   def exec_data(self, data, **kwargs):
      return self.__loader__.exec_code(self, data, **kwargs)

   def set_next_part(self, text):
      if text:
         self.__ynext_part__ = text 

   def exec_text_part(self, part):
      if not part.strip():
         return 

      code = self.ycompile(part, self.__file__.replace('.', '/') + '.py', 'exec', firstlineno=self.line_count())
  
      exec(code, self.__dict__)

      if self.__ytext__:
         self.__ytext__ += '\n'

      self.__ytext__ += part
      self.__ytext__ += '\n'
      self.__ylineco__ = self.__ytext__.count('\n')
      self.__ycode__.append(code)

      self.reindex()

   def reindex(self):
      lc = self.line_count()

      if 2 * self.__last_reindex__ < lc:
         try:
            func = self.y.reindex_module
         except Exception:
            func = None

         if func:
            func(self)

         self.__last_reindex__ = lc

   def line_count(self):
      return self.__ylineco__

   def text(self):
      return self.__ytext__

   def line_count_part(self, text):
      return text.count('\n')

   def builtin_data(self):
      return self.__loader__.builtin_data(self)

   def full_name(self, sub):
      return self.__name__ + '.' + sub
   

class Loader(object):
   def __init__(self, name, g, preproc=lambda x: x):
      self.__name__ = name
      self._by_name = {}
      self._builtin = g.builtin_modules
      self._order = []
      self._g = g
      self._preproc = preproc
  
      Mod(name, self)
  
   def root_module(self):
      return self._by_name[self._order[0]]
  
   def create_module(self, name):
      fname = self.root_module().full_name(name)
  
      if fname in self._by_name:
         return self._by_name[fname]

      return self.root_module().create_sub_module(name)

   def register_module(self, mod):
      mn = mod.__name__

      assert mn not in self._by_name
  
      self._order.append(mn)
      self._by_name[mn] = mod
  
      return mod
   
   def builtin_data(self, mod):
      return self._builtin.get(mod.vname(), {}).get('data', '')

   def exec_code(self, mod, data, module_name=None, arch={}, **kwargs):
      if arch:
         module_name = arch['os'] + '_' + arch['arch'] + '.' + module_name
         data = '#define __OS__ "' + arch['os'].upper() + '"\n\n' + data
         data = '#define __ARCH__ "' + arch['arch'].upper() + '"\n' + data
         data = '#define __' + arch['arch'].upper() + '__ 1\n' + data
         data = '#define __' + arch['os'].upper() + '__ 1\n' + data
         
      if module_name:
         m = self.create_module(module_name)

         if data != m.builtin_data():
            m.exec_text_part(data)

         return m

      mod.exec_text_part(data)

      return mod

   def find_sub_module(self, name):
      return self._by_name[self.root_module().full_name(name)]
   
   def get_y(self):
      return self.find_sub_module('ut.iface').y

   def get_source(self, name):
      return self._by_name[name].text()
  
   def iter_modules(self):
      for k in self._order:
         yield self._by_name[k]


def bootstrap(g):
    loader = Loader('1', g)

    loader.create_module('ut.iface')
    loader.create_module('ut.args_parse')
    loader.create_module('ut.mod_load')
    __loader__.__dict__.clear()
    loader.create_module('ut.stage2').run_stage2(g)

+++++++++++++++++++
import sys
import random


class Mod(dict):
   def __init__(self, name, loader):
      self.__dict__ = self
      self.__yid__ = str(int(random.random() * 1000000000))
      self.__name__ = name
      self.__loader__ = loader
      self.__file__ = self.__name__
      self.__pkg__ = None
      self.__ytext__ = ''
      self.__ylineco__ = 0
      self.__ycode__ = []
      self.__yexec__ = self.exec_data
      self.__last_reindex__ = 0
      self.__sub__ = {}
  
      def get_log():
         log = self.y.logging.getLogger(self.__name__)

         self.__ylog__ = lambda: log

         return self.__ylog__()
 
      self.__ylog__ = get_log
  
      try:
         self.y = loader.get_y()
      except Exception:
         pass

      self.__loader__.register_module(self)
      self.exec_text_part(self.builtin_data())

   def ycompile(self, a, b, c, **kwargs):
      print('--------------------' + b + '\n' + a)
      ap = self.__loader__._preproc(a)
      print('+++++++++++++++++++\n' + ap)
      
      return self.__loader__._g.compile('\n' * kwargs.get('firstlineno', 0) + ap, b, c)

   def vname(self):
      return self.__name__[len(self.__loader__.root_module().__name__) + 1:]
  
   def create_sub_module(self, name):
      if (pos := name.find('.')) > 0:
         return self.create_sub_module_0(name[:pos]).create_sub_module(name[pos + 1:])

      return self.create_sub_module_0(name)

   def create_sub_module_0(self, name):
      if name not in self.__sub__:
         self.__sub__[name] = Mod(self.full_name(name), self.__loader__)

      return self.__sub__[name]
  
   def self_exec(self):
      self.exec_text_part(self.pop('__ynext_part__', ''))

   def exec_data(self, data, **kwargs):
      return self.__loader__.exec_code(self, data, **kwargs)

   def set_next_part(self, text):
      if text:
         self.__ynext_part__ = text 

   def exec_text_part(self, part):
      if not part.strip():
         return 

      code = self.ycompile(part, self.__file__.replace('.', '/') + '.py', 'exec', firstlineno=self.line_count())
  
      exec(code, self.__dict__)

      if self.__ytext__:
         self.__ytext__ += '\n'

      self.__ytext__ += part
      self.__ytext__ += '\n'
      self.__ylineco__ = self.__ytext__.count('\n')
      self.__ycode__.append(code)

      self.reindex()

   def reindex(self):
      lc = self.line_count()

      if 2 * self.__last_reindex__ < lc:
         try:
            func = self.y.reindex_module
         except Exception:
            func = None

         if func:
            func(self)

         self.__last_reindex__ = lc

   def line_count(self):
      return self.__ylineco__

   def text(self):
      return self.__ytext__

   def line_count_part(self, text):
      return text.count('\n')

   def builtin_data(self):
      return self.__loader__.builtin_data(self)

   def full_name(self, sub):
      return self.__name__ + '.' + sub
   

class Loader(object):
   def __init__(self, name, g, preproc=lambda x: x):
      self.__name__ = name
      self._by_name = {}
      self._builtin = g.builtin_modules
      self._order = []
      self._g = g
      self._preproc = preproc
  
      Mod(name, self)
  
   def root_module(self):
      return self._by_name[self._order[0]]
  
   def create_module(self, name):
      fname = self.root_module().full_name(name)
  
      if fname in self._by_name:
         return self._by_name[fname]

      return self.root_module().create_sub_module(name)

   def register_module(self, mod):
      mn = mod.__name__

      assert mn not in self._by_name
  
      self._order.append(mn)
      self._by_name[mn] = mod
  
      return mod
   
   def builtin_data(self, mod):
      return self._builtin.get(mod.vname(), {}).get('data', '')

   def exec_code(self, mod, data, module_name=None, arch={}, **kwargs):
      if arch:
         module_name = arch['os'] + '_' + arch['arch'] + '.' + module_name
         data = '#define __OS__ "' + arch['os'].upper() + '"\n\n' + data
         data = '#define __ARCH__ "' + arch['arch'].upper() + '"\n' + data
         data = '#define __' + arch['arch'].upper() + '__ 1\n' + data
         data = '#define __' + arch['os'].upper() + '__ 1\n' + data
         
      if module_name:
         m = self.create_module(module_name)

         if data != m.builtin_data():
            m.exec_text_part(data)

         return m

      mod.exec_text_part(data)

      return mod

   def find_sub_module(self, name):
      return self._by_name[self.root_module().full_name(name)]
   
   def get_y(self):
      return self.find_sub_module('ut.iface').y

   def get_source(self, name):
      return self._by_name[name].text()
  
   def iter_modules(self):
      for k in self._order:
         yield self._by_name[k]


def bootstrap(g):
    loader = Loader('1', g)

    loader.create_module('ut.iface')
    loader.create_module('ut.args_parse')
    loader.create_module('ut.mod_load')
    __loader__.__dict__.clear()
    loader.create_module('ut.stage2').run_stage2(g)

--------------------1.py
#!/usr/bin/env python3


import os
import sys
import gc
import hashlib
import marshal

#gc.set_debug(gc.DEBUG_LEAK)


def check_ver():
    vi = sys.version_info

    if vi.major >= 3 and vi.minor >= 8:
        return

    for x in ('/root/python/bin:/Users/pg/18/bin:' + os.environ.get('PATH', '/bin:/usr/bin:/usr/local/bin')).split(':'):
        for v in ('3.8', '3.9', '3.10'):
            path = x + '/python' + v

            if os.path.isfile(path):
                os.execvp(path, [path] + sys.argv)

    raise Exception('we need python 3.8')


check_ver()


def find_me(g):
    for f in (lambda: __file__, lambda: sys.argv[0], lambda: os.path.abspath(os.getcwd()) + '/cli'):
        p = os.path.abspath(f())

        if os.path.isfile(p):
            return p

    raise Exception('can not find myself')


class Globals(dict):
    def __init__(self, cache):
        self.__dict__ = self
        self.cache = cache
        self.md5 = hashlib.md5
        self.dumps = marshal.dumps
        self.do_compile = compile
        self.hit = 0
        self.miss = 0
        
    def key(self, data):
        return self.md5(self.dumps(data)).hexdigest()
        
    def compile(self, a, b, c):
        key = self.key([a, b, c])

        if key not in self.cache:
            self.miss += 1
            self.cache[key] = self.do_compile(a, b, c)
        else:
            self.hit += 1
            
        return self.cache[key]
        

def real_main():
    file_data = None
    #REPLACEME

    if file_data:
        g = Globals(fd['compile_cache'])
    else:
        g = Globals({})

    g.script_path = find_me(g)
    g.script_dir = os.path.dirname(g.script_path)
    g.file_data = file_data
    
    if g.file_data:
        data = dict((x['name'], x) for x in g.file_data)['ut/stagea.py']['data']
    else:
        with open(g.script_dir + '/ut/stagea.py') as f:
            data = f.read()

    ctx = {'_globals': g}
    exec(compile(data +'\nmain(_globals)\n', '__main__', 'exec'), ctx)
    ctx.clear()


if __name__ == '__main__':
    real_main()

+++++++++++++++++++
#!/usr/bin/env python3


import os
import sys
import gc
import hashlib
import marshal

#gc.set_debug(gc.DEBUG_LEAK)


def check_ver():
    vi = sys.version_info

    if vi.major >= 3 and vi.minor >= 8:
        return

    for x in ('/root/python/bin:/Users/pg/18/bin:' + os.environ.get('PATH', '/bin:/usr/bin:/usr/local/bin')).split(':'):
        for v in ('3.8', '3.9', '3.10'):
            path = x + '/python' + v

            if os.path.isfile(path):
                os.execvp(path, [path] + sys.argv)

    raise Exception('we need python 3.8')


check_ver()


def find_me(g):
    for f in (lambda: __file__, lambda: sys.argv[0], lambda: os.path.abspath(os.getcwd()) + '/cli'):
        p = os.path.abspath(f())

        if os.path.isfile(p):
            return p

    raise Exception('can not find myself')


class Globals(dict):
    def __init__(self, cache):
        self.__dict__ = self
        self.cache = cache
        self.md5 = hashlib.md5
        self.dumps = marshal.dumps
        self.do_compile = compile
        self.hit = 0
        self.miss = 0
        
    def key(self, data):
        return self.md5(self.dumps(data)).hexdigest()
        
    def compile(self, a, b, c):
        key = self.key([a, b, c])

        if key not in self.cache:
            self.miss += 1
            self.cache[key] = self.do_compile(a, b, c)
        else:
            self.hit += 1
            
        return self.cache[key]
        

def real_main():
    file_data = None
    #REPLACEME

    if file_data:
        g = Globals(fd['compile_cache'])
    else:
        g = Globals({})

    g.script_path = find_me(g)
    g.script_dir = os.path.dirname(g.script_path)
    g.file_data = file_data
    
    if g.file_data:
        data = dict((x['name'], x) for x in g.file_data)['ut/stagea.py']['data']
    else:
        with open(g.script_dir + '/ut/stagea.py') as f:
            data = f.read()

    ctx = {'_globals': g}
    exec(compile(data +'\nmain(_globals)\n', '__main__', 'exec'), ctx)
    ctx.clear()


if __name__ == '__main__':
    real_main()

--------------------1/ut/iface.py
import sys
import imp
import inspect


class StopNow(Exception):
    pass


class IFaceSlave(dict):
    def __init__(self, mod, parent):
        self.__dict__ = self
        self._mod = mod
        self._pa = parent

    def __getattr__(self, name):
        key = self._mod.__name__ + '.' + name

        try:
            return self[key]
        except KeyError:
            self[key] = self.find(name)

        return self[key]

    def lst(self):
        return (self.find_module, self.find_function)

    def find(self, name):
        for f in self.lst():
            try:
                return f(name)
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def find_module(self, name):
        return self._pa.create_slave(self._mod.__sub__[name])

    def find_function(self, name):
        return self._mod[name]


class IFaceStd(IFaceSlave):
    def __init__(self, mod, parent):
        IFaceSlave.__init__(self, mod, parent)

    def import_from(self, name):
        ctx = dict()
        exec('from ' + self._mod.__name__ + ' import ' + name, ctx)
        return ctx[name]

    def find_module_1(self, name):
        return self._pa.create_std(__import__(self._mod.__name__ + '.' + name))

    def find_module_2(self, name):
        x = self.import_from(name)

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_module_3(self, name):
        x = self._mod.__dict__[name]

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_function_1(self, name):
        return self._mod.__dict__[name]

    def find_function_2(self, name):
        return self.import_from(name)

    def lst(self):
        return (self.find_module_2, self.find_module_1, self.find_module_3, self.find_function_1, self.find_function_2)


class IFace(dict):
    def __init__(self):
        self.__dict__ = self
        self._l = []
        self._a = {}
        self._cc = {}
        self._hit = 0
   
        self.add_lookup(self.fast_search)
        self.add_lookup(self.find_function)
        self.add_lookup(lambda x: self.find_module(x))
        self.add_lookup(lambda x: self.create_std(sys.modules[x]))
        self.add_lookup(lambda x: self.create_std(__import__(x)))

    def clear_cache(self):
        for k in list(self.keys()):
            if k.startswith('_'):
                continue

            self.pop(k)

    @property
    def stdout(self):
        return sys.stdout

    @property
    def stderr(self):
        return sys.stderr

    def spawn(self, coro, name=None, debug=True):
        return self.async_loop.spawn(coro, name=name, debug=debug)

    async def offload(self, job):
        return await self.async_loop.offload(job)
  
    def last_msg(self, t):
        e = sys.stderr
        o = sys.stdout

        sys.stderr = None
        sys.stdout = None

        o.flush()
        e.flush()

        e.write(t)
        e.flush()

    @property
    def copy(self):
        try:
            return sys.modules['copy']
        except KeyError:
            __import__('copy')

        return sys.modules['copy']

    def print_stats(self):
        for i, f in enumerate(self._l):
            y.xprint_w(i, self._cc[i])

        y.xprint_w('hit =', self._hit, 'miss =', len(self._c))

    def create_slave_0(self, mod, klass):
        key = 's:' + mod.__name__ + ':' + klass.__name__

        try:
            return self[key]
        except KeyError:
            self[key] = klass(mod, self)

        return self[key]

    def create_slave(self, mod):
        return self.create_slave_0(mod, IFaceSlave)

    def create_std(self, mod):
        return mod
        #return self.create_slave_0(mod, IFaceStd)

    def find_module(self, x):
        y = '.' + x

        for mod in __loader__.iter_modules():
            if mod.__name__.endswith(y):
                return self.create_slave(mod)

        raise AttributeError(x)

    def fast_search(self, name):
        return __loader__._by_name[self._a[name]][name]

    def reindex_module(self, mod):
        def do():
            for x in frozenset(dir(mod)) - frozenset(dir(mod.__class__)):
                if x.startswith('__'):
                    continue

                yield x

        for k in do():
            self._a[k] = mod.__name__

    def find(self, name):
        subst = {
            'xpath': 'run_xpath_simple',
            'Queue': 'queue',
        }

        name = subst.get(name, name)

        for i, f in enumerate(self._l):
            try:
                ret = f(name)
                self._cc[i] += 1

                return ret
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def __getattr__(self, name):
        try:
            self._hit += 1
            return self[name]
        except KeyError:
            self._hit -= 1
            self[name] = self.find(name)

        return self[name]

    def add_lookup(self, func):
        self._cc[len(self._l)] = 0
        self._l.append(func)

    def lookup(self, func):
        self.add_lookup(func)

        return func

    def find_function(self, name):
        for m in __loader__.iter_modules():
            try:
                return m[name]
            except KeyError:
                pass

        raise AttributeError(name)


y = IFace()
y.sys.modules['__main__'].y = y


def prompt(l):
    def can_use():
        try:
            if l in y.verbose:
                return True

            return y.config.get(l, False)
        except Exception as e:
            print(e)

        return False

    if can_use():
        frame = y.inspect.currentframe()
        frame = frame.f_back

        try:
            from ptpython.repl import embed

            embed(frame.f_globals, locals())
        except ImportError:
            y.code.interact(local=frame.f_globals)
        except Exception as e:
            y.debug('in prompt', e)

  
def load_builtin_modules(builtin):
    initial = (
        'ut.burn_it',
        'ut.single',
        'ut.preproc',
        'ut.xprint',
        'ut.rng',
        'ut.mod_load',
        'ut.defer',
        'ut.std_io',
        'ut.init_log',
        'ut.int_counter',
        'ut.mini_db',
        'ut.args_parse',
        'ut.algo',
        'ut.at_exit',
        'ut.err_handle',  
        'ut.caches',
        'ut.pub_sub',
        'ut.cli',
        'ut.queues',
    )

    for m in initial:
        __loader__.create_module(m)

    initial = set(initial)

    for k in builtin:
        if k not in initial:
            if k.startswith('ya') or k.startswith('ut'):
                __loader__.create_module(k)
                initial.add(k)


def run_stage4_0(data):
    try:
        run_stage4_1(data)
    except:
        y.os.abort()


def builtin_data(name):
    return y.globals.by_name[name]['data']


def run_stage4_1(data):
    @y.lookup
    def lookup(name):
        return data[name]

    y.clear_cache()
    y.linecache.clearcache()

    load_builtin_modules(y.globals.builtin_modules)

    data['async_loop'] = y.CoroLoop('main')

    y.init_logger(log_level=y.config.get('ll', 'info').upper())

    y.debug('will run defer constructors')
    y.run_defer_constructors()
    y.debug('done')

    async def flush_streams():
        ctl = y.current_coro()
        ss = [y.stderr, y.stdout]

        while True:
            try:
                for s in ss:
                    await ctl.sleep(0.1)
                    s.flush()
            except Exception as e:
                y.debug('in flush streams', e)

    async def entry_point():
        try:
            try:
                return await y.run_main(data.pop('args'))
            except AssertionError as e:
                print('{br}' + str(e) + '{}', file=y.stderr)
                y.shut_down(1)
            except SystemExit as e:
                code = e.code

                if code is None:
                    code = 0

                y.shut_down(retcode=code)
            except:
                y.os.abort()
        finally:
            y.shut_down(0)

    y.spawn(entry_point, debug=False)
    y.spawn(flush_streams, debug=False)

+++++++++++++++++++
import sys
import imp
import inspect


class StopNow(Exception):
    pass


class IFaceSlave(dict):
    def __init__(self, mod, parent):
        self.__dict__ = self
        self._mod = mod
        self._pa = parent

    def __getattr__(self, name):
        key = self._mod.__name__ + '.' + name

        try:
            return self[key]
        except KeyError:
            self[key] = self.find(name)

        return self[key]

    def lst(self):
        return (self.find_module, self.find_function)

    def find(self, name):
        for f in self.lst():
            try:
                return f(name)
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def find_module(self, name):
        return self._pa.create_slave(self._mod.__sub__[name])

    def find_function(self, name):
        return self._mod[name]


class IFaceStd(IFaceSlave):
    def __init__(self, mod, parent):
        IFaceSlave.__init__(self, mod, parent)

    def import_from(self, name):
        ctx = dict()
        exec('from ' + self._mod.__name__ + ' import ' + name, ctx)
        return ctx[name]

    def find_module_1(self, name):
        return self._pa.create_std(__import__(self._mod.__name__ + '.' + name))

    def find_module_2(self, name):
        x = self.import_from(name)

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_module_3(self, name):
        x = self._mod.__dict__[name]

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_function_1(self, name):
        return self._mod.__dict__[name]

    def find_function_2(self, name):
        return self.import_from(name)

    def lst(self):
        return (self.find_module_2, self.find_module_1, self.find_module_3, self.find_function_1, self.find_function_2)


class IFace(dict):
    def __init__(self):
        self.__dict__ = self
        self._l = []
        self._a = {}
        self._cc = {}
        self._hit = 0
   
        self.add_lookup(self.fast_search)
        self.add_lookup(self.find_function)
        self.add_lookup(lambda x: self.find_module(x))
        self.add_lookup(lambda x: self.create_std(sys.modules[x]))
        self.add_lookup(lambda x: self.create_std(__import__(x)))

    def clear_cache(self):
        for k in list(self.keys()):
            if k.startswith('_'):
                continue

            self.pop(k)

    @property
    def stdout(self):
        return sys.stdout

    @property
    def stderr(self):
        return sys.stderr

    def spawn(self, coro, name=None, debug=True):
        return self.async_loop.spawn(coro, name=name, debug=debug)

    async def offload(self, job):
        return await self.async_loop.offload(job)
  
    def last_msg(self, t):
        e = sys.stderr
        o = sys.stdout

        sys.stderr = None
        sys.stdout = None

        o.flush()
        e.flush()

        e.write(t)
        e.flush()

    @property
    def copy(self):
        try:
            return sys.modules['copy']
        except KeyError:
            __import__('copy')

        return sys.modules['copy']

    def print_stats(self):
        for i, f in enumerate(self._l):
            y.xprint_w(i, self._cc[i])

        y.xprint_w('hit =', self._hit, 'miss =', len(self._c))

    def create_slave_0(self, mod, klass):
        key = 's:' + mod.__name__ + ':' + klass.__name__

        try:
            return self[key]
        except KeyError:
            self[key] = klass(mod, self)

        return self[key]

    def create_slave(self, mod):
        return self.create_slave_0(mod, IFaceSlave)

    def create_std(self, mod):
        return mod
        #return self.create_slave_0(mod, IFaceStd)

    def find_module(self, x):
        y = '.' + x

        for mod in __loader__.iter_modules():
            if mod.__name__.endswith(y):
                return self.create_slave(mod)

        raise AttributeError(x)

    def fast_search(self, name):
        return __loader__._by_name[self._a[name]][name]

    def reindex_module(self, mod):
        def do():
            for x in frozenset(dir(mod)) - frozenset(dir(mod.__class__)):
                if x.startswith('__'):
                    continue

                yield x

        for k in do():
            self._a[k] = mod.__name__

    def find(self, name):
        subst = {
            'xpath': 'run_xpath_simple',
            'Queue': 'queue',
        }

        name = subst.get(name, name)

        for i, f in enumerate(self._l):
            try:
                ret = f(name)
                self._cc[i] += 1

                return ret
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def __getattr__(self, name):
        try:
            self._hit += 1
            return self[name]
        except KeyError:
            self._hit -= 1
            self[name] = self.find(name)

        return self[name]

    def add_lookup(self, func):
        self._cc[len(self._l)] = 0
        self._l.append(func)

    def lookup(self, func):
        self.add_lookup(func)

        return func

    def find_function(self, name):
        for m in __loader__.iter_modules():
            try:
                return m[name]
            except KeyError:
                pass

        raise AttributeError(name)


y = IFace()
y.sys.modules['__main__'].y = y


def prompt(l):
    def can_use():
        try:
            if l in y.verbose:
                return True

            return y.config.get(l, False)
        except Exception as e:
            print(e)

        return False

    if can_use():
        frame = y.inspect.currentframe()
        frame = frame.f_back

        try:
            from ptpython.repl import embed

            embed(frame.f_globals, locals())
        except ImportError:
            y.code.interact(local=frame.f_globals)
        except Exception as e:
            y.debug('in prompt', e)

  
def load_builtin_modules(builtin):
    initial = (
        'ut.burn_it',
        'ut.single',
        'ut.preproc',
        'ut.xprint',
        'ut.rng',
        'ut.mod_load',
        'ut.defer',
        'ut.std_io',
        'ut.init_log',
        'ut.int_counter',
        'ut.mini_db',
        'ut.args_parse',
        'ut.algo',
        'ut.at_exit',
        'ut.err_handle',  
        'ut.caches',
        'ut.pub_sub',
        'ut.cli',
        'ut.queues',
    )

    for m in initial:
        __loader__.create_module(m)

    initial = set(initial)

    for k in builtin:
        if k not in initial:
            if k.startswith('ya') or k.startswith('ut'):
                __loader__.create_module(k)
                initial.add(k)


def run_stage4_0(data):
    try:
        run_stage4_1(data)
    except:
        y.os.abort()


def builtin_data(name):
    return y.globals.by_name[name]['data']


def run_stage4_1(data):
    @y.lookup
    def lookup(name):
        return data[name]

    y.clear_cache()
    y.linecache.clearcache()

    load_builtin_modules(y.globals.builtin_modules)

    data['async_loop'] = y.CoroLoop('main')

    y.init_logger(log_level=y.config.get('ll', 'info').upper())

    y.debug('will run defer constructors')
    y.run_defer_constructors()
    y.debug('done')

    async def flush_streams():
        ctl = y.current_coro()
        ss = [y.stderr, y.stdout]

        while True:
            try:
                for s in ss:
                    await ctl.sleep(0.1)
                    s.flush()
            except Exception as e:
                y.debug('in flush streams', e)

    async def entry_point():
        try:
            try:
                return await y.run_main(data.pop('args'))
            except AssertionError as e:
                print('{br}' + str(e) + '{}', file=y.stderr)
                y.shut_down(1)
            except SystemExit as e:
                code = e.code

                if code is None:
                    code = 0

                y.shut_down(retcode=code)
            except:
                y.os.abort()
        finally:
            y.shut_down(0)

    y.spawn(entry_point, debug=False)
    y.spawn(flush_streams, debug=False)

--------------------1/ut/args_parse.py
import itertools


def check_arg_2(args, p, with_arg=False):
   res = {p: None}

   def flt():
      it = itertools.chain(args)

      for x in it:
         if x == p:
            res[p] = True

            if with_arg:
               for y in it:
                  res[p] = y

                  for z in it:
                     yield z

                  return

            for y in it:
               yield y

            return

         yield x

   return list(flt()), res[p]


def check_arg(args, params):
   old_len = len(args)

   for p in params:
      args, _ = check_arg_2(args, p)

   return args, len(args) != old_len


def parse_args(args):
    args, verbose = check_arg(args, ('-v', '--verbose'))
    args, profile = check_arg(args, ('--profile',))
    args, verbose_mode = check_arg_2(args, '-vm', True)

    if verbose_mode is None:
        args, verbose_mode = check_arg_2(args, '--verbose-mode', True)

    if verbose_mode:
        verbose = verbose_mode
    else:
        if verbose:
            verbose = '1'
        else:
            verbose = ''

    if len(args) < 2:
        args = args + ['help']

    return args, verbose, profile

+++++++++++++++++++
import itertools


def check_arg_2(args, p, with_arg=False):
   res = {p: None}

   def flt():
      it = itertools.chain(args)

      for x in it:
         if x == p:
            res[p] = True

            if with_arg:
               for y in it:
                  res[p] = y

                  for z in it:
                     yield z

                  return

            for y in it:
               yield y

            return

         yield x

   return list(flt()), res[p]


def check_arg(args, params):
   old_len = len(args)

   for p in params:
      args, _ = check_arg_2(args, p)

   return args, len(args) != old_len


def parse_args(args):
    args, verbose = check_arg(args, ('-v', '--verbose'))
    args, profile = check_arg(args, ('--profile',))
    args, verbose_mode = check_arg_2(args, '-vm', True)

    if verbose_mode is None:
        args, verbose_mode = check_arg_2(args, '--verbose-mode', True)

    if verbose_mode:
        verbose = verbose_mode
    else:
        if verbose:
            verbose = '1'
        else:
            verbose = ''

    if len(args) < 2:
        args = args + ['help']

    return args, verbose, profile

--------------------1/ut/mod_load.py
import sys
import random


class Mod(dict):
   def __init__(self, name, loader):
      self.__dict__ = self
      self.__yid__ = str(int(random.random() * 1000000000))
      self.__name__ = name
      self.__loader__ = loader
      self.__file__ = self.__name__
      self.__pkg__ = None
      self.__ytext__ = ''
      self.__ylineco__ = 0
      self.__ycode__ = []
      self.__yexec__ = self.exec_data
      self.__last_reindex__ = 0
      self.__sub__ = {}
  
      def get_log():
         log = self.y.logging.getLogger(self.__name__)

         self.__ylog__ = lambda: log

         return self.__ylog__()
 
      self.__ylog__ = get_log
  
      try:
         self.y = loader.get_y()
      except Exception:
         pass

      self.__loader__.register_module(self)
      self.exec_text_part(self.builtin_data())

   def ycompile(self, a, b, c, **kwargs):
      print('--------------------' + b + '\n' + a)
      ap = self.__loader__._preproc(a)
      print('+++++++++++++++++++\n' + ap)
      
      return self.__loader__._g.compile('\n' * kwargs.get('firstlineno', 0) + ap, b, c)

   def vname(self):
      return self.__name__[len(self.__loader__.root_module().__name__) + 1:]
  
   def create_sub_module(self, name):
      if (pos := name.find('.')) > 0:
         return self.create_sub_module_0(name[:pos]).create_sub_module(name[pos + 1:])

      return self.create_sub_module_0(name)

   def create_sub_module_0(self, name):
      if name not in self.__sub__:
         self.__sub__[name] = Mod(self.full_name(name), self.__loader__)

      return self.__sub__[name]
  
   def self_exec(self):
      self.exec_text_part(self.pop('__ynext_part__', ''))

   def exec_data(self, data, **kwargs):
      return self.__loader__.exec_code(self, data, **kwargs)

   def set_next_part(self, text):
      if text:
         self.__ynext_part__ = text 

   def exec_text_part(self, part):
      if not part.strip():
         return 

      code = self.ycompile(part, self.__file__.replace('.', '/') + '.py', 'exec', firstlineno=self.line_count())
  
      exec(code, self.__dict__)

      if self.__ytext__:
         self.__ytext__ += '\n'

      self.__ytext__ += part
      self.__ytext__ += '\n'
      self.__ylineco__ = self.__ytext__.count('\n')
      self.__ycode__.append(code)

      self.reindex()

   def reindex(self):
      lc = self.line_count()

      if 2 * self.__last_reindex__ < lc:
         try:
            func = self.y.reindex_module
         except Exception:
            func = None

         if func:
            func(self)

         self.__last_reindex__ = lc

   def line_count(self):
      return self.__ylineco__

   def text(self):
      return self.__ytext__

   def line_count_part(self, text):
      return text.count('\n')

   def builtin_data(self):
      return self.__loader__.builtin_data(self)

   def full_name(self, sub):
      return self.__name__ + '.' + sub
   

class Loader(object):
   def __init__(self, name, g, preproc=lambda x: x):
      self.__name__ = name
      self._by_name = {}
      self._builtin = g.builtin_modules
      self._order = []
      self._g = g
      self._preproc = preproc
  
      Mod(name, self)
  
   def root_module(self):
      return self._by_name[self._order[0]]
  
   def create_module(self, name):
      fname = self.root_module().full_name(name)
  
      if fname in self._by_name:
         return self._by_name[fname]

      return self.root_module().create_sub_module(name)

   def register_module(self, mod):
      mn = mod.__name__

      assert mn not in self._by_name
  
      self._order.append(mn)
      self._by_name[mn] = mod
  
      return mod
   
   def builtin_data(self, mod):
      return self._builtin.get(mod.vname(), {}).get('data', '')

   def exec_code(self, mod, data, module_name=None, arch={}, **kwargs):
      if arch:
         module_name = arch['os'] + '_' + arch['arch'] + '.' + module_name
         data = '#define __OS__ "' + arch['os'].upper() + '"\n\n' + data
         data = '#define __ARCH__ "' + arch['arch'].upper() + '"\n' + data
         data = '#define __' + arch['arch'].upper() + '__ 1\n' + data
         data = '#define __' + arch['os'].upper() + '__ 1\n' + data
         
      if module_name:
         m = self.create_module(module_name)

         if data != m.builtin_data():
            m.exec_text_part(data)

         return m

      mod.exec_text_part(data)

      return mod

   def find_sub_module(self, name):
      return self._by_name[self.root_module().full_name(name)]
   
   def get_y(self):
      return self.find_sub_module('ut.iface').y

   def get_source(self, name):
      return self._by_name[name].text()
  
   def iter_modules(self):
      for k in self._order:
         yield self._by_name[k]


def bootstrap(g):
    loader = Loader('1', g)

    loader.create_module('ut.iface')
    loader.create_module('ut.args_parse')
    loader.create_module('ut.mod_load')
    __loader__.__dict__.clear()
    loader.create_module('ut.stage2').run_stage2(g)

+++++++++++++++++++
import sys
import random


class Mod(dict):
   def __init__(self, name, loader):
      self.__dict__ = self
      self.__yid__ = str(int(random.random() * 1000000000))
      self.__name__ = name
      self.__loader__ = loader
      self.__file__ = self.__name__
      self.__pkg__ = None
      self.__ytext__ = ''
      self.__ylineco__ = 0
      self.__ycode__ = []
      self.__yexec__ = self.exec_data
      self.__last_reindex__ = 0
      self.__sub__ = {}
  
      def get_log():
         log = self.y.logging.getLogger(self.__name__)

         self.__ylog__ = lambda: log

         return self.__ylog__()
 
      self.__ylog__ = get_log
  
      try:
         self.y = loader.get_y()
      except Exception:
         pass

      self.__loader__.register_module(self)
      self.exec_text_part(self.builtin_data())

   def ycompile(self, a, b, c, **kwargs):
      print('--------------------' + b + '\n' + a)
      ap = self.__loader__._preproc(a)
      print('+++++++++++++++++++\n' + ap)
      
      return self.__loader__._g.compile('\n' * kwargs.get('firstlineno', 0) + ap, b, c)

   def vname(self):
      return self.__name__[len(self.__loader__.root_module().__name__) + 1:]
  
   def create_sub_module(self, name):
      if (pos := name.find('.')) > 0:
         return self.create_sub_module_0(name[:pos]).create_sub_module(name[pos + 1:])

      return self.create_sub_module_0(name)

   def create_sub_module_0(self, name):
      if name not in self.__sub__:
         self.__sub__[name] = Mod(self.full_name(name), self.__loader__)

      return self.__sub__[name]
  
   def self_exec(self):
      self.exec_text_part(self.pop('__ynext_part__', ''))

   def exec_data(self, data, **kwargs):
      return self.__loader__.exec_code(self, data, **kwargs)

   def set_next_part(self, text):
      if text:
         self.__ynext_part__ = text 

   def exec_text_part(self, part):
      if not part.strip():
         return 

      code = self.ycompile(part, self.__file__.replace('.', '/') + '.py', 'exec', firstlineno=self.line_count())
  
      exec(code, self.__dict__)

      if self.__ytext__:
         self.__ytext__ += '\n'

      self.__ytext__ += part
      self.__ytext__ += '\n'
      self.__ylineco__ = self.__ytext__.count('\n')
      self.__ycode__.append(code)

      self.reindex()

   def reindex(self):
      lc = self.line_count()

      if 2 * self.__last_reindex__ < lc:
         try:
            func = self.y.reindex_module
         except Exception:
            func = None

         if func:
            func(self)

         self.__last_reindex__ = lc

   def line_count(self):
      return self.__ylineco__

   def text(self):
      return self.__ytext__

   def line_count_part(self, text):
      return text.count('\n')

   def builtin_data(self):
      return self.__loader__.builtin_data(self)

   def full_name(self, sub):
      return self.__name__ + '.' + sub
   

class Loader(object):
   def __init__(self, name, g, preproc=lambda x: x):
      self.__name__ = name
      self._by_name = {}
      self._builtin = g.builtin_modules
      self._order = []
      self._g = g
      self._preproc = preproc
  
      Mod(name, self)
  
   def root_module(self):
      return self._by_name[self._order[0]]
  
   def create_module(self, name):
      fname = self.root_module().full_name(name)
  
      if fname in self._by_name:
         return self._by_name[fname]

      return self.root_module().create_sub_module(name)

   def register_module(self, mod):
      mn = mod.__name__

      assert mn not in self._by_name
  
      self._order.append(mn)
      self._by_name[mn] = mod
  
      return mod
   
   def builtin_data(self, mod):
      return self._builtin.get(mod.vname(), {}).get('data', '')

   def exec_code(self, mod, data, module_name=None, arch={}, **kwargs):
      if arch:
         module_name = arch['os'] + '_' + arch['arch'] + '.' + module_name
         data = '#define __OS__ "' + arch['os'].upper() + '"\n\n' + data
         data = '#define __ARCH__ "' + arch['arch'].upper() + '"\n' + data
         data = '#define __' + arch['arch'].upper() + '__ 1\n' + data
         data = '#define __' + arch['os'].upper() + '__ 1\n' + data
         
      if module_name:
         m = self.create_module(module_name)

         if data != m.builtin_data():
            m.exec_text_part(data)

         return m

      mod.exec_text_part(data)

      return mod

   def find_sub_module(self, name):
      return self._by_name[self.root_module().full_name(name)]
   
   def get_y(self):
      return self.find_sub_module('ut.iface').y

   def get_source(self, name):
      return self._by_name[name].text()
  
   def iter_modules(self):
      for k in self._order:
         yield self._by_name[k]


def bootstrap(g):
    loader = Loader('1', g)

    loader.create_module('ut.iface')
    loader.create_module('ut.args_parse')
    loader.create_module('ut.mod_load')
    __loader__.__dict__.clear()
    loader.create_module('ut.stage2').run_stage2(g)

--------------------1/ut/stage2.py
def run_stage2(g):
    args, verbose, profile = y.parse_args(y.sys.argv)

    def iter_cfg():
        for v in verbose.split(','):
            parts = v.split('=')

            if len(parts) >= 2:
                yield parts[0], parts[1]

            if len(parts) == 1:
                yield parts[0], True

    config = dict(iter_cfg())

    def run_thr():
        fd = {
            'verbose': verbose,
            'need_profile': profile,
            'args': args,
            'config': config,
            'globals': g,
        }

        loader = y.Loader('&', g)
        ml = loader.create_module('ut.mod_load')

        for m in loader.iter_modules():
            m.__class__ = ml.Mod

        loader.__class__ = ml.Loader

        __loader__.__dict__.clear()
        loader.create_module('ut.iface').run_stage4_0(fd)

    t = y.threading.Thread(target=run_thr)
    t.start()

+++++++++++++++++++
def run_stage2(g):
    args, verbose, profile = y.parse_args(y.sys.argv)

    def iter_cfg():
        for v in verbose.split(','):
            parts = v.split('=')

            if len(parts) >= 2:
                yield parts[0], parts[1]

            if len(parts) == 1:
                yield parts[0], True

    config = dict(iter_cfg())

    def run_thr():
        fd = {
            'verbose': verbose,
            'need_profile': profile,
            'args': args,
            'config': config,
            'globals': g,
        }

        loader = y.Loader('&', g)
        ml = loader.create_module('ut.mod_load')

        for m in loader.iter_modules():
            m.__class__ = ml.Mod

        loader.__class__ = ml.Loader

        __loader__.__dict__.clear()
        loader.create_module('ut.iface').run_stage4_0(fd)

    t = y.threading.Thread(target=run_thr)
    t.start()

--------------------&.py
#!/usr/bin/env python3


import os
import sys
import gc
import hashlib
import marshal

#gc.set_debug(gc.DEBUG_LEAK)


def check_ver():
    vi = sys.version_info

    if vi.major >= 3 and vi.minor >= 8:
        return

    for x in ('/root/python/bin:/Users/pg/18/bin:' + os.environ.get('PATH', '/bin:/usr/bin:/usr/local/bin')).split(':'):
        for v in ('3.8', '3.9', '3.10'):
            path = x + '/python' + v

            if os.path.isfile(path):
                os.execvp(path, [path] + sys.argv)

    raise Exception('we need python 3.8')


check_ver()


def find_me(g):
    for f in (lambda: __file__, lambda: sys.argv[0], lambda: os.path.abspath(os.getcwd()) + '/cli'):
        p = os.path.abspath(f())

        if os.path.isfile(p):
            return p

    raise Exception('can not find myself')


class Globals(dict):
    def __init__(self, cache):
        self.__dict__ = self
        self.cache = cache
        self.md5 = hashlib.md5
        self.dumps = marshal.dumps
        self.do_compile = compile
        self.hit = 0
        self.miss = 0
        
    def key(self, data):
        return self.md5(self.dumps(data)).hexdigest()
        
    def compile(self, a, b, c):
        key = self.key([a, b, c])

        if key not in self.cache:
            self.miss += 1
            self.cache[key] = self.do_compile(a, b, c)
        else:
            self.hit += 1
            
        return self.cache[key]
        

def real_main():
    file_data = None
    #REPLACEME

    if file_data:
        g = Globals(fd['compile_cache'])
    else:
        g = Globals({})

    g.script_path = find_me(g)
    g.script_dir = os.path.dirname(g.script_path)
    g.file_data = file_data
    
    if g.file_data:
        data = dict((x['name'], x) for x in g.file_data)['ut/stagea.py']['data']
    else:
        with open(g.script_dir + '/ut/stagea.py') as f:
            data = f.read()

    ctx = {'_globals': g}
    exec(compile(data +'\nmain(_globals)\n', '__main__', 'exec'), ctx)
    ctx.clear()


if __name__ == '__main__':
    real_main()

+++++++++++++++++++
#!/usr/bin/env python3


import os
import sys
import gc
import hashlib
import marshal

#gc.set_debug(gc.DEBUG_LEAK)


def check_ver():
    vi = sys.version_info

    if vi.major >= 3 and vi.minor >= 8:
        return

    for x in ('/root/python/bin:/Users/pg/18/bin:' + os.environ.get('PATH', '/bin:/usr/bin:/usr/local/bin')).split(':'):
        for v in ('3.8', '3.9', '3.10'):
            path = x + '/python' + v

            if os.path.isfile(path):
                os.execvp(path, [path] + sys.argv)

    raise Exception('we need python 3.8')


check_ver()


def find_me(g):
    for f in (lambda: __file__, lambda: sys.argv[0], lambda: os.path.abspath(os.getcwd()) + '/cli'):
        p = os.path.abspath(f())

        if os.path.isfile(p):
            return p

    raise Exception('can not find myself')


class Globals(dict):
    def __init__(self, cache):
        self.__dict__ = self
        self.cache = cache
        self.md5 = hashlib.md5
        self.dumps = marshal.dumps
        self.do_compile = compile
        self.hit = 0
        self.miss = 0
        
    def key(self, data):
        return self.md5(self.dumps(data)).hexdigest()
        
    def compile(self, a, b, c):
        key = self.key([a, b, c])

        if key not in self.cache:
            self.miss += 1
            self.cache[key] = self.do_compile(a, b, c)
        else:
            self.hit += 1
            
        return self.cache[key]
        

def real_main():
    file_data = None
    #REPLACEME

    if file_data:
        g = Globals(fd['compile_cache'])
    else:
        g = Globals({})

    g.script_path = find_me(g)
    g.script_dir = os.path.dirname(g.script_path)
    g.file_data = file_data
    
    if g.file_data:
        data = dict((x['name'], x) for x in g.file_data)['ut/stagea.py']['data']
    else:
        with open(g.script_dir + '/ut/stagea.py') as f:
            data = f.read()

    ctx = {'_globals': g}
    exec(compile(data +'\nmain(_globals)\n', '__main__', 'exec'), ctx)
    ctx.clear()


if __name__ == '__main__':
    real_main()

--------------------&/ut/mod_load.py
import sys
import random


class Mod(dict):
   def __init__(self, name, loader):
      self.__dict__ = self
      self.__yid__ = str(int(random.random() * 1000000000))
      self.__name__ = name
      self.__loader__ = loader
      self.__file__ = self.__name__
      self.__pkg__ = None
      self.__ytext__ = ''
      self.__ylineco__ = 0
      self.__ycode__ = []
      self.__yexec__ = self.exec_data
      self.__last_reindex__ = 0
      self.__sub__ = {}
  
      def get_log():
         log = self.y.logging.getLogger(self.__name__)

         self.__ylog__ = lambda: log

         return self.__ylog__()
 
      self.__ylog__ = get_log
  
      try:
         self.y = loader.get_y()
      except Exception:
         pass

      self.__loader__.register_module(self)
      self.exec_text_part(self.builtin_data())

   def ycompile(self, a, b, c, **kwargs):
      print('--------------------' + b + '\n' + a)
      ap = self.__loader__._preproc(a)
      print('+++++++++++++++++++\n' + ap)
      
      return self.__loader__._g.compile('\n' * kwargs.get('firstlineno', 0) + ap, b, c)

   def vname(self):
      return self.__name__[len(self.__loader__.root_module().__name__) + 1:]
  
   def create_sub_module(self, name):
      if (pos := name.find('.')) > 0:
         return self.create_sub_module_0(name[:pos]).create_sub_module(name[pos + 1:])

      return self.create_sub_module_0(name)

   def create_sub_module_0(self, name):
      if name not in self.__sub__:
         self.__sub__[name] = Mod(self.full_name(name), self.__loader__)

      return self.__sub__[name]
  
   def self_exec(self):
      self.exec_text_part(self.pop('__ynext_part__', ''))

   def exec_data(self, data, **kwargs):
      return self.__loader__.exec_code(self, data, **kwargs)

   def set_next_part(self, text):
      if text:
         self.__ynext_part__ = text 

   def exec_text_part(self, part):
      if not part.strip():
         return 

      code = self.ycompile(part, self.__file__.replace('.', '/') + '.py', 'exec', firstlineno=self.line_count())
  
      exec(code, self.__dict__)

      if self.__ytext__:
         self.__ytext__ += '\n'

      self.__ytext__ += part
      self.__ytext__ += '\n'
      self.__ylineco__ = self.__ytext__.count('\n')
      self.__ycode__.append(code)

      self.reindex()

   def reindex(self):
      lc = self.line_count()

      if 2 * self.__last_reindex__ < lc:
         try:
            func = self.y.reindex_module
         except Exception:
            func = None

         if func:
            func(self)

         self.__last_reindex__ = lc

   def line_count(self):
      return self.__ylineco__

   def text(self):
      return self.__ytext__

   def line_count_part(self, text):
      return text.count('\n')

   def builtin_data(self):
      return self.__loader__.builtin_data(self)

   def full_name(self, sub):
      return self.__name__ + '.' + sub
   

class Loader(object):
   def __init__(self, name, g, preproc=lambda x: x):
      self.__name__ = name
      self._by_name = {}
      self._builtin = g.builtin_modules
      self._order = []
      self._g = g
      self._preproc = preproc
  
      Mod(name, self)
  
   def root_module(self):
      return self._by_name[self._order[0]]
  
   def create_module(self, name):
      fname = self.root_module().full_name(name)
  
      if fname in self._by_name:
         return self._by_name[fname]

      return self.root_module().create_sub_module(name)

   def register_module(self, mod):
      mn = mod.__name__

      assert mn not in self._by_name
  
      self._order.append(mn)
      self._by_name[mn] = mod
  
      return mod
   
   def builtin_data(self, mod):
      return self._builtin.get(mod.vname(), {}).get('data', '')

   def exec_code(self, mod, data, module_name=None, arch={}, **kwargs):
      if arch:
         module_name = arch['os'] + '_' + arch['arch'] + '.' + module_name
         data = '#define __OS__ "' + arch['os'].upper() + '"\n\n' + data
         data = '#define __ARCH__ "' + arch['arch'].upper() + '"\n' + data
         data = '#define __' + arch['arch'].upper() + '__ 1\n' + data
         data = '#define __' + arch['os'].upper() + '__ 1\n' + data
         
      if module_name:
         m = self.create_module(module_name)

         if data != m.builtin_data():
            m.exec_text_part(data)

         return m

      mod.exec_text_part(data)

      return mod

   def find_sub_module(self, name):
      return self._by_name[self.root_module().full_name(name)]
   
   def get_y(self):
      return self.find_sub_module('ut.iface').y

   def get_source(self, name):
      return self._by_name[name].text()
  
   def iter_modules(self):
      for k in self._order:
         yield self._by_name[k]


def bootstrap(g):
    loader = Loader('1', g)

    loader.create_module('ut.iface')
    loader.create_module('ut.args_parse')
    loader.create_module('ut.mod_load')
    __loader__.__dict__.clear()
    loader.create_module('ut.stage2').run_stage2(g)

+++++++++++++++++++
import sys
import random


class Mod(dict):
   def __init__(self, name, loader):
      self.__dict__ = self
      self.__yid__ = str(int(random.random() * 1000000000))
      self.__name__ = name
      self.__loader__ = loader
      self.__file__ = self.__name__
      self.__pkg__ = None
      self.__ytext__ = ''
      self.__ylineco__ = 0
      self.__ycode__ = []
      self.__yexec__ = self.exec_data
      self.__last_reindex__ = 0
      self.__sub__ = {}
  
      def get_log():
         log = self.y.logging.getLogger(self.__name__)

         self.__ylog__ = lambda: log

         return self.__ylog__()
 
      self.__ylog__ = get_log
  
      try:
         self.y = loader.get_y()
      except Exception:
         pass

      self.__loader__.register_module(self)
      self.exec_text_part(self.builtin_data())

   def ycompile(self, a, b, c, **kwargs):
      print('--------------------' + b + '\n' + a)
      ap = self.__loader__._preproc(a)
      print('+++++++++++++++++++\n' + ap)
      
      return self.__loader__._g.compile('\n' * kwargs.get('firstlineno', 0) + ap, b, c)

   def vname(self):
      return self.__name__[len(self.__loader__.root_module().__name__) + 1:]
  
   def create_sub_module(self, name):
      if (pos := name.find('.')) > 0:
         return self.create_sub_module_0(name[:pos]).create_sub_module(name[pos + 1:])

      return self.create_sub_module_0(name)

   def create_sub_module_0(self, name):
      if name not in self.__sub__:
         self.__sub__[name] = Mod(self.full_name(name), self.__loader__)

      return self.__sub__[name]
  
   def self_exec(self):
      self.exec_text_part(self.pop('__ynext_part__', ''))

   def exec_data(self, data, **kwargs):
      return self.__loader__.exec_code(self, data, **kwargs)

   def set_next_part(self, text):
      if text:
         self.__ynext_part__ = text 

   def exec_text_part(self, part):
      if not part.strip():
         return 

      code = self.ycompile(part, self.__file__.replace('.', '/') + '.py', 'exec', firstlineno=self.line_count())
  
      exec(code, self.__dict__)

      if self.__ytext__:
         self.__ytext__ += '\n'

      self.__ytext__ += part
      self.__ytext__ += '\n'
      self.__ylineco__ = self.__ytext__.count('\n')
      self.__ycode__.append(code)

      self.reindex()

   def reindex(self):
      lc = self.line_count()

      if 2 * self.__last_reindex__ < lc:
         try:
            func = self.y.reindex_module
         except Exception:
            func = None

         if func:
            func(self)

         self.__last_reindex__ = lc

   def line_count(self):
      return self.__ylineco__

   def text(self):
      return self.__ytext__

   def line_count_part(self, text):
      return text.count('\n')

   def builtin_data(self):
      return self.__loader__.builtin_data(self)

   def full_name(self, sub):
      return self.__name__ + '.' + sub
   

class Loader(object):
   def __init__(self, name, g, preproc=lambda x: x):
      self.__name__ = name
      self._by_name = {}
      self._builtin = g.builtin_modules
      self._order = []
      self._g = g
      self._preproc = preproc
  
      Mod(name, self)
  
   def root_module(self):
      return self._by_name[self._order[0]]
  
   def create_module(self, name):
      fname = self.root_module().full_name(name)
  
      if fname in self._by_name:
         return self._by_name[fname]

      return self.root_module().create_sub_module(name)

   def register_module(self, mod):
      mn = mod.__name__

      assert mn not in self._by_name
  
      self._order.append(mn)
      self._by_name[mn] = mod
  
      return mod
   
   def builtin_data(self, mod):
      return self._builtin.get(mod.vname(), {}).get('data', '')

   def exec_code(self, mod, data, module_name=None, arch={}, **kwargs):
      if arch:
         module_name = arch['os'] + '_' + arch['arch'] + '.' + module_name
         data = '#define __OS__ "' + arch['os'].upper() + '"\n\n' + data
         data = '#define __ARCH__ "' + arch['arch'].upper() + '"\n' + data
         data = '#define __' + arch['arch'].upper() + '__ 1\n' + data
         data = '#define __' + arch['os'].upper() + '__ 1\n' + data
         
      if module_name:
         m = self.create_module(module_name)

         if data != m.builtin_data():
            m.exec_text_part(data)

         return m

      mod.exec_text_part(data)

      return mod

   def find_sub_module(self, name):
      return self._by_name[self.root_module().full_name(name)]
   
   def get_y(self):
      return self.find_sub_module('ut.iface').y

   def get_source(self, name):
      return self._by_name[name].text()
  
   def iter_modules(self):
      for k in self._order:
         yield self._by_name[k]


def bootstrap(g):
    loader = Loader('1', g)

    loader.create_module('ut.iface')
    loader.create_module('ut.args_parse')
    loader.create_module('ut.mod_load')
    __loader__.__dict__.clear()
    loader.create_module('ut.stage2').run_stage2(g)

--------------------&/ut/iface.py
import sys
import imp
import inspect


class StopNow(Exception):
    pass


class IFaceSlave(dict):
    def __init__(self, mod, parent):
        self.__dict__ = self
        self._mod = mod
        self._pa = parent

    def __getattr__(self, name):
        key = self._mod.__name__ + '.' + name

        try:
            return self[key]
        except KeyError:
            self[key] = self.find(name)

        return self[key]

    def lst(self):
        return (self.find_module, self.find_function)

    def find(self, name):
        for f in self.lst():
            try:
                return f(name)
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def find_module(self, name):
        return self._pa.create_slave(self._mod.__sub__[name])

    def find_function(self, name):
        return self._mod[name]


class IFaceStd(IFaceSlave):
    def __init__(self, mod, parent):
        IFaceSlave.__init__(self, mod, parent)

    def import_from(self, name):
        ctx = dict()
        exec('from ' + self._mod.__name__ + ' import ' + name, ctx)
        return ctx[name]

    def find_module_1(self, name):
        return self._pa.create_std(__import__(self._mod.__name__ + '.' + name))

    def find_module_2(self, name):
        x = self.import_from(name)

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_module_3(self, name):
        x = self._mod.__dict__[name]

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_function_1(self, name):
        return self._mod.__dict__[name]

    def find_function_2(self, name):
        return self.import_from(name)

    def lst(self):
        return (self.find_module_2, self.find_module_1, self.find_module_3, self.find_function_1, self.find_function_2)


class IFace(dict):
    def __init__(self):
        self.__dict__ = self
        self._l = []
        self._a = {}
        self._cc = {}
        self._hit = 0
   
        self.add_lookup(self.fast_search)
        self.add_lookup(self.find_function)
        self.add_lookup(lambda x: self.find_module(x))
        self.add_lookup(lambda x: self.create_std(sys.modules[x]))
        self.add_lookup(lambda x: self.create_std(__import__(x)))

    def clear_cache(self):
        for k in list(self.keys()):
            if k.startswith('_'):
                continue

            self.pop(k)

    @property
    def stdout(self):
        return sys.stdout

    @property
    def stderr(self):
        return sys.stderr

    def spawn(self, coro, name=None, debug=True):
        return self.async_loop.spawn(coro, name=name, debug=debug)

    async def offload(self, job):
        return await self.async_loop.offload(job)
  
    def last_msg(self, t):
        e = sys.stderr
        o = sys.stdout

        sys.stderr = None
        sys.stdout = None

        o.flush()
        e.flush()

        e.write(t)
        e.flush()

    @property
    def copy(self):
        try:
            return sys.modules['copy']
        except KeyError:
            __import__('copy')

        return sys.modules['copy']

    def print_stats(self):
        for i, f in enumerate(self._l):
            y.xprint_w(i, self._cc[i])

        y.xprint_w('hit =', self._hit, 'miss =', len(self._c))

    def create_slave_0(self, mod, klass):
        key = 's:' + mod.__name__ + ':' + klass.__name__

        try:
            return self[key]
        except KeyError:
            self[key] = klass(mod, self)

        return self[key]

    def create_slave(self, mod):
        return self.create_slave_0(mod, IFaceSlave)

    def create_std(self, mod):
        return mod
        #return self.create_slave_0(mod, IFaceStd)

    def find_module(self, x):
        y = '.' + x

        for mod in __loader__.iter_modules():
            if mod.__name__.endswith(y):
                return self.create_slave(mod)

        raise AttributeError(x)

    def fast_search(self, name):
        return __loader__._by_name[self._a[name]][name]

    def reindex_module(self, mod):
        def do():
            for x in frozenset(dir(mod)) - frozenset(dir(mod.__class__)):
                if x.startswith('__'):
                    continue

                yield x

        for k in do():
            self._a[k] = mod.__name__

    def find(self, name):
        subst = {
            'xpath': 'run_xpath_simple',
            'Queue': 'queue',
        }

        name = subst.get(name, name)

        for i, f in enumerate(self._l):
            try:
                ret = f(name)
                self._cc[i] += 1

                return ret
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def __getattr__(self, name):
        try:
            self._hit += 1
            return self[name]
        except KeyError:
            self._hit -= 1
            self[name] = self.find(name)

        return self[name]

    def add_lookup(self, func):
        self._cc[len(self._l)] = 0
        self._l.append(func)

    def lookup(self, func):
        self.add_lookup(func)

        return func

    def find_function(self, name):
        for m in __loader__.iter_modules():
            try:
                return m[name]
            except KeyError:
                pass

        raise AttributeError(name)


y = IFace()
y.sys.modules['__main__'].y = y


def prompt(l):
    def can_use():
        try:
            if l in y.verbose:
                return True

            return y.config.get(l, False)
        except Exception as e:
            print(e)

        return False

    if can_use():
        frame = y.inspect.currentframe()
        frame = frame.f_back

        try:
            from ptpython.repl import embed

            embed(frame.f_globals, locals())
        except ImportError:
            y.code.interact(local=frame.f_globals)
        except Exception as e:
            y.debug('in prompt', e)

  
def load_builtin_modules(builtin):
    initial = (
        'ut.burn_it',
        'ut.single',
        'ut.preproc',
        'ut.xprint',
        'ut.rng',
        'ut.mod_load',
        'ut.defer',
        'ut.std_io',
        'ut.init_log',
        'ut.int_counter',
        'ut.mini_db',
        'ut.args_parse',
        'ut.algo',
        'ut.at_exit',
        'ut.err_handle',  
        'ut.caches',
        'ut.pub_sub',
        'ut.cli',
        'ut.queues',
    )

    for m in initial:
        __loader__.create_module(m)

    initial = set(initial)

    for k in builtin:
        if k not in initial:
            if k.startswith('ya') or k.startswith('ut'):
                __loader__.create_module(k)
                initial.add(k)


def run_stage4_0(data):
    try:
        run_stage4_1(data)
    except:
        y.os.abort()


def builtin_data(name):
    return y.globals.by_name[name]['data']


def run_stage4_1(data):
    @y.lookup
    def lookup(name):
        return data[name]

    y.clear_cache()
    y.linecache.clearcache()

    load_builtin_modules(y.globals.builtin_modules)

    data['async_loop'] = y.CoroLoop('main')

    y.init_logger(log_level=y.config.get('ll', 'info').upper())

    y.debug('will run defer constructors')
    y.run_defer_constructors()
    y.debug('done')

    async def flush_streams():
        ctl = y.current_coro()
        ss = [y.stderr, y.stdout]

        while True:
            try:
                for s in ss:
                    await ctl.sleep(0.1)
                    s.flush()
            except Exception as e:
                y.debug('in flush streams', e)

    async def entry_point():
        try:
            try:
                return await y.run_main(data.pop('args'))
            except AssertionError as e:
                print('{br}' + str(e) + '{}', file=y.stderr)
                y.shut_down(1)
            except SystemExit as e:
                code = e.code

                if code is None:
                    code = 0

                y.shut_down(retcode=code)
            except:
                y.os.abort()
        finally:
            y.shut_down(0)

    y.spawn(entry_point, debug=False)
    y.spawn(flush_streams, debug=False)

+++++++++++++++++++
import sys
import imp
import inspect


class StopNow(Exception):
    pass


class IFaceSlave(dict):
    def __init__(self, mod, parent):
        self.__dict__ = self
        self._mod = mod
        self._pa = parent

    def __getattr__(self, name):
        key = self._mod.__name__ + '.' + name

        try:
            return self[key]
        except KeyError:
            self[key] = self.find(name)

        return self[key]

    def lst(self):
        return (self.find_module, self.find_function)

    def find(self, name):
        for f in self.lst():
            try:
                return f(name)
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def find_module(self, name):
        return self._pa.create_slave(self._mod.__sub__[name])

    def find_function(self, name):
        return self._mod[name]


class IFaceStd(IFaceSlave):
    def __init__(self, mod, parent):
        IFaceSlave.__init__(self, mod, parent)

    def import_from(self, name):
        ctx = dict()
        exec('from ' + self._mod.__name__ + ' import ' + name, ctx)
        return ctx[name]

    def find_module_1(self, name):
        return self._pa.create_std(__import__(self._mod.__name__ + '.' + name))

    def find_module_2(self, name):
        x = self.import_from(name)

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_module_3(self, name):
        x = self._mod.__dict__[name]

        if inspect.ismodule(x):
            return self._pa.create_std(x)

        raise AttributeError(name)

    def find_function_1(self, name):
        return self._mod.__dict__[name]

    def find_function_2(self, name):
        return self.import_from(name)

    def lst(self):
        return (self.find_module_2, self.find_module_1, self.find_module_3, self.find_function_1, self.find_function_2)


class IFace(dict):
    def __init__(self):
        self.__dict__ = self
        self._l = []
        self._a = {}
        self._cc = {}
        self._hit = 0
   
        self.add_lookup(self.fast_search)
        self.add_lookup(self.find_function)
        self.add_lookup(lambda x: self.find_module(x))
        self.add_lookup(lambda x: self.create_std(sys.modules[x]))
        self.add_lookup(lambda x: self.create_std(__import__(x)))

    def clear_cache(self):
        for k in list(self.keys()):
            if k.startswith('_'):
                continue

            self.pop(k)

    @property
    def stdout(self):
        return sys.stdout

    @property
    def stderr(self):
        return sys.stderr

    def spawn(self, coro, name=None, debug=True):
        return self.async_loop.spawn(coro, name=name, debug=debug)

    async def offload(self, job):
        return await self.async_loop.offload(job)
  
    def last_msg(self, t):
        e = sys.stderr
        o = sys.stdout

        sys.stderr = None
        sys.stdout = None

        o.flush()
        e.flush()

        e.write(t)
        e.flush()

    @property
    def copy(self):
        try:
            return sys.modules['copy']
        except KeyError:
            __import__('copy')

        return sys.modules['copy']

    def print_stats(self):
        for i, f in enumerate(self._l):
            y.xprint_w(i, self._cc[i])

        y.xprint_w('hit =', self._hit, 'miss =', len(self._c))

    def create_slave_0(self, mod, klass):
        key = 's:' + mod.__name__ + ':' + klass.__name__

        try:
            return self[key]
        except KeyError:
            self[key] = klass(mod, self)

        return self[key]

    def create_slave(self, mod):
        return self.create_slave_0(mod, IFaceSlave)

    def create_std(self, mod):
        return mod
        #return self.create_slave_0(mod, IFaceStd)

    def find_module(self, x):
        y = '.' + x

        for mod in __loader__.iter_modules():
            if mod.__name__.endswith(y):
                return self.create_slave(mod)

        raise AttributeError(x)

    def fast_search(self, name):
        return __loader__._by_name[self._a[name]][name]

    def reindex_module(self, mod):
        def do():
            for x in frozenset(dir(mod)) - frozenset(dir(mod.__class__)):
                if x.startswith('__'):
                    continue

                yield x

        for k in do():
            self._a[k] = mod.__name__

    def find(self, name):
        subst = {
            'xpath': 'run_xpath_simple',
            'Queue': 'queue',
        }

        name = subst.get(name, name)

        for i, f in enumerate(self._l):
            try:
                ret = f(name)
                self._cc[i] += 1

                return ret
            except AttributeError:
                pass
            except KeyError:
                pass
            except ImportError:
                pass

        raise AttributeError(name)

    def __getattr__(self, name):
        try:
            self._hit += 1
            return self[name]
        except KeyError:
            self._hit -= 1
            self[name] = self.find(name)

        return self[name]

    def add_lookup(self, func):
        self._cc[len(self._l)] = 0
        self._l.append(func)

    def lookup(self, func):
        self.add_lookup(func)

        return func

    def find_function(self, name):
        for m in __loader__.iter_modules():
            try:
                return m[name]
            except KeyError:
                pass

        raise AttributeError(name)


y = IFace()
y.sys.modules['__main__'].y = y


def prompt(l):
    def can_use():
        try:
            if l in y.verbose:
                return True

            return y.config.get(l, False)
        except Exception as e:
            print(e)

        return False

    if can_use():
        frame = y.inspect.currentframe()
        frame = frame.f_back

        try:
            from ptpython.repl import embed

            embed(frame.f_globals, locals())
        except ImportError:
            y.code.interact(local=frame.f_globals)
        except Exception as e:
            y.debug('in prompt', e)

  
def load_builtin_modules(builtin):
    initial = (
        'ut.burn_it',
        'ut.single',
        'ut.preproc',
        'ut.xprint',
        'ut.rng',
        'ut.mod_load',
        'ut.defer',
        'ut.std_io',
        'ut.init_log',
        'ut.int_counter',
        'ut.mini_db',
        'ut.args_parse',
        'ut.algo',
        'ut.at_exit',
        'ut.err_handle',  
        'ut.caches',
        'ut.pub_sub',
        'ut.cli',
        'ut.queues',
    )

    for m in initial:
        __loader__.create_module(m)

    initial = set(initial)

    for k in builtin:
        if k not in initial:
            if k.startswith('ya') or k.startswith('ut'):
                __loader__.create_module(k)
                initial.add(k)


def run_stage4_0(data):
    try:
        run_stage4_1(data)
    except:
        y.os.abort()


def builtin_data(name):
    return y.globals.by_name[name]['data']


def run_stage4_1(data):
    @y.lookup
    def lookup(name):
        return data[name]

    y.clear_cache()
    y.linecache.clearcache()

    load_builtin_modules(y.globals.builtin_modules)

    data['async_loop'] = y.CoroLoop('main')

    y.init_logger(log_level=y.config.get('ll', 'info').upper())

    y.debug('will run defer constructors')
    y.run_defer_constructors()
    y.debug('done')

    async def flush_streams():
        ctl = y.current_coro()
        ss = [y.stderr, y.stdout]

        while True:
            try:
                for s in ss:
                    await ctl.sleep(0.1)
                    s.flush()
            except Exception as e:
                y.debug('in flush streams', e)

    async def entry_point():
        try:
            try:
                return await y.run_main(data.pop('args'))
            except AssertionError as e:
                print('{br}' + str(e) + '{}', file=y.stderr)
                y.shut_down(1)
            except SystemExit as e:
                code = e.code

                if code is None:
                    code = 0

                y.shut_down(retcode=code)
            except:
                y.os.abort()
        finally:
            y.shut_down(0)

    y.spawn(entry_point, debug=False)
    y.spawn(flush_streams, debug=False)

--------------------&/ut/burn_it.py
import hashlib
import marshal
import json


def burn(p):
    return struct_dump_bytes(p)


def struct_dump_bytes(p):
    return hashlib.md5(marshal.dumps(p)).hexdigest()[:16]


def struct_dump_bytes_json(p):
    return hashlib.md5(json.dumps(p, sort_keys=True)).hexdigest()

+++++++++++++++++++
import hashlib
import marshal
import json


def burn(p):
    return struct_dump_bytes(p)


def struct_dump_bytes(p):
    return hashlib.md5(marshal.dumps(p)).hexdigest()[:16]


def struct_dump_bytes_json(p):
    return hashlib.md5(json.dumps(p, sort_keys=True)).hexdigest()

--------------------&/ut/single.py
def singleton(f):
    def wrapper():
        d = wrapper.__dict__

        try:
            return d['']
        except KeyError:
            d[''] = f()

        return d['']

    wrapper.__name__ = f.__name__

    return wrapper

+++++++++++++++++++
def singleton(f):
    def wrapper():
        d = wrapper.__dict__

        try:
            return d['']
        except KeyError:
            d[''] = f()

        return d['']

    wrapper.__name__ = f.__name__

    return wrapper

--------------------&/ut/preproc.py
undefined = object()


@y.singleton
def is_debug():
    return 'preproc=debug' in ''.join(y.sys.argv)


class Defines(dict):
    def __init__(self, defs):
        self.__dict__ = self
        self.update(defs)

        def defined(x):
            is_debug() and print(x)
            return not x is undefined

        self.defined = defined

    def __missing__(self, key):
        is_debug() and print('missing', key)
        return undefined


class Preproc(object):
    def __init__(self, l, text):
        self.t = text
        self.d = Defines(l)
        self.r = []
        self.v = []

    def run(self):
        for l in self.t.split('\n'):
            _, val = self.command(l)
            self.r.append(val)

        return '\n'.join(self.r) + '\n'

    def command(self, l):
        ll = l.strip()

        if ll and ll[0] == '#':
            p = ll.find(' ')

            if p < 0:
                p = len(ll)

            cmd = ll[1:p]
            fill = l[:-len(ll)]

            try:
                f = getattr(self, 'do_' + cmd)
            except AttributeError:
                return False, l

            data = ll[p + 1:]
            res = f(data) or ''

            is_debug() and print(repr(cmd), repr(data), repr(fill + res), f.__name__)

            return True, fill + res

        return False, l

    def do_define(self, l):
        x, y = l.split(' ', 1)

        self.d[x] = eval(y, self.d)

        return x + ' = ' + repr(self.d[x])

    def do_undef(self, l):
        self.d.pop(l.strip())

        return 'del ' + l.strip()

    def do_if(self, l):
        self.v.append(False)
        return self.do_elif(l)

    def do_elif(self, l):
        if not self.v[-1]:
            is_debug() and print(l, eval(l, self.d))

            if eval(l, self.d):
                self.v[-1] = True

                return 'if 1:'

        return 'if 0:'

    def do_else(self, l):
        if self.v[-1] == False:
            self.v[-1] = True
            return 'if 1:'

        return 'if 0:'

    def do_endif(self, l):
        assert self.v.pop() is not None

    def do_exclude(self, l):
        if eval(l, self.d):
            is_debug() and print('will exclude ' + l)
            return 'if 0:'

        is_debug() and print('will include ' + l)
        return 'if 1:'

    def do_endex(self, l):
        pass

    def do_print_state(self, l):
        print('\n'.join(self.r), file=y.stderr)


@y.singleton
def global_defines():
    return {
        'arch': y.platform.machine(),
	'os': y.platform.system().lower(),
    }


def preprocess_text(text, defines=global_defines()):
    ps = y.globals.by_prefix
    fs = y.globals.file_data

    def check(*els):
        for el in els:
            el = chr(35) + el

            if el in text:
                return True

    if check('if', 'ex'):
        return Preproc(defines, text).run()
    
    return text


__loader__._preproc = preprocess_text

+++++++++++++++++++
undefined = object()


@y.singleton
def is_debug():
    return 'preproc=debug' in ''.join(y.sys.argv)


class Defines(dict):
    def __init__(self, defs):
        self.__dict__ = self
        self.update(defs)

        def defined(x):
            is_debug() and print(x)
            return not x is undefined

        self.defined = defined

    def __missing__(self, key):
        is_debug() and print('missing', key)
        return undefined


class Preproc(object):
    def __init__(self, l, text):
        self.t = text
        self.d = Defines(l)
        self.r = []
        self.v = []

    def run(self):
        for l in self.t.split('\n'):
            _, val = self.command(l)
            self.r.append(val)

        return '\n'.join(self.r) + '\n'

    def command(self, l):
        ll = l.strip()

        if ll and ll[0] == '#':
            p = ll.find(' ')

            if p < 0:
                p = len(ll)

            cmd = ll[1:p]
            fill = l[:-len(ll)]

            try:
                f = getattr(self, 'do_' + cmd)
            except AttributeError:
                return False, l

            data = ll[p + 1:]
            res = f(data) or ''

            is_debug() and print(repr(cmd), repr(data), repr(fill + res), f.__name__)

            return True, fill + res

        return False, l

    def do_define(self, l):
        x, y = l.split(' ', 1)

        self.d[x] = eval(y, self.d)

        return x + ' = ' + repr(self.d[x])

    def do_undef(self, l):
        self.d.pop(l.strip())

        return 'del ' + l.strip()

    def do_if(self, l):
        self.v.append(False)
        return self.do_elif(l)

    def do_elif(self, l):
        if not self.v[-1]:
            is_debug() and print(l, eval(l, self.d))

            if eval(l, self.d):
                self.v[-1] = True

                return 'if 1:'

        return 'if 0:'

    def do_else(self, l):
        if self.v[-1] == False:
            self.v[-1] = True
            return 'if 1:'

        return 'if 0:'

    def do_endif(self, l):
        assert self.v.pop() is not None

    def do_exclude(self, l):
        if eval(l, self.d):
            is_debug() and print('will exclude ' + l)
            return 'if 0:'

        is_debug() and print('will include ' + l)
        return 'if 1:'

    def do_endex(self, l):
        pass

    def do_print_state(self, l):
        print('\n'.join(self.r), file=y.stderr)


@y.singleton
def global_defines():
    return {
        'arch': y.platform.machine(),
	'os': y.platform.system().lower(),
    }


def preprocess_text(text, defines=global_defines()):
    ps = y.globals.by_prefix
    fs = y.globals.file_data

    def check(*els):
        for el in els:
            el = chr(35) + el

            if el in text:
                return True

    if check('if', 'ex'):
        return Preproc(defines, text).run()
    
    return text


__loader__._preproc = preprocess_text

--------------------&/ut/xprint.py
def xxformat(*args, **kwargs):
    def iter_t():
        for x in args:
            yield x

        if 'text' in kwargs:
            yield kwargs.pop('text')

    text = ' '.join(str(x) for x in iter_t())

    if 'init' in kwargs:
        text = '{' + kwargs['init'] + '}' + text + '{}'

    return text


def xxprint(*args, **kwargs):
    kwargs.pop('where', y.stderr).write(xxformat(*args, **kwargs) + '\n')


@y.singleton
def my_cm():
    return y.dc(y.COLOR_TABLE)


def process_color(text, init, kwargs):
    verbose = kwargs.get('verbose', y.verbose)
    raw = kwargs.get('raw', False)
    strip_colors = kwargs.get('strip_colors', False)
    cm = my_cm()
    rst = ('c', '')

    def process_stack(s, text):
        while text:
            p = text.find('{')

            if p < 0:
                yield ('t', text)

                return

            yield ('t', text[:p])

            text = text[p:]

            p = text.find('}')

            if p < 0:
                yield ('t', text)

                return

            c = text[:p + 1]
            text = text[p + 1:]

            if c == '{}':
                s.pop()

                yield ('c', s[-1])
            elif c in cm:
                s.append(c)

                yield ('c', c)
            else:
                yield ('t', c)

    out_txt = (verbose and '/rc' in verbose) or ('txt' in y.config.get('color', ''))

    def combine():
        s = [init or '']
        last = []

        def join(l):
            if l[0][0] == 'c':
                c = l[-1][1]

                if raw:
                    return {'color': c}

                if out_txt:
                    return c

                if strip_colors:
                    return ''

                return cm[''] + cm[c]
            else:
                res = ''.join([x[1] for x in last])

                if raw:
                    return {'text': res}

                return res

        for p in process_stack(s, text):
            if p[0] == 't' and not p[1]:
                continue

            if not last:
                last.append(p)
            else:
                if last[0][0] == p[0]:
                    last.append(p)
                else:
                    yield join(last)
                    last = [p]

        if last:
            yield join(last)

    if raw:
        return list(combine())

    return ''.join(combine())


@y.lookup
def lookup(xp):
    if xp.startswith('xprint_'):
        color=xp[7:]

        def func(*args, **kwargs):
            xxprint(*args, init=color, **kwargs)

        func.__name__ = xp

        return func

    raise AttributeError(xp)


def run_color_test():
    text = '''
{w}{g}982{} | {b}18:32:34{} | {y}ut.iface    {} | {ds}D{} | {bs}will run defer constructors {}{}
{w}{g}982{} | {b}18:32:34{} | {y}ut.iface    {} | {ds}D{} | {bs}done {}{}
{w}{g}982{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}spawn <coro entry_point, from <loop main>, created>{}{}
{w}{g}982{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}spawn <coro flush_streams, from <loop main>, created>{}{}
{w}{g}958{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro entry_point, from <loop main>, created> step in{}{}
{w}{g}33 {} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro flush_streams, from <loop main>, created> step in{}{}
{w}{g}33 {} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro flush_streams, from <loop main>, suspended> step out{}{}
{w}{g}958{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro entry_point, from <loop main>, suspended> step out{}{}
{w}{g}345{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}reschedule <coro entry_point, from <loop main>, suspended>{}{}
{w}{g}9  {} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro entry_point, from <loop main>, suspended> step in{}{}
'''

    y.sys.stderr.write(process_color(text.strip() + '\n', '', {'verbose': '/rc'}))
    y.sys.stderr.flush()

+++++++++++++++++++
def xxformat(*args, **kwargs):
    def iter_t():
        for x in args:
            yield x

        if 'text' in kwargs:
            yield kwargs.pop('text')

    text = ' '.join(str(x) for x in iter_t())

    if 'init' in kwargs:
        text = '{' + kwargs['init'] + '}' + text + '{}'

    return text


def xxprint(*args, **kwargs):
    kwargs.pop('where', y.stderr).write(xxformat(*args, **kwargs) + '\n')


@y.singleton
def my_cm():
    return y.dc(y.COLOR_TABLE)


def process_color(text, init, kwargs):
    verbose = kwargs.get('verbose', y.verbose)
    raw = kwargs.get('raw', False)
    strip_colors = kwargs.get('strip_colors', False)
    cm = my_cm()
    rst = ('c', '')

    def process_stack(s, text):
        while text:
            p = text.find('{')

            if p < 0:
                yield ('t', text)

                return

            yield ('t', text[:p])

            text = text[p:]

            p = text.find('}')

            if p < 0:
                yield ('t', text)

                return

            c = text[:p + 1]
            text = text[p + 1:]

            if c == '{}':
                s.pop()

                yield ('c', s[-1])
            elif c in cm:
                s.append(c)

                yield ('c', c)
            else:
                yield ('t', c)

    out_txt = (verbose and '/rc' in verbose) or ('txt' in y.config.get('color', ''))

    def combine():
        s = [init or '']
        last = []

        def join(l):
            if l[0][0] == 'c':
                c = l[-1][1]

                if raw:
                    return {'color': c}

                if out_txt:
                    return c

                if strip_colors:
                    return ''

                return cm[''] + cm[c]
            else:
                res = ''.join([x[1] for x in last])

                if raw:
                    return {'text': res}

                return res

        for p in process_stack(s, text):
            if p[0] == 't' and not p[1]:
                continue

            if not last:
                last.append(p)
            else:
                if last[0][0] == p[0]:
                    last.append(p)
                else:
                    yield join(last)
                    last = [p]

        if last:
            yield join(last)

    if raw:
        return list(combine())

    return ''.join(combine())


@y.lookup
def lookup(xp):
    if xp.startswith('xprint_'):
        color=xp[7:]

        def func(*args, **kwargs):
            xxprint(*args, init=color, **kwargs)

        func.__name__ = xp

        return func

    raise AttributeError(xp)


def run_color_test():
    text = '''
{w}{g}982{} | {b}18:32:34{} | {y}ut.iface    {} | {ds}D{} | {bs}will run defer constructors {}{}
{w}{g}982{} | {b}18:32:34{} | {y}ut.iface    {} | {ds}D{} | {bs}done {}{}
{w}{g}982{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}spawn <coro entry_point, from <loop main>, created>{}{}
{w}{g}982{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}spawn <coro flush_streams, from <loop main>, created>{}{}
{w}{g}958{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro entry_point, from <loop main>, created> step in{}{}
{w}{g}33 {} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro flush_streams, from <loop main>, created> step in{}{}
{w}{g}33 {} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro flush_streams, from <loop main>, suspended> step out{}{}
{w}{g}958{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro entry_point, from <loop main>, suspended> step out{}{}
{w}{g}345{} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}reschedule <coro entry_point, from <loop main>, suspended>{}{}
{w}{g}9  {} | {b}18:32:34{} | {y}ut.coro     {} | {ds}D{} | {bs}<coro entry_point, from <loop main>, suspended> step in{}{}
'''

    y.sys.stderr.write(process_color(text.strip() + '\n', '', {'verbose': '/rc'}))
    y.sys.stderr.flush()

--------------------&/ut/rng.py
MASK32 = 2**32 - 1
MASK64 = 2**64 - 1


def pcg_srandom(initstate, initseq):
    rng = [0, (initseq << 1) & MASK64 | 1]
    pcg_random(rng)
    rng[0] += initstate
    rng[0] &= MASK64
    pcg_random(rng)

    return rng


def pcg_random(rng):
    oldstate, inc = rng
    rng[0] = (oldstate * 6364136223846793005 + inc) & MASK64
    xorshifted = (((oldstate >> 18) ^ oldstate) >> 27) & MASK32
    rot = (oldstate >> 59) & MASK32

    return ((xorshifted >> rot) | (xorshifted << ((-rot) & 31))) & MASK32


class PCGRandom(object):
    def __init__(self, state, seq):
        self.rng = pcg_srandom(state, seq)

    def next_random(self):
        return pcg_random(self.rng)

    def next_float(self):
        while (res := self.next_random() / (MASK32 + 1.0)) >= 1.0:
            pass

        return res

    def iter_float(self):
        while True:
            yield self.next_float()

    def iter_int(self):
        while True:
            yield self.next_random()

+++++++++++++++++++
MASK32 = 2**32 - 1
MASK64 = 2**64 - 1


def pcg_srandom(initstate, initseq):
    rng = [0, (initseq << 1) & MASK64 | 1]
    pcg_random(rng)
    rng[0] += initstate
    rng[0] &= MASK64
    pcg_random(rng)

    return rng


def pcg_random(rng):
    oldstate, inc = rng
    rng[0] = (oldstate * 6364136223846793005 + inc) & MASK64
    xorshifted = (((oldstate >> 18) ^ oldstate) >> 27) & MASK32
    rot = (oldstate >> 59) & MASK32

    return ((xorshifted >> rot) | (xorshifted << ((-rot) & 31))) & MASK32


class PCGRandom(object):
    def __init__(self, state, seq):
        self.rng = pcg_srandom(state, seq)

    def next_random(self):
        return pcg_random(self.rng)

    def next_float(self):
        while (res := self.next_random() / (MASK32 + 1.0)) >= 1.0:
            pass

        return res

    def iter_float(self):
        while True:
            yield self.next_float()

    def iter_int(self):
        while True:
            yield self.next_random()

--------------------&/ut/defer.py
@y.contextlib.contextmanager
def defer_context(verbose=False):
    defer = []

    try:
        yield defer.append
    finally:
        for d in defer:
            try:
                d()
            except Exception:
                pass


def defer_wrapper(func):
    @y.functools.wraps(func)
    def wrapper(*args, **kwargs):
        with defer_context(verbose=True) as defer:
            return func(defer, *args, **kwargs)

    return wrapper


@y.singleton
def defer_channel():
    return []


def defer_constructor(func):
    defer_channel().append({'func': func})

    return func


def run_defer_constructors():
    @defer_constructor
    def sentinel():
        return 'shit'

    while True:
        for arg in defer_channel():
            res = str(arg['func']())

            if res == 'shit':
                return

+++++++++++++++++++
@y.contextlib.contextmanager
def defer_context(verbose=False):
    defer = []

    try:
        yield defer.append
    finally:
        for d in defer:
            try:
                d()
            except Exception:
                pass


def defer_wrapper(func):
    @y.functools.wraps(func)
    def wrapper(*args, **kwargs):
        with defer_context(verbose=True) as defer:
            return func(defer, *args, **kwargs)

    return wrapper


@y.singleton
def defer_channel():
    return []


def defer_constructor(func):
    defer_channel().append({'func': func})

    return func


def run_defer_constructors():
    @defer_constructor
    def sentinel():
        return 'shit'

    while True:
        for arg in defer_channel():
            res = str(arg['func']())

            if res == 'shit':
                return

--------------------&/ut/std_io.py
stdio_lock = y.threading.Lock()


class StdIO(object):
    def __init__(self, s):
        self.s = s

    def write(self, t):
        with stdio_lock:
            self.s.buffer.write(t.encode('utf-8'))
            self.s.buffer.flush()

    def flush(self):
        with stdio_lock:
            self.s.flush()


@y.singleton
def is_debug():
    return 'debug' in y.config.get('color', '')


class ColorStdIO(object):
    def __init__(self, s):
        self.s = s
        self.p = ''
        self.f = {'strip_colors': not self.isatty()}

    def isatty(self):
        return self.s.isatty()

    def can_colorize(self, t):
        if len(t) > 100000:
            return False

        return not is_debug()

    def colorize_0(self, t):
        #return t
        return y.process_color(t, '', self.f)

    def colorize(self, t):
        if not self.can_colorize(t):
            return t

        try:
            return self.colorize_0(t)
        except IndexError:
            pass

        def iter_lines():
            for l in t.split('\n'):
                try:
                    yield self.colorize_0(l)
                except IndexError:
                    yield l

        return '\n'.join(iter_lines())

    def get_part(self):
        try:
            return self.p
        finally:
            self.p = ''

    def write(self, t):
        if not t:
            return

        with stdio_lock:
            if len(t) > 4096:
                self.flush_impl()
                self.write_part(t)
            else:
                self.p += t

                if len(self.p) > 4096:
                    self.flush_impl()

    def write_part(self, p):
        if p:
            try:
                self.s.buffer.write(self.colorize(p).encode('utf-8'))
            except AttributeError:
                self.s.buffer.write(p)

        self.s.buffer.flush()
        self.s.flush()

    def flush_impl(self):
        self.write_part(self.get_part())

    def flush(self):
        with stdio_lock:
            self.flush_impl()

    def slave(self):
        self.flush()

        return self.s

    def close(self):
        with stdio_lock:
            self.flush_impl()
            self.s.close()

    def fileno(self):
        return self.s.fileno()

    @property
    def encoding(self):
        return self.s.encoding


@y.defer_constructor
def init_stdio():
    y.sys.stdout = ColorStdIO(y.sys.stdout)
    y.sys.stderr = ColorStdIO(y.sys.stderr)

+++++++++++++++++++
stdio_lock = y.threading.Lock()


class StdIO(object):
    def __init__(self, s):
        self.s = s

    def write(self, t):
        with stdio_lock:
            self.s.buffer.write(t.encode('utf-8'))
            self.s.buffer.flush()

    def flush(self):
        with stdio_lock:
            self.s.flush()


@y.singleton
def is_debug():
    return 'debug' in y.config.get('color', '')


class ColorStdIO(object):
    def __init__(self, s):
        self.s = s
        self.p = ''
        self.f = {'strip_colors': not self.isatty()}

    def isatty(self):
        return self.s.isatty()

    def can_colorize(self, t):
        if len(t) > 100000:
            return False

        return not is_debug()

    def colorize_0(self, t):
        #return t
        return y.process_color(t, '', self.f)

    def colorize(self, t):
        if not self.can_colorize(t):
            return t

        try:
            return self.colorize_0(t)
        except IndexError:
            pass

        def iter_lines():
            for l in t.split('\n'):
                try:
                    yield self.colorize_0(l)
                except IndexError:
                    yield l

        return '\n'.join(iter_lines())

    def get_part(self):
        try:
            return self.p
        finally:
            self.p = ''

    def write(self, t):
        if not t:
            return

        with stdio_lock:
            if len(t) > 4096:
                self.flush_impl()
                self.write_part(t)
            else:
                self.p += t

                if len(self.p) > 4096:
                    self.flush_impl()

    def write_part(self, p):
        if p:
            try:
                self.s.buffer.write(self.colorize(p).encode('utf-8'))
            except AttributeError:
                self.s.buffer.write(p)

        self.s.buffer.flush()
        self.s.flush()

    def flush_impl(self):
        self.write_part(self.get_part())

    def flush(self):
        with stdio_lock:
            self.flush_impl()

    def slave(self):
        self.flush()

        return self.s

    def close(self):
        with stdio_lock:
            self.flush_impl()
            self.s.close()

    def fileno(self):
        return self.s.fileno()

    @property
    def encoding(self):
        return self.s.encoding


@y.defer_constructor
def init_stdio():
    y.sys.stdout = ColorStdIO(y.sys.stdout)
    y.sys.stderr = ColorStdIO(y.sys.stderr)

--------------------&/ut/init_log.py
import datetime


def get_log():
    f = y.sys._getframe()

    while 'init_log' in f.f_globals.__name__:
        f = f.f_back

    return f.f_globals.__ylog__()


@y.lookup
def log_lookup(name):
    if name in ('debug', 'info', 'warning', 'error', 'critical', 'exception'):
        def func(msg, *args, **kwargs):
            if not '%' in msg: 
                msg = msg + ' ' + ' '.join(str(x) for x in args)
                args = ()
            elif msg == '%s':
                msg = ' '.join(str(x) for x in args)
                args = ()

            return getattr(get_log(), name)(msg, *args, **kwargs)

        return func

    raise AttributeError()


class ColoredFormatter(y.logging.Formatter):
    def __init__(self, fmt):
        dls = {
            'protocol': '{s}',
            'debug': '{bs}',
            'info': '{g}',
            'verbose': '{b}',
            'warning': '{y}',
            'error': '{r}',
            'critical': '{r}',
        }

        for l in list(dls.keys()):
            dls[l.upper()[0]] = dls[l]

        self.styles = dls
        self.fmt = fmt

    def format(self, record):
        res = self.fmt
        extra = record.__dict__

        if 'status' not in extra:
            extra['status'] = 'none'

        if '_target' in extra:
            extra['target'] = extra.pop('_target')

        colors = {
            'fail': '{br}',
            'done': '{bb}',
            'init': '{by}',
            'fini': '{bc}',
            'none': '{bs}',
        }

        def replace(k, v):
            return res.replace('%(' + k + ')', v)

        def on_levelname(k, l):
            return replace(k, l[:1].upper())

        def on_status(k, s):
            c = colors.get(s, '{bw}')
            f = funcs['on_target']

            funcs['on_target'] = lambda k, v: f(k, v, color=c[2])

            return replace(k, (c + s.upper() + '{}    ')[:10])

        def on_target(k, t, color='b'):
            return res.replace('{target}', '{' + color + '}' + t + '{}')

        funcs = dict((x.__name__, x) for x in (on_levelname, on_status, on_target))

        for k in sorted(extra.keys()):
            res = funcs.get('on_' + k, replace)(k, str(extra[k]))

        return res


def init_logger(log_level='INFO'):
    if 'pip' in y.sys.argv:
        return

    #y.logging.raiseExceptions = False
    old_factory = y.logging.getLogRecordFactory()

    def record_factory(*args, **kwargs):
        record = old_factory(*args, **kwargs)

        try:
            record.thr = str(y.current_coro().thread_id)

            if len(record.thr) == 1:
                record.thr = '0' + record.thr
        except Exception:
            record.thr = '##'

        record.asctime = datetime.datetime.fromtimestamp(int(y.time.time())).strftime('%H:%M:%S')
        record.name = record.name[:10]

        return record

    y.logging.setLogRecordFactory(record_factory)

    fmt = '{w}{g}%(thr){} | {m}%(asctime){} | {br}%(levelname){} | %(status) | {dw}%(msg){}{}'

    class Stream(object):
        def write(self, t):
            y.stderr.write(t)

        def flush(self):
            pass

    @y.lookup
    def lookup(name):
        return {'log_stream': Stream()}[name]

    screen_handler = y.logging.StreamHandler(stream=y.log_stream)
    screen_handler.setLevel(log_level)
    screen_handler.setFormatter(ColoredFormatter(fmt))

    y.logging.root.addHandler(screen_handler)
    y.logging.root.setLevel('DEBUG')

+++++++++++++++++++
import datetime


def get_log():
    f = y.sys._getframe()

    while 'init_log' in f.f_globals.__name__:
        f = f.f_back

    return f.f_globals.__ylog__()


@y.lookup
def log_lookup(name):
    if name in ('debug', 'info', 'warning', 'error', 'critical', 'exception'):
        def func(msg, *args, **kwargs):
            if not '%' in msg: 
                msg = msg + ' ' + ' '.join(str(x) for x in args)
                args = ()
            elif msg == '%s':
                msg = ' '.join(str(x) for x in args)
                args = ()

            return getattr(get_log(), name)(msg, *args, **kwargs)

        return func

    raise AttributeError()


class ColoredFormatter(y.logging.Formatter):
    def __init__(self, fmt):
        dls = {
            'protocol': '{s}',
            'debug': '{bs}',
            'info': '{g}',
            'verbose': '{b}',
            'warning': '{y}',
            'error': '{r}',
            'critical': '{r}',
        }

        for l in list(dls.keys()):
            dls[l.upper()[0]] = dls[l]

        self.styles = dls
        self.fmt = fmt

    def format(self, record):
        res = self.fmt
        extra = record.__dict__

        if 'status' not in extra:
            extra['status'] = 'none'

        if '_target' in extra:
            extra['target'] = extra.pop('_target')

        colors = {
            'fail': '{br}',
            'done': '{bb}',
            'init': '{by}',
            'fini': '{bc}',
            'none': '{bs}',
        }

        def replace(k, v):
            return res.replace('%(' + k + ')', v)

        def on_levelname(k, l):
            return replace(k, l[:1].upper())

        def on_status(k, s):
            c = colors.get(s, '{bw}')
            f = funcs['on_target']

            funcs['on_target'] = lambda k, v: f(k, v, color=c[2])

            return replace(k, (c + s.upper() + '{}    ')[:10])

        def on_target(k, t, color='b'):
            return res.replace('{target}', '{' + color + '}' + t + '{}')

        funcs = dict((x.__name__, x) for x in (on_levelname, on_status, on_target))

        for k in sorted(extra.keys()):
            res = funcs.get('on_' + k, replace)(k, str(extra[k]))

        return res


def init_logger(log_level='INFO'):
    if 'pip' in y.sys.argv:
        return

    #y.logging.raiseExceptions = False
    old_factory = y.logging.getLogRecordFactory()

    def record_factory(*args, **kwargs):
        record = old_factory(*args, **kwargs)

        try:
            record.thr = str(y.current_coro().thread_id)

            if len(record.thr) == 1:
                record.thr = '0' + record.thr
        except Exception:
            record.thr = '##'

        record.asctime = datetime.datetime.fromtimestamp(int(y.time.time())).strftime('%H:%M:%S')
        record.name = record.name[:10]

        return record

    y.logging.setLogRecordFactory(record_factory)

    fmt = '{w}{g}%(thr){} | {m}%(asctime){} | {br}%(levelname){} | %(status) | {dw}%(msg){}{}'

    class Stream(object):
        def write(self, t):
            y.stderr.write(t)

        def flush(self):
            pass

    @y.lookup
    def lookup(name):
        return {'log_stream': Stream()}[name]

    screen_handler = y.logging.StreamHandler(stream=y.log_stream)
    screen_handler.setLevel(log_level)
    screen_handler.setFormatter(ColoredFormatter(fmt))

    y.logging.root.addHandler(screen_handler)
    y.logging.root.setLevel('DEBUG')

--------------------&/ut/mini_db.py
def deep_copy_json(x):
    return y.json.loads(y.json.dumps(x))


def struct_ptr(s):
    return 's:' + y.struct_dump_bytes(s)


def key_struct_ptr(n):
    return struct_ptr(n)[2:12]


def intern_list(l):
    assert None not in l
    return intern_struct({'l': l})


def load_list(ptr):
    return load_struct(ptr)['l']


def intern_struct(s):
    return intern_data({'s': s})


def load_struct(ptr):
    return load_data(ptr)['s']


if 0:
    class A(object):
        def __init__(self):
            self.III = {}
            self.VVV = []

        def intern_data(self, n):
            k = key_struct_ptr(n)

            if k in self.III:
                p = self.III[k]

                assert self.VVV[p][1] == k
            else:
                self.VVV.append((n, k))
                p = len(self.VVV) - 1
                self.III[k] = p

            return self.pointer(p)

        def load_data(self, ptr):
            return self.deref_pointer(ptr)

        def pointer(self, p):
            return self.mangle_pointer(p)

        def hash_key(self, p):
            return self.VVV[self.demangle_pointer(p)][1]

        def mangle_pointer(self, p):
            return 'p:' + str(p)

        def demangle_pointer(self, p):
            assert p[0] == 'p'
            return int(p[2:])

        def deref_pointer(self, v):
            return self.VVV[self.demangle_pointer(v)][0]

        def is_pointer(self, x):
            if str(x)[:2] == 'p:':
                try:
                    return self.demangle_pointer(x)
                except TypeError:
                    pass

        def check_db(self):
            for k, v in self.III.iteritems():
                assert k == self.VVV[v][1]
                assert k == key_struct_ptr(self.VVV[v][0])

            return 'db ok, ncount = ' + str(len(self.III))


if 1:
    class B(object):
        def __init__(self):
            self._v = {}

        def func1(self, data):
            return y.marshal.dumps(data)

        def func2(self, data):
            return y.marshal.loads(data)

        def intern_data(self, n):
            n = self.func1(n)
            k = y.hashlib.md5(n).hexdigest()[:12]
            self._v[k] = n
            return self.pointer(k)

        def load_data(self, k):
            return self.func2(self._v[self.demangle_pointer(k)])

        def pointer(self, p):
            return self.mangle_pointer(p)

        def mangle_pointer(self, p):
            return 'p:' + p

        def demangle_pointer(self, p):
            return p[2:]

        def defer_pointer(self, p):
            return self.load_data(p)

        def is_pointer(self, x):
            if str(x)[:2] == 'p:':
                try:
                    return self.demangle_pointer(x)
                except TypeError:
                    pass

        def hash_key(self, p):
            return self.demangle_pointer(p)[:6]

        def check_db(self):
            for k, v in self._v.iteritems():
                assert k == y.hashlib.md5(v).hexdigest()[:12]

            return 'all ok, count = ' + str(len(self._v))


@y.defer_constructor
def init():
    if y.config.get('adb'):
        v = A()
    else:
        v = B()

    for i in dir(v):
        if not i.startswith('__'):
            globals()[i] = eval('v.' + i)

    if y.config.get('check_db'):
        y.atexit.register(v.check_db)


+++++++++++++++++++
def deep_copy_json(x):
    return y.json.loads(y.json.dumps(x))


def struct_ptr(s):
    return 's:' + y.struct_dump_bytes(s)


def key_struct_ptr(n):
    return struct_ptr(n)[2:12]


def intern_list(l):
    assert None not in l
    return intern_struct({'l': l})


def load_list(ptr):
    return load_struct(ptr)['l']


def intern_struct(s):
    return intern_data({'s': s})


def load_struct(ptr):
    return load_data(ptr)['s']


if 0:
    class A(object):
        def __init__(self):
            self.III = {}
            self.VVV = []

        def intern_data(self, n):
            k = key_struct_ptr(n)

            if k in self.III:
                p = self.III[k]

                assert self.VVV[p][1] == k
            else:
                self.VVV.append((n, k))
                p = len(self.VVV) - 1
                self.III[k] = p

            return self.pointer(p)

        def load_data(self, ptr):
            return self.deref_pointer(ptr)

        def pointer(self, p):
            return self.mangle_pointer(p)

        def hash_key(self, p):
            return self.VVV[self.demangle_pointer(p)][1]

        def mangle_pointer(self, p):
            return 'p:' + str(p)

        def demangle_pointer(self, p):
            assert p[0] == 'p'
            return int(p[2:])

        def deref_pointer(self, v):
            return self.VVV[self.demangle_pointer(v)][0]

        def is_pointer(self, x):
            if str(x)[:2] == 'p:':
                try:
                    return self.demangle_pointer(x)
                except TypeError:
                    pass

        def check_db(self):
            for k, v in self.III.iteritems():
                assert k == self.VVV[v][1]
                assert k == key_struct_ptr(self.VVV[v][0])

            return 'db ok, ncount = ' + str(len(self.III))


if 1:
    class B(object):
        def __init__(self):
            self._v = {}

        def func1(self, data):
            return y.marshal.dumps(data)

        def func2(self, data):
            return y.marshal.loads(data)

        def intern_data(self, n):
            n = self.func1(n)
            k = y.hashlib.md5(n).hexdigest()[:12]
            self._v[k] = n
            return self.pointer(k)

        def load_data(self, k):
            return self.func2(self._v[self.demangle_pointer(k)])

        def pointer(self, p):
            return self.mangle_pointer(p)

        def mangle_pointer(self, p):
            return 'p:' + p

        def demangle_pointer(self, p):
            return p[2:]

        def defer_pointer(self, p):
            return self.load_data(p)

        def is_pointer(self, x):
            if str(x)[:2] == 'p:':
                try:
                    return self.demangle_pointer(x)
                except TypeError:
                    pass

        def hash_key(self, p):
            return self.demangle_pointer(p)[:6]

        def check_db(self):
            for k, v in self._v.iteritems():
                assert k == y.hashlib.md5(v).hexdigest()[:12]

            return 'all ok, count = ' + str(len(self._v))


@y.defer_constructor
def init():
    if y.config.get('adb'):
        v = A()
    else:
        v = B()

    for i in dir(v):
        if not i.startswith('__'):
            globals()[i] = eval('v.' + i)

    if y.config.get('check_db'):
        y.atexit.register(v.check_db)


--------------------&/ut/args_parse.py
import itertools


def check_arg_2(args, p, with_arg=False):
   res = {p: None}

   def flt():
      it = itertools.chain(args)

      for x in it:
         if x == p:
            res[p] = True

            if with_arg:
               for y in it:
                  res[p] = y

                  for z in it:
                     yield z

                  return

            for y in it:
               yield y

            return

         yield x

   return list(flt()), res[p]


def check_arg(args, params):
   old_len = len(args)

   for p in params:
      args, _ = check_arg_2(args, p)

   return args, len(args) != old_len


def parse_args(args):
    args, verbose = check_arg(args, ('-v', '--verbose'))
    args, profile = check_arg(args, ('--profile',))
    args, verbose_mode = check_arg_2(args, '-vm', True)

    if verbose_mode is None:
        args, verbose_mode = check_arg_2(args, '--verbose-mode', True)

    if verbose_mode:
        verbose = verbose_mode
    else:
        if verbose:
            verbose = '1'
        else:
            verbose = ''

    if len(args) < 2:
        args = args + ['help']

    return args, verbose, profile

+++++++++++++++++++
import itertools


def check_arg_2(args, p, with_arg=False):
   res = {p: None}

   def flt():
      it = itertools.chain(args)

      for x in it:
         if x == p:
            res[p] = True

            if with_arg:
               for y in it:
                  res[p] = y

                  for z in it:
                     yield z

                  return

            for y in it:
               yield y

            return

         yield x

   return list(flt()), res[p]


def check_arg(args, params):
   old_len = len(args)

   for p in params:
      args, _ = check_arg_2(args, p)

   return args, len(args) != old_len


def parse_args(args):
    args, verbose = check_arg(args, ('-v', '--verbose'))
    args, profile = check_arg(args, ('--profile',))
    args, verbose_mode = check_arg_2(args, '-vm', True)

    if verbose_mode is None:
        args, verbose_mode = check_arg_2(args, '--verbose-mode', True)

    if verbose_mode:
        verbose = verbose_mode
    else:
        if verbose:
            verbose = '1'
        else:
            verbose = ''

    if len(args) < 2:
        args = args + ['help']

    return args, verbose, profile

--------------------&/ut/algo.py
import hashlib
import json

from marshal import loads, dumps


isf = y.inspect.iscoroutinefunction


def uniq_list_3(l):
    return list(sorted(frozenset(l)))


def uniq_list_2(iter, key):
    visited = set()

    for x in iter:
        p = key(x)

        if p not in visited:
            visited.add(p)

            yield (p, x)


def uniq_list_1(iter, key):
    for p, x in uniq_list_2(iter, key):
        yield x


def uniq_list_0(iter):
    return uniq_list_1(iter, lambda x: x)


def uniq_list_x(iter):
    return list(uniq_list_0(iter))


def to_lines(text):
    def iter_l():
        for l in text.split('\n'):
            l = l.strip()

            if l:
                yield l

    return list(iter_l())


def dc(x):
    try:
        return loads(dumps(x))
    except Exception as e:
        if 'unmarshal' in str(e):
            return y.copy.deepcopy(x)

        raise e


class IncCounter(object):
    def __init__(self):
        self.c = 0
        self.l = y.threading.Lock()

    def __iter__(self):
        while True:
            with self.l:
                begin = self.c
                end = begin + 10000
                self.c = end

            for i in range(begin, end):
                yield i

    def inc_counter(self):
        it = iter(self)

        def func():
            return next(it)

        func()

        return func


@y.singleton
def inc_counter_holder():
    return IncCounter()


def inc_counter():
    return inc_counter_holder().inc_counter()


def compile_func(template, _async, name, mod_name):
    replaces = {
        True: {'[async]': 'async', '[await]': 'await', 'kind': 'async', '[sleep]': 'y.async_loop.sleep'},
        False: {'[async] ': '', '[await] ': '', 'kind': 'sync', '[sleep]': 'y.time.sleep'},
    }

    def subst(t):
        for k, v in replaces[_async].items():
            t = t.replace(k, v)

        return t

    template = subst(template)
    name = subst(name)
    mod_name = subst(mod_name)
    code = y.globals.compile(template, mod_name.replace('.', '/') + '.py', 'exec')
    mod = __yexec__(template, module_name=mod_name)

    return mod[name]


def template_engine(func):
    def gen(_async):
        subst = {
            True: 'async',
            False: 'sync',
        }

        tmpl = func()
        mod_name = func.__module__ + '.' + subst[_async]
        name = func.__name__

        return compile_func(tmpl, _async, name, mod_name)

    select = {
        True: gen(True),
        False: gen(False),
    }

    def wrapper(_async=False):
        return select[_async]

    wrapper.__name__ = func.__name__

    return wrapper


class TOut(object):
    def __init__(self):
        self.tout = 0

    def ok(self):
        self.tout = 0

    def bad(self):
        self.tout = min(self.tout * 1.2 + 0.001, 0.03)

    def current(self):
        if self.tout < 0.01:
            return 0

        return self.tout


@template_engine
def deque_iter():
    return """
[async] def deque_iter(q, sleep=None):
    sleep = sleep or [sleep]
    tout = y.TOut()

    [async] def xsleep(v):
        if v > 0:
            [await] sleep(v)

    while True:
        try:
            yield q.popleft()
            tout.ok()
        except IndexError:
            [await] xsleep(tout.current())
            tout.bad()
"""


deque_iter_sync = deque_iter(_async=False)
deque_iter_async = deque_iter(_async=True)


def modify_list(k, d, f):
    d[k] = f(d.get(k, []))


def append_list(k, d, v):
    modify_list(k, d, lambda l: l + [v])


def prepend_list(k, d, v):
    modify_list(k, d, lambda l: [v] + l)


def ensure_value(k, d, v):
    if k not in d:
        d[k] = v

    return d[k]

+++++++++++++++++++
import hashlib
import json

from marshal import loads, dumps


isf = y.inspect.iscoroutinefunction


def uniq_list_3(l):
    return list(sorted(frozenset(l)))


def uniq_list_2(iter, key):
    visited = set()

    for x in iter:
        p = key(x)

        if p not in visited:
            visited.add(p)

            yield (p, x)


def uniq_list_1(iter, key):
    for p, x in uniq_list_2(iter, key):
        yield x


def uniq_list_0(iter):
    return uniq_list_1(iter, lambda x: x)


def uniq_list_x(iter):
    return list(uniq_list_0(iter))


def to_lines(text):
    def iter_l():
        for l in text.split('\n'):
            l = l.strip()

            if l:
                yield l

    return list(iter_l())


def dc(x):
    try:
        return loads(dumps(x))
    except Exception as e:
        if 'unmarshal' in str(e):
            return y.copy.deepcopy(x)

        raise e


class IncCounter(object):
    def __init__(self):
        self.c = 0
        self.l = y.threading.Lock()

    def __iter__(self):
        while True:
            with self.l:
                begin = self.c
                end = begin + 10000
                self.c = end

            for i in range(begin, end):
                yield i

    def inc_counter(self):
        it = iter(self)

        def func():
            return next(it)

        func()

        return func


@y.singleton
def inc_counter_holder():
    return IncCounter()


def inc_counter():
    return inc_counter_holder().inc_counter()


def compile_func(template, _async, name, mod_name):
    replaces = {
        True: {'[async]': 'async', '[await]': 'await', 'kind': 'async', '[sleep]': 'y.async_loop.sleep'},
        False: {'[async] ': '', '[await] ': '', 'kind': 'sync', '[sleep]': 'y.time.sleep'},
    }

    def subst(t):
        for k, v in replaces[_async].items():
            t = t.replace(k, v)

        return t

    template = subst(template)
    name = subst(name)
    mod_name = subst(mod_name)
    code = y.globals.compile(template, mod_name.replace('.', '/') + '.py', 'exec')
    mod = __yexec__(template, module_name=mod_name)

    return mod[name]


def template_engine(func):
    def gen(_async):
        subst = {
            True: 'async',
            False: 'sync',
        }

        tmpl = func()
        mod_name = func.__module__ + '.' + subst[_async]
        name = func.__name__

        return compile_func(tmpl, _async, name, mod_name)

    select = {
        True: gen(True),
        False: gen(False),
    }

    def wrapper(_async=False):
        return select[_async]

    wrapper.__name__ = func.__name__

    return wrapper


class TOut(object):
    def __init__(self):
        self.tout = 0

    def ok(self):
        self.tout = 0

    def bad(self):
        self.tout = min(self.tout * 1.2 + 0.001, 0.03)

    def current(self):
        if self.tout < 0.01:
            return 0

        return self.tout


@template_engine
def deque_iter():
    return """
[async] def deque_iter(q, sleep=None):
    sleep = sleep or [sleep]
    tout = y.TOut()

    [async] def xsleep(v):
        if v > 0:
            [await] sleep(v)

    while True:
        try:
            yield q.popleft()
            tout.ok()
        except IndexError:
            [await] xsleep(tout.current())
            tout.bad()
"""


deque_iter_sync = deque_iter(_async=False)
deque_iter_async = deque_iter(_async=True)


def modify_list(k, d, f):
    d[k] = f(d.get(k, []))


def append_list(k, d, v):
    modify_list(k, d, lambda l: l + [v])


def prepend_list(k, d, v):
    modify_list(k, d, lambda l: [v] + l)


def ensure_value(k, d, v):
    if k not in d:
        d[k] = v

    return d[k]

--------------------&/&/ut/algo/async.py

async def deque_iter(q, sleep=None):
    sleep = sleep or y.async_loop.sleep
    tout = y.TOut()

    async def xsleep(v):
        if v > 0:
            await sleep(v)

    while True:
        try:
            yield q.popleft()
            tout.ok()
        except IndexError:
            await xsleep(tout.current())
            tout.bad()

+++++++++++++++++++

async def deque_iter(q, sleep=None):
    sleep = sleep or y.async_loop.sleep
    tout = y.TOut()

    async def xsleep(v):
        if v > 0:
            await sleep(v)

    while True:
        try:
            yield q.popleft()
            tout.ok()
        except IndexError:
            await xsleep(tout.current())
            tout.bad()

--------------------&/&/ut/algo/sync.py

def deque_iter(q, sleep=None):
    sleep = sleep or y.time.sleep
    tout = y.TOut()

    def xsleep(v):
        if v > 0:
            sleep(v)

    while True:
        try:
            yield q.popleft()
            tout.ok()
        except IndexError:
            xsleep(tout.current())
            tout.bad()

+++++++++++++++++++

def deque_iter(q, sleep=None):
    sleep = sleep or y.time.sleep
    tout = y.TOut()

    def xsleep(v):
        if v > 0:
            sleep(v)

    while True:
        try:
            yield q.popleft()
            tout.ok()
        except IndexError:
            xsleep(tout.current())
            tout.bad()

--------------------&/ut/at_exit.py
@y.singleton
def at_exit():
    ae = y.collections.deque()

    return ae


def run_at_exit(f):
    at_exit().append(f)

    return f


def run_handlers():
    try:
        while True:
            f = at_exit().pop()
            y.debug('run', f.__module__ + '.' + f.__name__)
            f()
    except IndexError:
        pass

+++++++++++++++++++
@y.singleton
def at_exit():
    ae = y.collections.deque()

    return ae


def run_at_exit(f):
    at_exit().append(f)

    return f


def run_handlers():
    try:
        while True:
            f = at_exit().pop()
            y.debug('run', f.__module__ + '.' + f.__name__)
            f()
    except IndexError:
        pass

--------------------&/ut/err_handle.py
def abort_on_error(func):
    @y.functools.wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except y.StopNow:
            raise
        except StopIteration:
            raise
        except Exception:
            y.os.abort()

    return wrapper


@y.contextlib.contextmanager
def abort_on_error():
    try:
        yield
    finally:
        if not y.exc_info()[0]:
            y.print_all_stacks()
            y.os.abort()


def sync_pack(f):
    try:
        return ([f()], None)
    except StopIteration:
        raise
    except Exception:
        return (None, y.sys.exc_info())


async def async_pack(f):
    try:
        res = await f()

        return ([res], None)
    except Exception:
        return (None, y.sys.exc_info())


def unpack(r):
    res, exc = r

    if res:
        return res[0]

    raise exc[1].with_traceback(exc[2])


def print_stacks():
    while True:
        y.time.sleep(5)
        y.print_all_stacks()


#y.threading.Thread(target=print_stacks).start()

+++++++++++++++++++
def abort_on_error(func):
    @y.functools.wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except y.StopNow:
            raise
        except StopIteration:
            raise
        except Exception:
            y.os.abort()

    return wrapper


@y.contextlib.contextmanager
def abort_on_error():
    try:
        yield
    finally:
        if not y.exc_info()[0]:
            y.print_all_stacks()
            y.os.abort()


def sync_pack(f):
    try:
        return ([f()], None)
    except StopIteration:
        raise
    except Exception:
        return (None, y.sys.exc_info())


async def async_pack(f):
    try:
        res = await f()

        return ([res], None)
    except Exception:
        return (None, y.sys.exc_info())


def unpack(r):
    res, exc = r

    if res:
        return res[0]

    raise exc[1].with_traceback(exc[2])


def print_stacks():
    while True:
        y.time.sleep(5)
        y.print_all_stacks()


#y.threading.Thread(target=print_stacks).start()

--------------------&/ut/caches.py

def default_key(*args, **kwargs):
    return y.struct_dump_bytes([args, kwargs])


def restore_name(f):
    return f.__module__ + '.' + f.__name__


@y.singleton
def common_cache():
    return dict()


def get_copy_func(copy=False):
    if not copy:
        return lambda x: x

    return lambda x: y.dc(x)


tmpl = """
def {holder}({vars}):
    sdb = y.struct_dump_bytes
    cc = y.common_cache()
    stats = dict(h=0, m=0)
    uniq = (y.random.random() * 10000000000000)

    def at_exit():
        if y.config.get('cache_stats'):
            y.xprint_w('{{y}}' + f.__module__ + '.' + f.__name__, '{{w}}->', '{{b}}' + str(stats))

    y.run_at_exit(at_exit)

    def {name}(*args, **kwargs):
        k = sdb([key(*args, **kwargs), uniq])

        if k not in cc:
            stats['m'] +=1
            cc[k] = f(*args, **kwargs) 
        else:
            stats['h'] += 1

        return cf(cc[k])

    return {name}
"""


def simple_cache(f):
    c = {}

    def wrapper(*args):
        key = y.burn(args)

        try:
            return c[key]
        except KeyError:
            c[key] = f(*args)

        return c[key]

    return wrapper


@simple_cache
def get_cache_holder_module(template, name):
    return __yexec__(template, module_name='gn.cachers.' + name)


def get_cache_holder(f, ic=y.inc_counter()):
    if '<lambda>' in f.__name__:
        f.__name__ = '[' + y.inspect.getsource(f).strip() + ']'
        name = 'lambda_' + str(ic())
    else:
        name = f.__name__

    hold_name = 'cache_holder_' + name
    vars = ', '.join(['key', 'f', 'cf'])

    return get_cache_holder_module(tmpl.format(name=name.upper(), vars=vars, holder=hold_name), name)[hold_name]


def cached(f=None, key=default_key, copy=False):
    cf = get_copy_func(copy=copy)

    def functor(f):
        if 'false' in y.config.get('cache', ''):
            print('disable caching')
            return f
            
            try:
                return get_cache_holder(f)(key, f, cf)
            finally:
                y.prompt('/test2')

        return f

    if f:
        return functor(f)

    return functor


def compose_simple(*funcs):
    def wrapper(*args, **kwargs):
        it = y.itertools.chain(funcs)

        for f in it:
            data = f(*args, **kwargs)

            for g in it:
                data = g(data)

            return data

    return wrapper


def compose_lisp(funcs):
    def wrapper(*args, **kwargs):
        f, ff = funcs
        data = f(*args, **kwargs)

        while ff:
            f, ff = ff
            data = f(data)

        return data

    return wrapper


def cached_method1(meth):
    def wrapper(self, *args, **kwargs):
        key = y.burn([meth.__name__, args, kwargs])[2:10]
        d = self.__dict__

        try:
            return d[key]
        except KeyError:
            d[key] = meth(self, *args, **kwargs)

        return d[key]

    return wrapper


def cached_method2(meth):
    return y.cached(key=lambda self, *args: (id(self), args))(meth)


cached_method = cached_method1

+++++++++++++++++++

def default_key(*args, **kwargs):
    return y.struct_dump_bytes([args, kwargs])


def restore_name(f):
    return f.__module__ + '.' + f.__name__


@y.singleton
def common_cache():
    return dict()


def get_copy_func(copy=False):
    if not copy:
        return lambda x: x

    return lambda x: y.dc(x)


tmpl = """
def {holder}({vars}):
    sdb = y.struct_dump_bytes
    cc = y.common_cache()
    stats = dict(h=0, m=0)
    uniq = (y.random.random() * 10000000000000)

    def at_exit():
        if y.config.get('cache_stats'):
            y.xprint_w('{{y}}' + f.__module__ + '.' + f.__name__, '{{w}}->', '{{b}}' + str(stats))

    y.run_at_exit(at_exit)

    def {name}(*args, **kwargs):
        k = sdb([key(*args, **kwargs), uniq])

        if k not in cc:
            stats['m'] +=1
            cc[k] = f(*args, **kwargs) 
        else:
            stats['h'] += 1

        return cf(cc[k])

    return {name}
"""


def simple_cache(f):
    c = {}

    def wrapper(*args):
        key = y.burn(args)

        try:
            return c[key]
        except KeyError:
            c[key] = f(*args)

        return c[key]

    return wrapper


@simple_cache
def get_cache_holder_module(template, name):
    return __yexec__(template, module_name='gn.cachers.' + name)


def get_cache_holder(f, ic=y.inc_counter()):
    if '<lambda>' in f.__name__:
        f.__name__ = '[' + y.inspect.getsource(f).strip() + ']'
        name = 'lambda_' + str(ic())
    else:
        name = f.__name__

    hold_name = 'cache_holder_' + name
    vars = ', '.join(['key', 'f', 'cf'])

    return get_cache_holder_module(tmpl.format(name=name.upper(), vars=vars, holder=hold_name), name)[hold_name]


def cached(f=None, key=default_key, copy=False):
    cf = get_copy_func(copy=copy)

    def functor(f):
        if 'false' in y.config.get('cache', ''):
            print('disable caching')
            return f
            
            try:
                return get_cache_holder(f)(key, f, cf)
            finally:
                y.prompt('/test2')

        return f

    if f:
        return functor(f)

    return functor


def compose_simple(*funcs):
    def wrapper(*args, **kwargs):
        it = y.itertools.chain(funcs)

        for f in it:
            data = f(*args, **kwargs)

            for g in it:
                data = g(data)

            return data

    return wrapper


def compose_lisp(funcs):
    def wrapper(*args, **kwargs):
        f, ff = funcs
        data = f(*args, **kwargs)

        while ff:
            f, ff = ff
            data = f(data)

        return data

    return wrapper


def cached_method1(meth):
    def wrapper(self, *args, **kwargs):
        key = y.burn([meth.__name__, args, kwargs])[2:10]
        d = self.__dict__

        try:
            return d[key]
        except KeyError:
            d[key] = meth(self, *args, **kwargs)

        return d[key]

    return wrapper


def cached_method2(meth):
    return y.cached(key=lambda self, *args: (id(self), args))(meth)


cached_method = cached_method1

--------------------&/ut/pub_sub.py
nt = y.collections.namedtuple
ic = y.inc_counter()


DEFUN = nt('DEFUN', ['f'])
DECORO = nt('DECORO', ['f'])
SKIP = nt('SKIP', [])
DEACT = nt('DEACT', [])
STATEFUL = nt('STATEFUL', [])


@y.cached(key=lambda x: y.burn(x))
def list_to_set(lst):
    return frozenset(lst)


@y.singleton
def is_debug():
    return 'debug' in y.config.get('pubsub', '')


def pretty_dumps(obj):
    cls = y.json.JSONEncoder

    def default(o):
        try:
            o.__json__
        except AttributeError:
            return str(o)

        return o.__json__()

    return cls(default=default, indent=4, sort_keys=True).encode(obj).replace('"', '').replace(',\n', '\n')


def guess_print_data(data):
    if data is None:
        return '[eof]'

    if data.__class__.__name__ == 'ROW':
        return str(data)

    try:
        if 'func' in data:
            return data['func']['gen'] + '-' + data['func']['base']

        if 'name' in data:
            return data['name']
    except TypeError:
        pass

    return str(data)


class ACCEPT(object):
    __slots__ = ('tags')

    def __init__(self, *tags):
        self.tags = frozenset(list_to_set(list(tags)))

    def __str__(self):
        return '(ACCEPT {' + ', '.join(sorted(self.tags)) + '})'

    def __repr__(self):
        return str(self)


class PROVIDES(object):
    __slots__ = ('tags')

    def __init__(self, *tags):
        self.tags = frozenset(list_to_set(list(tags)))

    def __str__(self):
        return '(PROVIDES {' + ', '.join(sorted(self.tags)) + '})'

    def __repr__(self):
        return str(self)


class EOP(object):
    __slots__ = ('extra')

    def __init__(self, *extra):
        self.extra = list(extra)

    def iter_me(self):
        for x in self.extra:
            if cmd_name(x) == 'eop':
                for y in x.iter_me():
                    yield y
            else:
                yield x

    def __str__(self):
        return '(EOP (' + ', '.join([str(x) for x in self.iter_me()]) + '))'


class DATA(object):
    __slots__ = ('tags', 'data')

    def __init__(self, tags=[], data=None):
        self.tags = list_to_set(tags)
        self.data = data

    def __str__(self):
        res = '(DATA {' + ', '.join(sorted(self.tags)) + '}, ' + guess_print_data(self.data) + ')'

        return res.replace('{', '(').replace('}', ')')

    def __repr__(self):
        return str(self)


def ELEM(data):
    return DATA(tags=[], data=data)


def EOS():
    return ELEM(None)


def FIN():
    return y.EOP(y.EOS(), y.DEACT())


class ROW(object):
    __slots__ = ('producer', 'consumers', 'data', 'uid')

    def __init__(self, producer, data):
        self.producer = producer
        self.consumers = {producer}
        self.data = data
        self.uid = ic()

    def __str__(self):
        return str({
            'producer': self.producer,
            'consumers': self.consumers,
            'data': self.data,
            'uid': self.uid,
        })


class FunBase(object):
    def __init__(self, f, parent, n):
        self.p = parent
        self.f = f
        self.accept = []
        self.inqueue = y.collections.deque()
        self.n = n
        self.active_x = True
        self.consumed_rows = 0
        self.produced = 0

    @property
    def __name__(self):
        return self.f.__name__

    @property
    def name(self):
        return self.__name__

    @property
    def active(self):
        return self.active_x

    def new_accept(self, tags):
        is_debug() and y.debug('new accept', self.f.__name__, tags)

        h1 = y.burn(self.accept)

        if self.accept:
            self.accept.append(frozenset(self.accept.pop() | frozenset(tags)))
        else:
            self.accept.append(frozenset(tags))

        h2 = y.burn(self.accept)

        return h1 != h2

    def deactivate(self):
        is_debug() and y.debug('deactivate', str(self))
        self.active_x = False

    @property
    def unconsumed_rows(self):
        return len(self.inqueue)

    def __str__(self):
        return str(self.__json__())

    def __repr__(self):
        return str(self)

    def __json__(self):
        def fmt_accept(a):
            if a:
                return list(a[0])

            return []

        return {
            'name': self.name,
            'accept': fmt_accept(self.accept),
            'inqueue': len(self.inqueue),
            'n': self.n,
            'klass': self.__class__.__name__,
            'active': self.active,
            'consumed': self.consumed_rows,
            'unconsumed': self.unconsumed_rows,
            'produced': self.produced,
        }

    @property
    def iface(self):
        return self.p

    def push(self, el):
        if self.accept_data(el):
            el.consumers.add(self.n)
            self.inqueue.append(el)

            return True

        return False

    def accept_data(self, el):
        if not self.active:
            return False

        if self.n in el.consumers:
            return False

        return True

    def iter_data_full(self):
        while True:
            try:
                yield self.inqueue.popleft()
                self.consumed_rows += 1
            except IndexError:
                return

    def iter_data(self):
        for r in self.iter_data_full():
            yield r.data

    def step_1(self):
        return list(self.step_01())

    def step_01(self):
        for d in self.step_0():
            yield ROW(self.n, d)

    def step(self):
        return self.step_1()


class Iterator(FunBase):
    def __init__(self, f, parent, n):
        FunBase.__init__(self, f, parent, n)
        self.iter = f(self)
        self.stateful = False
        self.provides = frozenset()

    def step_0(self):
        if not self.active:
            return

        def iter_cmd(v):
            if cmd_name(v) == 'eop':
                for x in v.iter_me():
                    yield x

                yield EOP()
            else:
                yield v

        def iter_00():
            while True:
                if self.stateful and not self.inqueue:
                    return

                for u in self.iter:
                    yield u

                if self.stateful:
                    y.os.abort()

                is_debug() and y.debug('rebuild iter for ', self.name)

                self.iter = self.f(self)

        def iter_0():
            for u in iter_00():
                for v in iter_cmd(u):
                    cm = cmd_name(v)

                    if cm == 'eop':
                        return
                    elif cm == 'stateful':
                        self.stateful = True
                    elif cm == 'provides':
                        self.provides = v.tags
                    elif cm == 'data':
                        self.produced += 1

                        if not v.tags:
                            v.tags = self.provides

                        yield v
                    else:
                        yield v

        yield from iter_0()


class Scheduler(Iterator):
    def __init__(self, f, parent, n):
        Iterator.__init__(self, f, parent, n)

    async def step(self):
        is_debug() and y.debug('will call scheduler', str(self))

        if self.active:
            s = self.p.funcs[0]

            for x in self.p.funcs[1:]:
                if x.active:
                    self.inqueue.extend(s.step_1())
                    self.inqueue.extend(x.step_01())

        return []


def kl_name(v):
    return v.__class__.__name__


def cmd_name(v):
    return kl_name(v).lower()


def all_timers():
    return (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 4.0, 8.0, 16.0)


def tout_to_teg(tout):
    return 'TIMER_' + str(int(10 * tout))


def timer(parent):
    timers = []

    yield EOP(ACCEPT())

    for t in all_timers():
        timers.append((t, y.time.time()))

    for t in all_timers():
        yield DATA(['ps:trash'], {'tag': tout_to_teg(t)})

    yield EOP()

    while True:
        yield SKIP()

        tags = []
        now = y.time.time()

        def iter_timers():
            for tout, begin in timers:
                if begin + tout < now:
                    tags.append(tout_to_teg(tout))

                    yield tout, now
                else:
                    yield tout, begin

        timers = list(iter_timers())

        for tag in tags:
            yield DATA([tag], {'now': now})

        yield EOP()


def tresher(iface):
    yield EOP(ACCEPT('ps:trash'))

    for data in iface.iter_data():
        data = data.data

        if 'tag' in data:
            yield ACCEPT(data['tag'])

    yield EOP()


class PubSubLoop(object):
    def __init__(self, ctl=None):
        self.ctl_ = ctl
        self.funcs = []
        self.net = {}
        self.by_name = set()
        self.ext = y.collections.deque()
        self.active_ns = set()

        self.add_fun(self.scheduler_step, Scheduler)
        self.add_fun(self.run_ext_queue)
        self.add_fun(self.unused_row)
        self.add_fun(self.state_checker)

        self.activate('ps')

    @property
    def ctl(self):
        return self.ctl_ or y.async_loop

    def activate(self, ns):
        self.active_ns.add(ns)

    def deactivate(self, ns):
        self.active_ns.remove(ns)

    def is_active_ns(self, ns):
        return ns in self.active_ns

    def run_ext_queue(self, iface):
        yield y.EOP(y.ACCEPT('ps:ext queue'))

        for i in iface.iter_data():
            while self.ext:
                ev = self.ext.pop()

                yield y.EOP(DATA(ev['tags'], ev['data']))


    def add_fun(self, ff, cls=Iterator):
        name = ff.__name__

        if name not in self.by_name:
            self.by_name.add(name)
            self.funcs.append(cls(ff, self, len(self.funcs)))

    def active(self):
        return any(x.active for x in self.funcs)

    def state_checker(self, iface):
        yield EOP(ACCEPT('ps:check state'))

        for row in iface.iter_data():
            if any(f.active for f in self.funcs[iface.n + 1:]):
                break

            for f in self.funcs:
                f.deactivate()

        yield EOP()

    def unused_row(self, iface):
        yield EOP(ACCEPT('ps:unused row'))

        while True:
            for row in iface.iter_data():
                yield row.data.data

            yield EOP()

    async def run(self, init=[], coro=[]):
        for f in init:
            self.add_fun(f)

        for c in coro:
            self.wrap_coro(c)

        async def pub_sub_cycle(ctl):
            while self.active():
                await self.step()

        return await self.ctl.spawn(pub_sub_cycle, 'pub_sub_cycle')

    def scheduler(self):
        return self.funcs[0]

    async def step(self):
        s = self.scheduler()

        await s.step()

    def rebuild_net(self):
        net = y.collections.defaultdict(list)

        for f in self.funcs:
            for a in f.accept:
                for el in a:
                    net[el].append(f)

        #is_debug() and y.debug('rebuild net', pretty_dumps(net))

        self.net = net

    def scheduler_step(self, iface):
        is_debug() and y.debug('scheduler step in')

        extra = []

        def iter_0():
            if self.ext:
                yield ROW(0, DATA(['ps:ext queue'], {}))

            if y.random.random() < 0.1:
                yield ROW(0, DATA(['ps:check state'], {}))

            for row in list(iface.iter_data_full()):
                yield row

            for row in [x for x in extra]:
                yield row

        for row in iter_0():
            f = self.funcs[row.producer]
            c = row.data
            cn = cmd_name(c)

            if cn == 'deact':
                f.deactivate()
            elif cn == 'defun':
                self.add_fun(c.f)
            elif cn == 'decoro':
                self.wrap_coro(c.f)
            elif cn == 'accept':
                if f.new_accept(list_to_set(c.tags)):
                    self.rebuild_net()
            elif cn == 'data':
                is_debug() and y.debug('new data', c)

                used = False

                for tag in row.data.tags:
                    for f in self.net.get(tag, []):
                        if f.push(row):
                            is_debug() and y.debug(f.name, 'accept', row)

                            used = True

                if not used:
                    extra.append(ROW(0, DATA(['ps:unused row'], row)))
            elif cn == 'skip':
                pass
            else:
                y.critical('bad command', cn)
                y.os.abort()

        is_debug() and y.debug('scheduler step out')

        yield EOP()

    def on_ext_event(self, ev):
        self.ext.append(ev)

    def wrap(self, f):
        self.add_fun(f)

        return f

    def wrap_coro(self, c):
        def wrapper_in(iface):
            outqueue = y.collections.deque()

            async def wrapper(ctl):
                async for x in c(ctl, y.deque_iter_async(iface.inqueue, sleep=ctl.sleep)):
                    outqueue.append(x)

            hndl = self.ctl.spawn(wrapper, 'async_' + c.__name__)

            while True:
                try:
                    yield outqueue.popleft()
                except IndexError:
                    yield EOP()

        self.add_fun(y.set_name(wrapper_in, 'sync_' + c.__name__))

        return c

+++++++++++++++++++
nt = y.collections.namedtuple
ic = y.inc_counter()


DEFUN = nt('DEFUN', ['f'])
DECORO = nt('DECORO', ['f'])
SKIP = nt('SKIP', [])
DEACT = nt('DEACT', [])
STATEFUL = nt('STATEFUL', [])


@y.cached(key=lambda x: y.burn(x))
def list_to_set(lst):
    return frozenset(lst)


@y.singleton
def is_debug():
    return 'debug' in y.config.get('pubsub', '')


def pretty_dumps(obj):
    cls = y.json.JSONEncoder

    def default(o):
        try:
            o.__json__
        except AttributeError:
            return str(o)

        return o.__json__()

    return cls(default=default, indent=4, sort_keys=True).encode(obj).replace('"', '').replace(',\n', '\n')


def guess_print_data(data):
    if data is None:
        return '[eof]'

    if data.__class__.__name__ == 'ROW':
        return str(data)

    try:
        if 'func' in data:
            return data['func']['gen'] + '-' + data['func']['base']

        if 'name' in data:
            return data['name']
    except TypeError:
        pass

    return str(data)


class ACCEPT(object):
    __slots__ = ('tags')

    def __init__(self, *tags):
        self.tags = frozenset(list_to_set(list(tags)))

    def __str__(self):
        return '(ACCEPT {' + ', '.join(sorted(self.tags)) + '})'

    def __repr__(self):
        return str(self)


class PROVIDES(object):
    __slots__ = ('tags')

    def __init__(self, *tags):
        self.tags = frozenset(list_to_set(list(tags)))

    def __str__(self):
        return '(PROVIDES {' + ', '.join(sorted(self.tags)) + '})'

    def __repr__(self):
        return str(self)


class EOP(object):
    __slots__ = ('extra')

    def __init__(self, *extra):
        self.extra = list(extra)

    def iter_me(self):
        for x in self.extra:
            if cmd_name(x) == 'eop':
                for y in x.iter_me():
                    yield y
            else:
                yield x

    def __str__(self):
        return '(EOP (' + ', '.join([str(x) for x in self.iter_me()]) + '))'


class DATA(object):
    __slots__ = ('tags', 'data')

    def __init__(self, tags=[], data=None):
        self.tags = list_to_set(tags)
        self.data = data

    def __str__(self):
        res = '(DATA {' + ', '.join(sorted(self.tags)) + '}, ' + guess_print_data(self.data) + ')'

        return res.replace('{', '(').replace('}', ')')

    def __repr__(self):
        return str(self)


def ELEM(data):
    return DATA(tags=[], data=data)


def EOS():
    return ELEM(None)


def FIN():
    return y.EOP(y.EOS(), y.DEACT())


class ROW(object):
    __slots__ = ('producer', 'consumers', 'data', 'uid')

    def __init__(self, producer, data):
        self.producer = producer
        self.consumers = {producer}
        self.data = data
        self.uid = ic()

    def __str__(self):
        return str({
            'producer': self.producer,
            'consumers': self.consumers,
            'data': self.data,
            'uid': self.uid,
        })


class FunBase(object):
    def __init__(self, f, parent, n):
        self.p = parent
        self.f = f
        self.accept = []
        self.inqueue = y.collections.deque()
        self.n = n
        self.active_x = True
        self.consumed_rows = 0
        self.produced = 0

    @property
    def __name__(self):
        return self.f.__name__

    @property
    def name(self):
        return self.__name__

    @property
    def active(self):
        return self.active_x

    def new_accept(self, tags):
        is_debug() and y.debug('new accept', self.f.__name__, tags)

        h1 = y.burn(self.accept)

        if self.accept:
            self.accept.append(frozenset(self.accept.pop() | frozenset(tags)))
        else:
            self.accept.append(frozenset(tags))

        h2 = y.burn(self.accept)

        return h1 != h2

    def deactivate(self):
        is_debug() and y.debug('deactivate', str(self))
        self.active_x = False

    @property
    def unconsumed_rows(self):
        return len(self.inqueue)

    def __str__(self):
        return str(self.__json__())

    def __repr__(self):
        return str(self)

    def __json__(self):
        def fmt_accept(a):
            if a:
                return list(a[0])

            return []

        return {
            'name': self.name,
            'accept': fmt_accept(self.accept),
            'inqueue': len(self.inqueue),
            'n': self.n,
            'klass': self.__class__.__name__,
            'active': self.active,
            'consumed': self.consumed_rows,
            'unconsumed': self.unconsumed_rows,
            'produced': self.produced,
        }

    @property
    def iface(self):
        return self.p

    def push(self, el):
        if self.accept_data(el):
            el.consumers.add(self.n)
            self.inqueue.append(el)

            return True

        return False

    def accept_data(self, el):
        if not self.active:
            return False

        if self.n in el.consumers:
            return False

        return True

    def iter_data_full(self):
        while True:
            try:
                yield self.inqueue.popleft()
                self.consumed_rows += 1
            except IndexError:
                return

    def iter_data(self):
        for r in self.iter_data_full():
            yield r.data

    def step_1(self):
        return list(self.step_01())

    def step_01(self):
        for d in self.step_0():
            yield ROW(self.n, d)

    def step(self):
        return self.step_1()


class Iterator(FunBase):
    def __init__(self, f, parent, n):
        FunBase.__init__(self, f, parent, n)
        self.iter = f(self)
        self.stateful = False
        self.provides = frozenset()

    def step_0(self):
        if not self.active:
            return

        def iter_cmd(v):
            if cmd_name(v) == 'eop':
                for x in v.iter_me():
                    yield x

                yield EOP()
            else:
                yield v

        def iter_00():
            while True:
                if self.stateful and not self.inqueue:
                    return

                for u in self.iter:
                    yield u

                if self.stateful:
                    y.os.abort()

                is_debug() and y.debug('rebuild iter for ', self.name)

                self.iter = self.f(self)

        def iter_0():
            for u in iter_00():
                for v in iter_cmd(u):
                    cm = cmd_name(v)

                    if cm == 'eop':
                        return
                    elif cm == 'stateful':
                        self.stateful = True
                    elif cm == 'provides':
                        self.provides = v.tags
                    elif cm == 'data':
                        self.produced += 1

                        if not v.tags:
                            v.tags = self.provides

                        yield v
                    else:
                        yield v

        yield from iter_0()


class Scheduler(Iterator):
    def __init__(self, f, parent, n):
        Iterator.__init__(self, f, parent, n)

    async def step(self):
        is_debug() and y.debug('will call scheduler', str(self))

        if self.active:
            s = self.p.funcs[0]

            for x in self.p.funcs[1:]:
                if x.active:
                    self.inqueue.extend(s.step_1())
                    self.inqueue.extend(x.step_01())

        return []


def kl_name(v):
    return v.__class__.__name__


def cmd_name(v):
    return kl_name(v).lower()


def all_timers():
    return (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 4.0, 8.0, 16.0)


def tout_to_teg(tout):
    return 'TIMER_' + str(int(10 * tout))


def timer(parent):
    timers = []

    yield EOP(ACCEPT())

    for t in all_timers():
        timers.append((t, y.time.time()))

    for t in all_timers():
        yield DATA(['ps:trash'], {'tag': tout_to_teg(t)})

    yield EOP()

    while True:
        yield SKIP()

        tags = []
        now = y.time.time()

        def iter_timers():
            for tout, begin in timers:
                if begin + tout < now:
                    tags.append(tout_to_teg(tout))

                    yield tout, now
                else:
                    yield tout, begin

        timers = list(iter_timers())

        for tag in tags:
            yield DATA([tag], {'now': now})

        yield EOP()


def tresher(iface):
    yield EOP(ACCEPT('ps:trash'))

    for data in iface.iter_data():
        data = data.data

        if 'tag' in data:
            yield ACCEPT(data['tag'])

    yield EOP()


class PubSubLoop(object):
    def __init__(self, ctl=None):
        self.ctl_ = ctl
        self.funcs = []
        self.net = {}
        self.by_name = set()
        self.ext = y.collections.deque()
        self.active_ns = set()

        self.add_fun(self.scheduler_step, Scheduler)
        self.add_fun(self.run_ext_queue)
        self.add_fun(self.unused_row)
        self.add_fun(self.state_checker)

        self.activate('ps')

    @property
    def ctl(self):
        return self.ctl_ or y.async_loop

    def activate(self, ns):
        self.active_ns.add(ns)

    def deactivate(self, ns):
        self.active_ns.remove(ns)

    def is_active_ns(self, ns):
        return ns in self.active_ns

    def run_ext_queue(self, iface):
        yield y.EOP(y.ACCEPT('ps:ext queue'))

        for i in iface.iter_data():
            while self.ext:
                ev = self.ext.pop()

                yield y.EOP(DATA(ev['tags'], ev['data']))


    def add_fun(self, ff, cls=Iterator):
        name = ff.__name__

        if name not in self.by_name:
            self.by_name.add(name)
            self.funcs.append(cls(ff, self, len(self.funcs)))

    def active(self):
        return any(x.active for x in self.funcs)

    def state_checker(self, iface):
        yield EOP(ACCEPT('ps:check state'))

        for row in iface.iter_data():
            if any(f.active for f in self.funcs[iface.n + 1:]):
                break

            for f in self.funcs:
                f.deactivate()

        yield EOP()

    def unused_row(self, iface):
        yield EOP(ACCEPT('ps:unused row'))

        while True:
            for row in iface.iter_data():
                yield row.data.data

            yield EOP()

    async def run(self, init=[], coro=[]):
        for f in init:
            self.add_fun(f)

        for c in coro:
            self.wrap_coro(c)

        async def pub_sub_cycle(ctl):
            while self.active():
                await self.step()

        return await self.ctl.spawn(pub_sub_cycle, 'pub_sub_cycle')

    def scheduler(self):
        return self.funcs[0]

    async def step(self):
        s = self.scheduler()

        await s.step()

    def rebuild_net(self):
        net = y.collections.defaultdict(list)

        for f in self.funcs:
            for a in f.accept:
                for el in a:
                    net[el].append(f)

        #is_debug() and y.debug('rebuild net', pretty_dumps(net))

        self.net = net

    def scheduler_step(self, iface):
        is_debug() and y.debug('scheduler step in')

        extra = []

        def iter_0():
            if self.ext:
                yield ROW(0, DATA(['ps:ext queue'], {}))

            if y.random.random() < 0.1:
                yield ROW(0, DATA(['ps:check state'], {}))

            for row in list(iface.iter_data_full()):
                yield row

            for row in [x for x in extra]:
                yield row

        for row in iter_0():
            f = self.funcs[row.producer]
            c = row.data
            cn = cmd_name(c)

            if cn == 'deact':
                f.deactivate()
            elif cn == 'defun':
                self.add_fun(c.f)
            elif cn == 'decoro':
                self.wrap_coro(c.f)
            elif cn == 'accept':
                if f.new_accept(list_to_set(c.tags)):
                    self.rebuild_net()
            elif cn == 'data':
                is_debug() and y.debug('new data', c)

                used = False

                for tag in row.data.tags:
                    for f in self.net.get(tag, []):
                        if f.push(row):
                            is_debug() and y.debug(f.name, 'accept', row)

                            used = True

                if not used:
                    extra.append(ROW(0, DATA(['ps:unused row'], row)))
            elif cn == 'skip':
                pass
            else:
                y.critical('bad command', cn)
                y.os.abort()

        is_debug() and y.debug('scheduler step out')

        yield EOP()

    def on_ext_event(self, ev):
        self.ext.append(ev)

    def wrap(self, f):
        self.add_fun(f)

        return f

    def wrap_coro(self, c):
        def wrapper_in(iface):
            outqueue = y.collections.deque()

            async def wrapper(ctl):
                async for x in c(ctl, y.deque_iter_async(iface.inqueue, sleep=ctl.sleep)):
                    outqueue.append(x)

            hndl = self.ctl.spawn(wrapper, 'async_' + c.__name__)

            while True:
                try:
                    yield outqueue.popleft()
                except IndexError:
                    yield EOP()

        self.add_fun(y.set_name(wrapper_in, 'sync_' + c.__name__))

        return c

disable caching
--------------------&/ut/cli.py
@y.singleton
def main_entry_points():
    return {}


def funcs_by_func(f):
    return [k for k in main_entry_points() if f(k)]


def funcs_by_prefix(prefix):
    return funcs_by_func(lambda k: k.startswith(prefix))


def funcs_by_suffix(suffix):
    return funcs_by_func(lambda k: k.endswith(suffix))


def get_entry_point(name):
    if name.startswith('cli_'):
        name = name[4:]

    try:
        return main_entry_points()[name][1]
    except KeyError:
        l = funcs_by_suffix('_' + name)

        if len(l) == 1:
            return main_entry_points()[l[0]][1]

    raise KeyError(name)


def register_entry_point(f):
    vis, func = f
    name = func.__name__

    if name.startswith('cli_'):
        name = name[4:]

    assert '__' not in name

    mep = main_entry_points()

    assert name not in mep

    mep[name] = f

    if '_' in name:
        def it_help(prefix):
            yield '{bg}options:{}'

            for k in funcs_by_prefix(prefix + '_'):
                yield '    {bb}' + k.replace('_', ' ') + '{}'

        async def func(mn, args):
            if args:
                nn = mn + '_' + args[0]

                if nn in mep:
                    return await mep[nn][1](args[1:])
            else:
                print('\n'.join(it_help(mn)), file=y.stderr)

        def register(n, s):
            if not s:
                return

            if n:
                n = n + '_' + s.pop()
            else:
                n = s.pop()

            if n in mep:
                pass
            else:
                ff = lambda args: func(n, args)
                ff.__name__ = n

                mep[n] = ('d', ff)

            register(n, s)

        register('', list(reversed(name.split('_'))))


def main_entry_point(f):
    register_entry_point(('m', f))

    return f


def verbose_entry_point(f):
    register_entry_point(('v', f))

    return f


@y.defer_constructor
def init_1():
    if y.config.get('psy'):
        y.run_at_exit(y.print_stats)


async def run_main(args):
    with y.without_gc(True):
        return await y.get_entry_point(args[1])(args[2:])

+++++++++++++++++++
@y.singleton
def main_entry_points():
    return {}


def funcs_by_func(f):
    return [k for k in main_entry_points() if f(k)]


def funcs_by_prefix(prefix):
    return funcs_by_func(lambda k: k.startswith(prefix))


def funcs_by_suffix(suffix):
    return funcs_by_func(lambda k: k.endswith(suffix))


def get_entry_point(name):
    if name.startswith('cli_'):
        name = name[4:]

    try:
        return main_entry_points()[name][1]
    except KeyError:
        l = funcs_by_suffix('_' + name)

        if len(l) == 1:
            return main_entry_points()[l[0]][1]

    raise KeyError(name)


def register_entry_point(f):
    vis, func = f
    name = func.__name__

    if name.startswith('cli_'):
        name = name[4:]

    assert '__' not in name

    mep = main_entry_points()

    assert name not in mep

    mep[name] = f

    if '_' in name:
        def it_help(prefix):
            yield '{bg}options:{}'

            for k in funcs_by_prefix(prefix + '_'):
                yield '    {bb}' + k.replace('_', ' ') + '{}'

        async def func(mn, args):
            if args:
                nn = mn + '_' + args[0]

                if nn in mep:
                    return await mep[nn][1](args[1:])
            else:
                print('\n'.join(it_help(mn)), file=y.stderr)

        def register(n, s):
            if not s:
                return

            if n:
                n = n + '_' + s.pop()
            else:
                n = s.pop()

            if n in mep:
                pass
            else:
                ff = lambda args: func(n, args)
                ff.__name__ = n

                mep[n] = ('d', ff)

            register(n, s)

        register('', list(reversed(name.split('_'))))


def main_entry_point(f):
    register_entry_point(('m', f))

    return f


def verbose_entry_point(f):
    register_entry_point(('v', f))

    return f


@y.defer_constructor
def init_1():
    if y.config.get('psy'):
        y.run_at_exit(y.print_stats)


async def run_main(args):
    with y.without_gc(True):
        return await y.get_entry_point(args[1])(args[2:])

--------------------&/ut/queues.py
import collections as cc


NOV = '$'


class QQ(object):
    def __init__(self, loop):
        self.l = loop
        self.q = cc.deque()
        self.c = cc.deque()

    def cycle(self):
        while True:
            try:
                c = self.c.popleft()
            except IndexError:
                return

            try:
                v = self.q.popleft()
            except IndexError:
                return self.c.append(c)

            #print 'ZZZZZZZZZZZZZ', c, v
            c(v)

    def pop_0(self, fut):
        def cb(v):
            #print 'XXXXXXXX', fut, v
            fut.set_result(v)

        self.c.append(cb)
        self.cycle()

    async def async_pop(self):
        fut = self.l.create_future(y.set_name(lambda: self.pop_0(fut), 'qq_pop'))
        await fut
        res = fut.result()

        return res

    def push(self, v):
        self.q.append(v)
        self.cycle()


class MTQ(object):
    def __init__(self, *args):
        self.q = y.queue.SimpleQueue()

    def push(self, v):
        self.q.put(v)

    def pop(self):
        return self.q.get()

    async def async_pop(self):
        return self.pop()

    def try_pop(self):
        try:
            return self.q.get_nowait()
        except y.queue.Empty:
            return NOV


class PQ(object):
    def __init__(self, *args):
        self.r, self.w = y.os.pipe()

    def push(self, v):
        y.os.write(self.w, y.struct.pack('I', v))

    async def async_pop(self):
        return self.pop()

    def pop(self):
        return y.struct.unpack('I', y.os.read(self.r, 4))[0]


+++++++++++++++++++
import collections as cc


NOV = '$'


class QQ(object):
    def __init__(self, loop):
        self.l = loop
        self.q = cc.deque()
        self.c = cc.deque()

    def cycle(self):
        while True:
            try:
                c = self.c.popleft()
            except IndexError:
                return

            try:
                v = self.q.popleft()
            except IndexError:
                return self.c.append(c)

            #print 'ZZZZZZZZZZZZZ', c, v
            c(v)

    def pop_0(self, fut):
        def cb(v):
            #print 'XXXXXXXX', fut, v
            fut.set_result(v)

        self.c.append(cb)
        self.cycle()

    async def async_pop(self):
        fut = self.l.create_future(y.set_name(lambda: self.pop_0(fut), 'qq_pop'))
        await fut
        res = fut.result()

        return res

    def push(self, v):
        self.q.append(v)
        self.cycle()


class MTQ(object):
    def __init__(self, *args):
        self.q = y.queue.SimpleQueue()

    def push(self, v):
        self.q.put(v)

    def pop(self):
        return self.q.get()

    async def async_pop(self):
        return self.pop()

    def try_pop(self):
        try:
            return self.q.get_nowait()
        except y.queue.Empty:
            return NOV


class PQ(object):
    def __init__(self, *args):
        self.r, self.w = y.os.pipe()

    def push(self, v):
        y.os.write(self.w, y.struct.pack('I', v))

    async def async_pop(self):
        return self.pop()

    def pop(self):
        return y.struct.unpack('I', y.os.read(self.r, 4))[0]


--------------------&/ya/build.py
@y.lookup
def lookup_pubsub(name):
    return {'pubsub': y.PubSubLoop}[name]()


def gen_unpack_node(pkg):
    mpkg = y.mgr_pkg_mark(pkg)
    vis_name = pkg[4:]

    return {
        'inputs': [y.build_scripts_path(), pkg],
        'output': mpkg,
        'build': [
            '. "$2" && source unpackage $(basename "$3")'
        ],
    }


def print_v3_node(n):
    yield n['output'] + ': ' + ' '.join(n['inputs'])

    for l in n['build']:
        yield '\t' + l


def print_v3_node_2(n):
    yield n['output']

    yield ': '

    for i in n['inputs']:
        yield i
        yield ' '

    yield '\n'

    for l in n['build']:
        yield '\t'
        yield l
        yield '\n'


def do_apply_node(root, by_name):
    node = root['node']
    nnn = node['name']
    cc = node.get('constraint', {})
    pp = y.gen_pkg_path(root)

    def iter_groups():
        yield 'all'

        cur = ''

        for x in (nnn, y.small_repr(cc.get('host', {})), y.small_repr(cc.get('target', {}))):
            cur += '-'
            cur += x

            yield cur[1:]

    for name in iter_groups():
        name = name.replace('_', '-')

        if name in by_name:
            by_name[name].append(pp)
        else:
            by_name[name] = [pp]


def iter_nodes(nodes):
    vn = y.visit_nodes
    rn = y.restore_node

    for n in vn(nodes):
        yield rn(n), n


def gen_unpack_node_for_node(r):
    return y.gen_unpack_node(y.gen_pkg_path(r))


def preprocess(cmd, r):
    yield from cmd
    yield gen_unpack_node_for_node(r)


def reducer(v, by_deps):
    return v

    if len(v) < 2:
        return v

    v = list(sorted(set(v)))
    k = 'r' + y.struct_dump_bytes(v)

    s = by_deps.get(k, {})

    if s:
        s['c'] = s['c'] + 1
    else:
        by_deps[k] = {'c': 1, 'v': v}

    return [k]


def replacer(data):
    def func(s):
        return s.replace('-v4', '-v5' + data[4:7])

    return func


async def build_makefile(nodes, internal=False):
    by_noid = {}

    def iter1():
        for r, n in iter_nodes(nodes):
            by_noid[y.calc_noid_base(r)] = r

            yield r

    def iter2():
        trash = {
            'replacer': lambda x: x,
            'restore_node': lambda x: by_noid[y.calc_noid_base(y.restore_node(x))],
            'extra': 1,
            'reducer': lambda x: x,
        }

        for r in list(iter1()):
            r['trash'] = trash

            yield r

    def iter3():
        for r in list(iter2()):
            yield r, y.struct_dump_bytes(y.print_one_node(r))

    def iter4():
        by_deps = {}
        my_reducer = lambda v: reducer(v, by_deps)

        for r, data in list(iter3()):
            trash = {
                'replacer': replacer(data),
                'restore_node': lambda x: by_noid[y.calc_noid_base(y.restore_node(x))],
                'extra': 3,
                'reducer': my_reducer,
            }

            r['trash'] = trash

            yield r

    def iter5_0():
        by_name = {}

        yield y.build_scripts_run()

        for x in y.iter_workspace():
            yield x

        for r in list(iter4()):
            res = y.print_one_node(r)
            do_apply_node(r, by_name)

            for l in preprocess(res, r):
                yield l

        for name in sorted(by_name.keys()):
            yield {
                'output': name,
                'inputs': sorted(frozenset(by_name[name])),
                'build': [],
            }

    def iter5():
        by_out = {}

        for l in iter5_0():
            k = l['output']
            id = y.burn(l)

            if k in by_out:
                assert by_out[k] == id
            else:
                by_out[k] = id

                yield l

    if internal:
        def iter6():
            for cmd in iter5():
                yield {
                    'deps2': cmd['inputs'],
                    'deps1': [cmd['output']],
                    'cmd': cmd['build'],
                }

        mk = y.MakeFile()
        mk.init_from_parsed({'lst': list(iter6()), 'flags': {}})

        return y.dumps_mk(mk)

    def iter6():
        for cmd in iter5():
            for l in print_v3_node_2(cmd):
                yield l

            if cmd['build']:
                yield '\n\n'

    res = ''

    for v in iter6():
        res += v

    return res

+++++++++++++++++++
@y.lookup
def lookup_pubsub(name):
    return {'pubsub': y.PubSubLoop}[name]()


def gen_unpack_node(pkg):
    mpkg = y.mgr_pkg_mark(pkg)
    vis_name = pkg[4:]

    return {
        'inputs': [y.build_scripts_path(), pkg],
        'output': mpkg,
        'build': [
            '. "$2" && source unpackage $(basename "$3")'
        ],
    }


def print_v3_node(n):
    yield n['output'] + ': ' + ' '.join(n['inputs'])

    for l in n['build']:
        yield '\t' + l


def print_v3_node_2(n):
    yield n['output']

    yield ': '

    for i in n['inputs']:
        yield i
        yield ' '

    yield '\n'

    for l in n['build']:
        yield '\t'
        yield l
        yield '\n'


def do_apply_node(root, by_name):
    node = root['node']
    nnn = node['name']
    cc = node.get('constraint', {})
    pp = y.gen_pkg_path(root)

    def iter_groups():
        yield 'all'

        cur = ''

        for x in (nnn, y.small_repr(cc.get('host', {})), y.small_repr(cc.get('target', {}))):
            cur += '-'
            cur += x

            yield cur[1:]

    for name in iter_groups():
        name = name.replace('_', '-')

        if name in by_name:
            by_name[name].append(pp)
        else:
            by_name[name] = [pp]


def iter_nodes(nodes):
    vn = y.visit_nodes
    rn = y.restore_node

    for n in vn(nodes):
        yield rn(n), n


def gen_unpack_node_for_node(r):
    return y.gen_unpack_node(y.gen_pkg_path(r))


def preprocess(cmd, r):
    yield from cmd
    yield gen_unpack_node_for_node(r)


def reducer(v, by_deps):
    return v

    if len(v) < 2:
        return v

    v = list(sorted(set(v)))
    k = 'r' + y.struct_dump_bytes(v)

    s = by_deps.get(k, {})

    if s:
        s['c'] = s['c'] + 1
    else:
        by_deps[k] = {'c': 1, 'v': v}

    return [k]


def replacer(data):
    def func(s):
        return s.replace('-v4', '-v5' + data[4:7])

    return func


async def build_makefile(nodes, internal=False):
    by_noid = {}

    def iter1():
        for r, n in iter_nodes(nodes):
            by_noid[y.calc_noid_base(r)] = r

            yield r

    def iter2():
        trash = {
            'replacer': lambda x: x,
            'restore_node': lambda x: by_noid[y.calc_noid_base(y.restore_node(x))],
            'extra': 1,
            'reducer': lambda x: x,
        }

        for r in list(iter1()):
            r['trash'] = trash

            yield r

    def iter3():
        for r in list(iter2()):
            yield r, y.struct_dump_bytes(y.print_one_node(r))

    def iter4():
        by_deps = {}
        my_reducer = lambda v: reducer(v, by_deps)

        for r, data in list(iter3()):
            trash = {
                'replacer': replacer(data),
                'restore_node': lambda x: by_noid[y.calc_noid_base(y.restore_node(x))],
                'extra': 3,
                'reducer': my_reducer,
            }

            r['trash'] = trash

            yield r

    def iter5_0():
        by_name = {}

        yield y.build_scripts_run()

        for x in y.iter_workspace():
            yield x

        for r in list(iter4()):
            res = y.print_one_node(r)
            do_apply_node(r, by_name)

            for l in preprocess(res, r):
                yield l

        for name in sorted(by_name.keys()):
            yield {
                'output': name,
                'inputs': sorted(frozenset(by_name[name])),
                'build': [],
            }

    def iter5():
        by_out = {}

        for l in iter5_0():
            k = l['output']
            id = y.burn(l)

            if k in by_out:
                assert by_out[k] == id
            else:
                by_out[k] = id

                yield l

    if internal:
        def iter6():
            for cmd in iter5():
                yield {
                    'deps2': cmd['inputs'],
                    'deps1': [cmd['output']],
                    'cmd': cmd['build'],
                }

        mk = y.MakeFile()
        mk.init_from_parsed({'lst': list(iter6()), 'flags': {}})

        return y.dumps_mk(mk)

    def iter6():
        for cmd in iter5():
            for l in print_v3_node_2(cmd):
                yield l

            if cmd['build']:
                yield '\n\n'

    res = ''

    for v in iter6():
        res += v

    return res

--------------------&/ya/db.py
def visit_nodes(nodes, debug=False):
    s = set()

    def check_hash(k):
        assert k

        kk = y.hash_key(k)

        if kk in s:
            return True

        s.add(kk)

        return False

    def do(k):
        if check_hash(k):
            return

        yield k

        for x in y.restore_node_deps(k):
            for v in do(x):
                yield v

    for x in nodes:
        for z in do(x):
            yield z


@y.cached
def restore_node(ptr):
    res = y.load_list(ptr)

    v = {
        'node': y.load_struct(res[0]),
        'deps': y.load_list(res[1]),
    }

    v['noid'] = y.calc_noid_base(v)

    return v


def restore_node_node(ptr):
    return y.load_struct(y.load_list(ptr)[0])


def restore_node_deps(ptr):
    return y.load_list(y.load_list(ptr)[1])


def store_node(node):
    return y.intern_list([
        y.intern_struct(node['node']),
        y.intern_list(node['deps']),
    ])

+++++++++++++++++++
def visit_nodes(nodes, debug=False):
    s = set()

    def check_hash(k):
        assert k

        kk = y.hash_key(k)

        if kk in s:
            return True

        s.add(kk)

        return False

    def do(k):
        if check_hash(k):
            return

        yield k

        for x in y.restore_node_deps(k):
            for v in do(x):
                yield v

    for x in nodes:
        for z in do(x):
            yield z


@y.cached
def restore_node(ptr):
    res = y.load_list(ptr)

    v = {
        'node': y.load_struct(res[0]),
        'deps': y.load_list(res[1]),
    }

    v['noid'] = y.calc_noid_base(v)

    return v


def restore_node_node(ptr):
    return y.load_struct(y.load_list(ptr)[0])


def restore_node_deps(ptr):
    return y.load_list(y.load_list(ptr)[1])


def store_node(node):
    return y.intern_list([
        y.intern_struct(node['node']),
        y.intern_list(node['deps']),
    ])

disable caching
--------------------&/ya/cli_make.py
@y.main_entry_point
async def cli_pkg_make(arg):
    p = y.argparse.ArgumentParser()

    p.add_argument('-j', '--threads', default=1, action='store', help='set num threads')
    p.add_argument('-f', '--path', default='gen', action='store', help='path to Makefile, "-" - read from stdin, "gen" - generate on the fly')
    p.add_argument('-r', '--root', default=None, action='store', help='main root for build files')
    p.add_argument('-i', '--install-dir', default=None, action='store', help='where to install packages')
    p.add_argument('-d', '--do-not-remove', default=None, action='store', help='  ')
    p.add_argument('-s', '--shell', default=None, action='store', help='   ')
    p.add_argument('--production', default=False, action='store_const', const=True, help='production execution')
    p.add_argument('--curses', default=False, action='store_const', const=True, help='use curses gui')
    p.add_argument('--proxy', default=False, action='store_const', const=True, help='serve as as a stream proxy')
    p.add_argument('targets', nargs=y.argparse.REMAINDER)

    args = p.parse_args(arg)
    local = not args.production

    if local and args.install_dir:
        raise Exception('do not do this, kids, at home')

    def calc_root():
        if args.root:
            return args.root

        with y.open_pdb() as db:
            if 'build_prefix' in db.kv:
                return db.kv['build_prefix']

        if local:
            return y.upm_root()

        if args.production:
            return '/d'

        raise Exception('can not determine root')

    root = calc_root()

    def iter_replaces():
        if args.install_dir:
            yield ('$PD', args.install_dir)

        yield ('$MD', '$PREFIX/m')
        yield ('$RD', '$PREFIX/r')
        yield ('$WD', '$PREFIX/w')
        yield ('$SD', '$PREFIX/s')

        if local:
            yield ('$PD', '$PREFIX/p')

        if args.production:
            yield ('$PD', '/private')

        yield ('$PREFIX', root)
        yield ('$UPM', y.globals.script_path)

        if args.shell:
            yield ('$YSHELL', args.shell)

    shell_vars = dict(iter_replaces())

    async def gen():
        mk = await y.main_makefile(y.iter_cc, internal=True)

        return y.loads_mk(mk)

    mk = await y.open_mk_file(args.path, gen)

    if int(args.threads):
        if not args.targets:
            args.targets = ['all']

        args.pre_run = ['workspace']
        args.shell_vars = shell_vars

        return await mk.build(args)

    return 0

+++++++++++++++++++
@y.main_entry_point
async def cli_pkg_make(arg):
    p = y.argparse.ArgumentParser()

    p.add_argument('-j', '--threads', default=1, action='store', help='set num threads')
    p.add_argument('-f', '--path', default='gen', action='store', help='path to Makefile, "-" - read from stdin, "gen" - generate on the fly')
    p.add_argument('-r', '--root', default=None, action='store', help='main root for build files')
    p.add_argument('-i', '--install-dir', default=None, action='store', help='where to install packages')
    p.add_argument('-d', '--do-not-remove', default=None, action='store', help='  ')
    p.add_argument('-s', '--shell', default=None, action='store', help='   ')
    p.add_argument('--production', default=False, action='store_const', const=True, help='production execution')
    p.add_argument('--curses', default=False, action='store_const', const=True, help='use curses gui')
    p.add_argument('--proxy', default=False, action='store_const', const=True, help='serve as as a stream proxy')
    p.add_argument('targets', nargs=y.argparse.REMAINDER)

    args = p.parse_args(arg)
    local = not args.production

    if local and args.install_dir:
        raise Exception('do not do this, kids, at home')

    def calc_root():
        if args.root:
            return args.root

        with y.open_pdb() as db:
            if 'build_prefix' in db.kv:
                return db.kv['build_prefix']

        if local:
            return y.upm_root()

        if args.production:
            return '/d'

        raise Exception('can not determine root')

    root = calc_root()

    def iter_replaces():
        if args.install_dir:
            yield ('$PD', args.install_dir)

        yield ('$MD', '$PREFIX/m')
        yield ('$RD', '$PREFIX/r')
        yield ('$WD', '$PREFIX/w')
        yield ('$SD', '$PREFIX/s')

        if local:
            yield ('$PD', '$PREFIX/p')

        if args.production:
            yield ('$PD', '/private')

        yield ('$PREFIX', root)
        yield ('$UPM', y.globals.script_path)

        if args.shell:
            yield ('$YSHELL', args.shell)

    shell_vars = dict(iter_replaces())

    async def gen():
        mk = await y.main_makefile(y.iter_cc, internal=True)

        return y.loads_mk(mk)

    mk = await y.open_mk_file(args.path, gen)

    if int(args.threads):
        if not args.targets:
            args.targets = ['all']

        args.pre_run = ['workspace']
        args.shell_vars = shell_vars

        return await mk.build(args)

    return 0

--------------------&/ya/cli_prune.py
def iter_non_trivial_clusters(data, keyf):
    dd = y.collections.defaultdict(list)

    for x in data:
        dd[keyf(x)].append(x)

    def iter_0():
        for v in dd.values():
            if len(v) > 1:
                yield v

    return list(iter_0())


def fix_absolute_symlinks(d):
    y.info('fix absolute symlinks in', d)

    def iter_links():
        for a, b, c in y.os.walk(d):
            for x in c:
                p = y.os.path.join(a, x)

                if y.os.path.islink(p):
                    pp = y.os.readlink(p)

                    if pp[0] == '/':
                        yield p, pp

    for p, pp in list(iter_links()):
        y.info('relink', p, pp)
        y.os.unlink(p)
        y.os.link(pp, p)


def prune_dir(d):
    y.info('prune', d)

    def iter_files():
        for a, b, c in y.os.walk(d):
            for x in c:
                p = y.os.path.join(a, x)

                if y.os.path.islink(p):
                    continue

                yield p

    def smart_getsize(p):
        res = y.os.path.getsize(p)

        if res < 100:
            res += y.random.random()

        return res

    files = list(iter_files())
    by_size = iter_non_trivial_clusters(files, smart_getsize)

    def path_md5(p):
        with open(p, 'rb') as f:
            return y.hashlib.md5(f.read()).hexdigest()

    def iter_clusters():
        for c in by_size:
            yield from iter_non_trivial_clusters(c, path_md5)

    clusters = list(iter_clusters())

    y.os.chdir(d)

    for c in clusters:
        c = sorted(c, key=lambda x: (len(x), x))
        fr = c[0][len(d) + 1:]

        for to in c[1:]:
            to = to[len(d) + 1:]

            y.info(fr, '->', to)

            y.os.unlink(to)
            y.os.symlink('../' * to.count('/') + fr, to)


@y.main_entry_point
async def cli_cmd_prune(args):
    for a in args:
        fix_absolute_symlinks(a)
        prune_dir(a)

+++++++++++++++++++
def iter_non_trivial_clusters(data, keyf):
    dd = y.collections.defaultdict(list)

    for x in data:
        dd[keyf(x)].append(x)

    def iter_0():
        for v in dd.values():
            if len(v) > 1:
                yield v

    return list(iter_0())


def fix_absolute_symlinks(d):
    y.info('fix absolute symlinks in', d)

    def iter_links():
        for a, b, c in y.os.walk(d):
            for x in c:
                p = y.os.path.join(a, x)

                if y.os.path.islink(p):
                    pp = y.os.readlink(p)

                    if pp[0] == '/':
                        yield p, pp

    for p, pp in list(iter_links()):
        y.info('relink', p, pp)
        y.os.unlink(p)
        y.os.link(pp, p)


def prune_dir(d):
    y.info('prune', d)

    def iter_files():
        for a, b, c in y.os.walk(d):
            for x in c:
                p = y.os.path.join(a, x)

                if y.os.path.islink(p):
                    continue

                yield p

    def smart_getsize(p):
        res = y.os.path.getsize(p)

        if res < 100:
            res += y.random.random()

        return res

    files = list(iter_files())
    by_size = iter_non_trivial_clusters(files, smart_getsize)

    def path_md5(p):
        with open(p, 'rb') as f:
            return y.hashlib.md5(f.read()).hexdigest()

    def iter_clusters():
        for c in by_size:
            yield from iter_non_trivial_clusters(c, path_md5)

    clusters = list(iter_clusters())

    y.os.chdir(d)

    for c in clusters:
        c = sorted(c, key=lambda x: (len(x), x))
        fr = c[0][len(d) + 1:]

        for to in c[1:]:
            to = to[len(d) + 1:]

            y.info(fr, '->', to)

            y.os.unlink(to)
            y.os.symlink('../' * to.count('/') + fr, to)


@y.main_entry_point
async def cli_cmd_prune(args):
    for a in args:
        fix_absolute_symlinks(a)
        prune_dir(a)

--------------------&/ya/tc_system.py
@y.singleton
def find_system_tools():
    def iter_candidates():
        yield 'clang', {'kind': ['c'], 'type': 'clang'}
        yield 'clang++', {'kind': ['c++'], 'type': 'clang'}
        yield 'ld.lld', {'kind': ['linker'], 'type': 'lld', 'os': 'linux'}
        yield 'ld64.lld', {'kind': ['linker'], 'type': 'lld', 'os': 'darwin'}
        yield 'lld-link', {'kind': ['linker'], 'type': 'lld', 'os': 'windows'}
        yield 'wasm-ld', {'kind': ['linker'], 'type': 'lld', 'os': 'webasm'}

    def find():
        def find_cand():
            for tool, info in iter_candidates():
                for tp in y.find_tool(tool):
                    if tp:
                        y.info('find tool', tp, info)

                        yield tp, info

        for tp, info in find_cand():
            if info['type'] == 'clang':
                if not y.os.path.isfile(y.os.path.dirname(tp) + '/llvm-ar'):
                    y.info('skip', tp, 'cause not full tool chain')
                    continue

            try:
                data = y.subprocess.check_output([tp, '--version'], stderr=y.subprocess.STDOUT, shell=False)
            except Exception as e:
                data = str(e)

            info.update({'name': y.os.path.basename(tp), 'path': tp, 'data': data})

            yield info

    return list(find())


def parse_gcc(info):
    if 'clang' in info['data']:
        yield from parse_clang(info)

        return

    raise Exception('todo')


def parse_clang_info(data):
    lines = data.strip().split('\n')
    info = {}
    info['version'] = lines[0].split(' ')[3]

    for l in lines:
        l = l.strip()

        if not l:
            continue

        if not l.startswith('Target'):
            continue

        k, v = l.split(':')

        if k != 'Target':
            continue

        a, b, *_ = v.strip().split('-')

        info['target'] = {
            'arch': a,
            'os': {'apple': 'darwin'}.get(b, y.platform.system().lower()),
        }

    return info


def filter_by_os(it, info):
    if 'os' in info:
        ios = info['os']

        for x in it:
            if x['os'] == ios:
                yield x
    else:
        yield from it


def parse_clang(info):
    host = y.current_host_platform()
    extra = parse_clang_info(info['data'])
    path = info['path']

    for t in filter_by_os(y.iter_all_targets(), info):
        c = {}

        cc = {
            'host': host,
            'target': t,
        }

        is_cross_c = y.is_cross(cc)

        c['constraint'] = cc
        c['version'] = extra['version']
        c['build'] = []

        tg = t['arch'] + '-' + t['os']

        def iter_kind():
            for k in info['kind']:
                yield k

                if k in ('c', 'c++') and not is_cross_c:
                    yield 'linker'

        def iter_nodes():
            where = y.os.path.dirname(path)

            for k in iter_kind():
                meta = {'kind': [k, 'tool']}

                if k == 'c':
                    meta['provides'] = [
                        {'env': 'CC', 'value': '"' + path + '"'},
                        {'env': 'CFLAGS', 'value': '"-nostdinc $CFLAGS"'.replace('{tg}', tg)},
                        {'env': 'AR', 'value': '"' + where + '/llvm-ar' + '"'},
                        {'env': 'RANLIB', 'value': '"' + where + '/llvm-ranlib' + '"'},
                        {'env': 'STRIP', 'value': '"' + where + '/llvm-strip' + '"'},
                        {'env': 'NM', 'value': '"' + where + '/llvm-nm' + '"'},
                    ]
                elif k == 'c++':
                    meta['provides'] = [
                        {'env': 'CXX', 'value': '"' + path + '"'},
                        {'env': 'CFLAGS', 'value': '"-nostdinc $CFLAGS"'.replace('{tg}', tg)},
                        {'env': 'CXXFLAGS', 'value': '"-nostdinc++ $CXXFLAGS"'},
                    ]
                elif k == 'linker':
                    meta['provides'] = [
                        {'env': 'LD', 'value': '"' + path + '"'},
                        {'env': 'LDFLAGS', 'value': '"-nostdlib -static -all-static $LDFLAGS"'},
                    ]

                n = y.dc(c)

                n['name'] = info['name']
                n['meta'] = meta

                yield n

        for n in iter_nodes():
            yield {
                'node': n,
                'deps': [],
            }


@y.singleton
def iter_darwin():
    def iter_nodes():
        for k in ('c', 'c++', 'linker'):
            meta = {'kind': [k, 'tool']}
            path = '/usr/bin/clang'

            if k == 'c':
                meta['provides'] = [
                    {'env': 'CC', 'value': '"' + path + '"'},
                    {'env': 'CFLAGS', 'value': '"$CFLAGS"'},
                    {'env': 'AR', 'value': '"ar"'},
                    {'env': 'RANLIB', 'value': '"ranlib"'},
                    {'env': 'STRIP', 'value': '"strip"'},
                    {'env': 'NM', 'value': '"nm"'},
                ]
            elif k == 'c++':
                meta['provides'] = [
                    {'env': 'CXX', 'value': '"' + path + '"'},
                ]
            elif k == 'linker':
                meta['provides'] = [
                    {'env': 'LD', 'value': '"' + path + '"'},
                ]

            yield meta

    def do_iter():
        for meta in iter_nodes():
            n = {
                'name': '-'.join(['clang'] + meta['kind']),
                'build': [],
                'version': y.burn(meta),
                'meta': meta,
                'constraint': {
                    'host': y.current_host_platform(),
                    'target': y.current_host_platform(),
                },
            }

            yield {
                'node': n,
                'deps': [],
            }

    return list(do_iter())


def parse_lld(info):
    path = info['path']
    host = y.current_host_platform()

    for t in filter_by_os(y.iter_all_targets(), info):
        c = {}

        c['constraint'] = {
            'host': host,
            'target': t,
        }

        opts = extra + [
            '-fuse-ld=lld',
            '-nostdlib',
            '-static',
            '-all-static',
            '-Wl,--no-whole-archive',
            '-Wl,--sort-section,alignment',
            '-Wl,--sort-common',
            '-Wl,--gc-sections',
            '-Wl,--hash-style=both',
            '-Wl,--exclude-libs=ALL',
            '-Wl,--no-dynamic-linker',
            '-Wl,--no-export-dynamic',
        ]

        c['build'] = []
        c['name'] = 'lld'
        c['version'] = y.burn(info)
        c['meta'] = {
            'kind': ['linker', 'tool'],
            'provides': [
                {'env': 'LD', 'value': '"' + path + '"'},
                {'env': 'LDFLAGS', 'value': '"{opts} $LDFLAGS"'.replace('{opts}', ' '.join(opts))}
            ],
        }

        yield {
            'node': c,
            'deps': [],
        }


def iter_system_tools():
    yield from iter_darwin()

    return

    for c in y.dc(iter_darwin()):
        try:
            c['data'] = c['data'].decode('utf-8')
        except AttributeError:
            pass

        if c['type'] == 'clang':
            yield from parse_clang(c)
        elif c['type'] == 'gcc':
            yield from parse_gcc(c)
        elif c['type'] == 'lld':
            yield from parse_lld(c)
        else:
            y.os.abort()

+++++++++++++++++++
@y.singleton
def find_system_tools():
    def iter_candidates():
        yield 'clang', {'kind': ['c'], 'type': 'clang'}
        yield 'clang++', {'kind': ['c++'], 'type': 'clang'}
        yield 'ld.lld', {'kind': ['linker'], 'type': 'lld', 'os': 'linux'}
        yield 'ld64.lld', {'kind': ['linker'], 'type': 'lld', 'os': 'darwin'}
        yield 'lld-link', {'kind': ['linker'], 'type': 'lld', 'os': 'windows'}
        yield 'wasm-ld', {'kind': ['linker'], 'type': 'lld', 'os': 'webasm'}

    def find():
        def find_cand():
            for tool, info in iter_candidates():
                for tp in y.find_tool(tool):
                    if tp:
                        y.info('find tool', tp, info)

                        yield tp, info

        for tp, info in find_cand():
            if info['type'] == 'clang':
                if not y.os.path.isfile(y.os.path.dirname(tp) + '/llvm-ar'):
                    y.info('skip', tp, 'cause not full tool chain')
                    continue

            try:
                data = y.subprocess.check_output([tp, '--version'], stderr=y.subprocess.STDOUT, shell=False)
            except Exception as e:
                data = str(e)

            info.update({'name': y.os.path.basename(tp), 'path': tp, 'data': data})

            yield info

    return list(find())


def parse_gcc(info):
    if 'clang' in info['data']:
        yield from parse_clang(info)

        return

    raise Exception('todo')


def parse_clang_info(data):
    lines = data.strip().split('\n')
    info = {}
    info['version'] = lines[0].split(' ')[3]

    for l in lines:
        l = l.strip()

        if not l:
            continue

        if not l.startswith('Target'):
            continue

        k, v = l.split(':')

        if k != 'Target':
            continue

        a, b, *_ = v.strip().split('-')

        info['target'] = {
            'arch': a,
            'os': {'apple': 'darwin'}.get(b, y.platform.system().lower()),
        }

    return info


def filter_by_os(it, info):
    if 'os' in info:
        ios = info['os']

        for x in it:
            if x['os'] == ios:
                yield x
    else:
        yield from it


def parse_clang(info):
    host = y.current_host_platform()
    extra = parse_clang_info(info['data'])
    path = info['path']

    for t in filter_by_os(y.iter_all_targets(), info):
        c = {}

        cc = {
            'host': host,
            'target': t,
        }

        is_cross_c = y.is_cross(cc)

        c['constraint'] = cc
        c['version'] = extra['version']
        c['build'] = []

        tg = t['arch'] + '-' + t['os']

        def iter_kind():
            for k in info['kind']:
                yield k

                if k in ('c', 'c++') and not is_cross_c:
                    yield 'linker'

        def iter_nodes():
            where = y.os.path.dirname(path)

            for k in iter_kind():
                meta = {'kind': [k, 'tool']}

                if k == 'c':
                    meta['provides'] = [
                        {'env': 'CC', 'value': '"' + path + '"'},
                        {'env': 'CFLAGS', 'value': '"-nostdinc $CFLAGS"'.replace('{tg}', tg)},
                        {'env': 'AR', 'value': '"' + where + '/llvm-ar' + '"'},
                        {'env': 'RANLIB', 'value': '"' + where + '/llvm-ranlib' + '"'},
                        {'env': 'STRIP', 'value': '"' + where + '/llvm-strip' + '"'},
                        {'env': 'NM', 'value': '"' + where + '/llvm-nm' + '"'},
                    ]
                elif k == 'c++':
                    meta['provides'] = [
                        {'env': 'CXX', 'value': '"' + path + '"'},
                        {'env': 'CFLAGS', 'value': '"-nostdinc $CFLAGS"'.replace('{tg}', tg)},
                        {'env': 'CXXFLAGS', 'value': '"-nostdinc++ $CXXFLAGS"'},
                    ]
                elif k == 'linker':
                    meta['provides'] = [
                        {'env': 'LD', 'value': '"' + path + '"'},
                        {'env': 'LDFLAGS', 'value': '"-nostdlib -static -all-static $LDFLAGS"'},
                    ]

                n = y.dc(c)

                n['name'] = info['name']
                n['meta'] = meta

                yield n

        for n in iter_nodes():
            yield {
                'node': n,
                'deps': [],
            }


@y.singleton
def iter_darwin():
    def iter_nodes():
        for k in ('c', 'c++', 'linker'):
            meta = {'kind': [k, 'tool']}
            path = '/usr/bin/clang'

            if k == 'c':
                meta['provides'] = [
                    {'env': 'CC', 'value': '"' + path + '"'},
                    {'env': 'CFLAGS', 'value': '"$CFLAGS"'},
                    {'env': 'AR', 'value': '"ar"'},
                    {'env': 'RANLIB', 'value': '"ranlib"'},
                    {'env': 'STRIP', 'value': '"strip"'},
                    {'env': 'NM', 'value': '"nm"'},
                ]
            elif k == 'c++':
                meta['provides'] = [
                    {'env': 'CXX', 'value': '"' + path + '"'},
                ]
            elif k == 'linker':
                meta['provides'] = [
                    {'env': 'LD', 'value': '"' + path + '"'},
                ]

            yield meta

    def do_iter():
        for meta in iter_nodes():
            n = {
                'name': '-'.join(['clang'] + meta['kind']),
                'build': [],
                'version': y.burn(meta),
                'meta': meta,
                'constraint': {
                    'host': y.current_host_platform(),
                    'target': y.current_host_platform(),
                },
            }

            yield {
                'node': n,
                'deps': [],
            }

    return list(do_iter())


def parse_lld(info):
    path = info['path']
    host = y.current_host_platform()

    for t in filter_by_os(y.iter_all_targets(), info):
        c = {}

        c['constraint'] = {
            'host': host,
            'target': t,
        }

        opts = extra + [
            '-fuse-ld=lld',
            '-nostdlib',
            '-static',
            '-all-static',
            '-Wl,--no-whole-archive',
            '-Wl,--sort-section,alignment',
            '-Wl,--sort-common',
            '-Wl,--gc-sections',
            '-Wl,--hash-style=both',
            '-Wl,--exclude-libs=ALL',
            '-Wl,--no-dynamic-linker',
            '-Wl,--no-export-dynamic',
        ]

        c['build'] = []
        c['name'] = 'lld'
        c['version'] = y.burn(info)
        c['meta'] = {
            'kind': ['linker', 'tool'],
            'provides': [
                {'env': 'LD', 'value': '"' + path + '"'},
                {'env': 'LDFLAGS', 'value': '"{opts} $LDFLAGS"'.replace('{opts}', ' '.join(opts))}
            ],
        }

        yield {
            'node': c,
            'deps': [],
        }


def iter_system_tools():
    yield from iter_darwin()

    return

    for c in y.dc(iter_darwin()):
        try:
            c['data'] = c['data'].decode('utf-8')
        except AttributeError:
            pass

        if c['type'] == 'clang':
            yield from parse_clang(c)
        elif c['type'] == 'gcc':
            yield from parse_gcc(c)
        elif c['type'] == 'lld':
            yield from parse_lld(c)
        else:
            y.os.abort()

--------------------&/ya/cli_cmd.py
@y.main_entry_point
async def cli_cmd_subst(args):
    assert len(args) == 3

    with open(args[0], 'r') as f:
        data = f.read()

    data = data.replace(args[1], args[2])

    with open(args[0] + '.tmp', 'w') as f:
        f.write(data)

    y.os.rename(args[0] + '.tmp', args[0])

+++++++++++++++++++
@y.main_entry_point
async def cli_cmd_subst(args):
    assert len(args) == 3

    with open(args[0], 'r') as f:
        data = f.read()

    data = data.replace(args[1], args[2])

    with open(args[0] + '.tmp', 'w') as f:
        f.write(data)

    y.os.rename(args[0] + '.tmp', args[0])

--------------------&/ya/apply_rules.py
def gen_fetch_cmd(url):
    fname = y.calc_pkg_full_name(url)
    cache = '$SD/' + fname

    return {
        'inputs': [],
        'output': cache,
        'build': [
            'PYTHONHOME= $SD/upm cmd fetch "' + url + '" "' + cache + '"'
        ],
    }


def apply_fetch(lines, v):
    for l in lines:
        if 'source fetch ' in l:
            parts = l.split('"')

            assert len(parts) == 3

            url = parts[1]
            bn = gen_fetch_cmd(url)
            vn = v['node']

            y.prepend_list('extra_cmd', vn, bn)
            y.prepend_list('urls', vn, url)

            yield y.prepare_untar_for_mf(bn['output'], strip=int(parts[2].strip()))
        else:
            yield l


def fix_v2(v, **kwargs):
    assert v is not None

    v = y.dc(v)
    n = v['node']

    m = y.ensure_value('meta', n, {})
    f = y.ensure_value('flags', m, [])

    m['flags'] = sorted(frozenset(f + n.pop('flags', [])))

    kind = y.ensure_value('kind', m, []) + n.pop('kind', [])
    m['kind'] = kind

    if 'box' in kind:
        kind.append('tool')

    if 'provides' in m and any(('lib' in x) for x in m['provides']):
        kind.append('library')

    m['kind'] = sorted(frozenset(kind))
    f = m['flags']

    if 'codec' in n:
        pass
    else:
        n['codec'] = kwargs.get('codec', 'gz')

    if 'naked' in kwargs:
        n['naked'] = kwargs['naked']

    if 'url' in n:
        if 'pkg_full_name' not in n:
            n['pkg_full_name'] = y.calc_pkg_full_name(n['url'])

    def iter_subst():
        for i, v in enumerate(n.get('extra', [])):
            if v['kind'] == 'file':
                cmd = 'echo "' + y.base64.b64encode(v['data'].encode('utf-8')).decode('utf-8') + '" | (base64 -D -i - -o - || base64 -d) > ' + v['path']
                key = '$(APPLY_EXTRA_PLAN_' + str(i) + ')'

                yield (key, cmd)

            if v['kind'] == 'subst':
                yield (v['from'], v['to'])

    subst = list(iter_subst())

    for p in ('build', 'prepare'):
        if p in n:
            n[p] = [y.subst_kv_base(l, subst) for l in apply_fetch(n[p], v)]

    return v

+++++++++++++++++++
def gen_fetch_cmd(url):
    fname = y.calc_pkg_full_name(url)
    cache = '$SD/' + fname

    return {
        'inputs': [],
        'output': cache,
        'build': [
            'PYTHONHOME= $SD/upm cmd fetch "' + url + '" "' + cache + '"'
        ],
    }


def apply_fetch(lines, v):
    for l in lines:
        if 'source fetch ' in l:
            parts = l.split('"')

            assert len(parts) == 3

            url = parts[1]
            bn = gen_fetch_cmd(url)
            vn = v['node']

            y.prepend_list('extra_cmd', vn, bn)
            y.prepend_list('urls', vn, url)

            yield y.prepare_untar_for_mf(bn['output'], strip=int(parts[2].strip()))
        else:
            yield l


def fix_v2(v, **kwargs):
    assert v is not None

    v = y.dc(v)
    n = v['node']

    m = y.ensure_value('meta', n, {})
    f = y.ensure_value('flags', m, [])

    m['flags'] = sorted(frozenset(f + n.pop('flags', [])))

    kind = y.ensure_value('kind', m, []) + n.pop('kind', [])
    m['kind'] = kind

    if 'box' in kind:
        kind.append('tool')

    if 'provides' in m and any(('lib' in x) for x in m['provides']):
        kind.append('library')

    m['kind'] = sorted(frozenset(kind))
    f = m['flags']

    if 'codec' in n:
        pass
    else:
        n['codec'] = kwargs.get('codec', 'gz')

    if 'naked' in kwargs:
        n['naked'] = kwargs['naked']

    if 'url' in n:
        if 'pkg_full_name' not in n:
            n['pkg_full_name'] = y.calc_pkg_full_name(n['url'])

    def iter_subst():
        for i, v in enumerate(n.get('extra', [])):
            if v['kind'] == 'file':
                cmd = 'echo "' + y.base64.b64encode(v['data'].encode('utf-8')).decode('utf-8') + '" | (base64 -D -i - -o - || base64 -d) > ' + v['path']
                key = '$(APPLY_EXTRA_PLAN_' + str(i) + ')'

                yield (key, cmd)

            if v['kind'] == 'subst':
                yield (v['from'], v['to'])

    subst = list(iter_subst())

    for p in ('build', 'prepare'):
        if p in n:
            n[p] = [y.subst_kv_base(l, subst) for l in apply_fetch(n[p], v)]

    return v

--------------------&/ya/cli_makefile.py
def iter_cc():   
    for t in y.iter_all_targets():
        yield y.dc(t)


@y.main_entry_point
async def cli_pkg_makefile(arg):
    parser = y.argparse.ArgumentParser()
   
    parser.add_argument('-o', '--output', default='', action='store', help='file to output, stdout by default')
    parser.add_argument('-S', '--shell', default=[], action='append', help='out build.sh script')
    parser.add_argument('-P', '--plugins', default=[], action='append', help='where to find build rules')
    parser.add_argument('-I', '--internal', default=False, action='store_const', const=True, help='generte internal format')
    parser.add_argument('-T', '--dot', default=False, action='store_const', const=True, help='output dot graph')
    parser.add_argument('-F', '--dump', default=False, action='store_const', const=True, help='output full dump')

    args = parser.parse_args(arg)
   
    with y.defer_context() as defer:
        if args.output:
            f = open(args.output, 'w')
            defer(f.close)
        else:
            f = y.stdout

        async def main_func():
            if args.dot:
                data = await y.build_dot_script()
            elif args.shell:
                data = await y.build_sh_script(args.shell)
            elif args.dump:
                data = await y.gen_full_dump(iter_cc)
            else:
                data = await y.main_makefile(iter_cc, internal=args.internal)

                def func():
                    f.write(data)
                    f.flush()

                return await y.offload(func)

        return await main_func()

+++++++++++++++++++
def iter_cc():   
    for t in y.iter_all_targets():
        yield y.dc(t)


@y.main_entry_point
async def cli_pkg_makefile(arg):
    parser = y.argparse.ArgumentParser()
   
    parser.add_argument('-o', '--output', default='', action='store', help='file to output, stdout by default')
    parser.add_argument('-S', '--shell', default=[], action='append', help='out build.sh script')
    parser.add_argument('-P', '--plugins', default=[], action='append', help='where to find build rules')
    parser.add_argument('-I', '--internal', default=False, action='store_const', const=True, help='generte internal format')
    parser.add_argument('-T', '--dot', default=False, action='store_const', const=True, help='output dot graph')
    parser.add_argument('-F', '--dump', default=False, action='store_const', const=True, help='output full dump')

    args = parser.parse_args(arg)
   
    with y.defer_context() as defer:
        if args.output:
            f = open(args.output, 'w')
            defer(f.close)
        else:
            f = y.stdout

        async def main_func():
            if args.dot:
                data = await y.build_dot_script()
            elif args.shell:
                data = await y.build_sh_script(args.shell)
            elif args.dump:
                data = await y.gen_full_dump(iter_cc)
            else:
                data = await y.main_makefile(iter_cc, internal=args.internal)

                def func():
                    f.write(data)
                    f.flush()

                return await y.offload(func)

        return await main_func()

--------------------&/ya/io.py
def calc_mode(name):
    lst = [
        ('.xz', 'xz'),
        ('.txz', 'xz'),
        ('.gz', 'gz'),
        ('.tgz', 'gz'),
        ('.tar', 'tr'),
        ('.bz2', 'bz'),
        ('.tbz2', 'bz'),
        ('.tbz', 'bz'),
        ('.zip', 'zp'),
        ('-xz', 'xz'),
        ('-gz', 'gz'),
        ('-bz', 'bz'),
        ('-zp', 'zp'),
        ('-tr', 'tr'),
        ('-7z', '7z'),
        ('-pg', 'pg'),
    ]

    if '-tr-' in name:
        return 'tr'

    for k, v in lst:
        if name.endswith(k):
            return v

    if '-xz-' in name:
        return 'xz'

    if '-zp-' in name:
        return 'zp'

    if '-gz-' in name:
        return 'gz'

    if '-bz-' in name:
        return 'bz'

    raise Exception('shit happen ' + name)


def known_codecs():
    return ('xz', 'gz', 'tr', 'bz', 'zp', '7z', 'pg')


def prepare_tar_cmd(fr, to, codec=None):
    res = {
        'xz': '$YXZ -zc',
        'gz': '$YGZIP -c',
        'tr': 'cat',
        'bz': '$YBZIP2 -c',
        '7z': '$Y7ZA a -si {to}',
        'pg': '(PYTHONHOME= $SD/upm cmd codec -c)',
    }

    if not codec:
        codec = calc_mode(y.os.path.basename(to))

    if codec == 'zp':
        return

    def iter_lines():
        if fr == '"$1"':
            dr = '$(dirname "$2")'
        else:
            dr = y.os.path.dirname(to)

        assert dr

        yield 'mkdir -p ' + dr
        yield 'cd ' + fr
        yield '($YTAR -v -cf - . | ' + res[codec] + ')'

    if codec == '7z':
        tot = to + '-tmp.7z'

        yield ('(' + ' && '.join(iter_lines()) + ') && (mv {to} ' + to + ')').replace('{to}', tot)
    else:
        yield '((' + ' && '.join(iter_lines()) + ') > ' + to + '-tmp) && (mv ' + to + '-tmp ' + to + ')'


data1 = '''
if test $2 -eq 1; then
    q=$(basename $1)
    q=$(echo $q | tr '_' '-' | tr '.' '-' | tr '-' '\n' | head -n 1)
    mv ./$q* ./xxx
    mv ./xxx/* ./
    rm -rf ./xxx
fi
'''


@y.singleton
def gen_extra_scripts():
    def do():
        for codec in known_codecs():
            data = ''.join(prepare_tar_cmd('"$1"', '"$2"', codec))

            yield 'prepare_' + codec + '_pkg', data

        for codec in list(known_codecs()) + ['zp']:
            data = ''.join(prepare_untar_cmd('"$1"', '.', ext_mode=codec, rm_old=False))
            yield 'untar_' + codec, data + '\n' + data1

    return list(do())


def prepare_untar_for_mf(fr, strip=0):
    try:
        return 'source untar_{codec} "{file}" {strip}'.format(codec=calc_mode(y.os.path.basename(fr)), file=fr, strip=strip)
    except Exception:
        return 'cp "{file}" .'.format(file=fr)


def prepare_untar_cmd(fr, to, extra='', rm_old=True, ext_mode=None):
    if (ext_mode and ext_mode == 'zp') or fr.endswith('.zip'):
        def do():
            yield '($YUNZIP -o ' + fr + ' || $Y7ZA x -y ' + fr + ') 2> /dev/null'

            if to not in ' .':
                yield 'cd ' + to
                yield 'mkdir -p ' + to

                if rm_old:
                    yield '(rm -rf ' + to + ' || true)'

        return ' && '.join(reversed(list(do())))

    tbl = {
        'xz': '| $YXZCAT -f |',
        'gz': '| $YGZIP -dc |',
        'bz': '| $YBZIP2 -dc |',
        'pg': '| (PYTHONHOME= $SD/upm cmd codec -d) |',
        'tr': '|',
    }

    mode = ext_mode or cay.lc_mode(os.path.basename(fr))

    if mode == '7z':
        core = '$Y7ZA x -so {fr} | $YTAR {extra} -xf -'.format(fr=fr, extra=extra)
    else:
        core = 'cat {fr} {uncompress} $YTAR {extra} -xf -'.format(fr=fr, uncompress=tbl[mode], extra=extra)

    if to in ' .':
        return core

    bt_rm = {
        True: '(rm -rf {to} || true) && ',
        False: '',
    }

    return (bt_rm[rm_old] + '(mkdir -p {to}) && (cd {to}) && ({core})').format(to=to, core=core)

+++++++++++++++++++
def calc_mode(name):
    lst = [
        ('.xz', 'xz'),
        ('.txz', 'xz'),
        ('.gz', 'gz'),
        ('.tgz', 'gz'),
        ('.tar', 'tr'),
        ('.bz2', 'bz'),
        ('.tbz2', 'bz'),
        ('.tbz', 'bz'),
        ('.zip', 'zp'),
        ('-xz', 'xz'),
        ('-gz', 'gz'),
        ('-bz', 'bz'),
        ('-zp', 'zp'),
        ('-tr', 'tr'),
        ('-7z', '7z'),
        ('-pg', 'pg'),
    ]

    if '-tr-' in name:
        return 'tr'

    for k, v in lst:
        if name.endswith(k):
            return v

    if '-xz-' in name:
        return 'xz'

    if '-zp-' in name:
        return 'zp'

    if '-gz-' in name:
        return 'gz'

    if '-bz-' in name:
        return 'bz'

    raise Exception('shit happen ' + name)


def known_codecs():
    return ('xz', 'gz', 'tr', 'bz', 'zp', '7z', 'pg')


def prepare_tar_cmd(fr, to, codec=None):
    res = {
        'xz': '$YXZ -zc',
        'gz': '$YGZIP -c',
        'tr': 'cat',
        'bz': '$YBZIP2 -c',
        '7z': '$Y7ZA a -si {to}',
        'pg': '(PYTHONHOME= $SD/upm cmd codec -c)',
    }

    if not codec:
        codec = calc_mode(y.os.path.basename(to))

    if codec == 'zp':
        return

    def iter_lines():
        if fr == '"$1"':
            dr = '$(dirname "$2")'
        else:
            dr = y.os.path.dirname(to)

        assert dr

        yield 'mkdir -p ' + dr
        yield 'cd ' + fr
        yield '($YTAR -v -cf - . | ' + res[codec] + ')'

    if codec == '7z':
        tot = to + '-tmp.7z'

        yield ('(' + ' && '.join(iter_lines()) + ') && (mv {to} ' + to + ')').replace('{to}', tot)
    else:
        yield '((' + ' && '.join(iter_lines()) + ') > ' + to + '-tmp) && (mv ' + to + '-tmp ' + to + ')'


data1 = '''
if test $2 -eq 1; then
    q=$(basename $1)
    q=$(echo $q | tr '_' '-' | tr '.' '-' | tr '-' '\n' | head -n 1)
    mv ./$q* ./xxx
    mv ./xxx/* ./
    rm -rf ./xxx
fi
'''


@y.singleton
def gen_extra_scripts():
    def do():
        for codec in known_codecs():
            data = ''.join(prepare_tar_cmd('"$1"', '"$2"', codec))

            yield 'prepare_' + codec + '_pkg', data

        for codec in list(known_codecs()) + ['zp']:
            data = ''.join(prepare_untar_cmd('"$1"', '.', ext_mode=codec, rm_old=False))
            yield 'untar_' + codec, data + '\n' + data1

    return list(do())


def prepare_untar_for_mf(fr, strip=0):
    try:
        return 'source untar_{codec} "{file}" {strip}'.format(codec=calc_mode(y.os.path.basename(fr)), file=fr, strip=strip)
    except Exception:
        return 'cp "{file}" .'.format(file=fr)


def prepare_untar_cmd(fr, to, extra='', rm_old=True, ext_mode=None):
    if (ext_mode and ext_mode == 'zp') or fr.endswith('.zip'):
        def do():
            yield '($YUNZIP -o ' + fr + ' || $Y7ZA x -y ' + fr + ') 2> /dev/null'

            if to not in ' .':
                yield 'cd ' + to
                yield 'mkdir -p ' + to

                if rm_old:
                    yield '(rm -rf ' + to + ' || true)'

        return ' && '.join(reversed(list(do())))

    tbl = {
        'xz': '| $YXZCAT -f |',
        'gz': '| $YGZIP -dc |',
        'bz': '| $YBZIP2 -dc |',
        'pg': '| (PYTHONHOME= $SD/upm cmd codec -d) |',
        'tr': '|',
    }

    mode = ext_mode or cay.lc_mode(os.path.basename(fr))

    if mode == '7z':
        core = '$Y7ZA x -so {fr} | $YTAR {extra} -xf -'.format(fr=fr, extra=extra)
    else:
        core = 'cat {fr} {uncompress} $YTAR {extra} -xf -'.format(fr=fr, uncompress=tbl[mode], extra=extra)

    if to in ' .':
        return core

    bt_rm = {
        True: '(rm -rf {to} || true) && ',
        False: '',
    }

    return (bt_rm[rm_old] + '(mkdir -p {to}) && (cd {to}) && ({core})').format(to=to, core=core)

--------------------&/ya/cli_codec.py
@y.contextlib.contextmanager
def switch_stdout():
    cur = y.sys.stdout
    prev = cur.slave()

    y.sys.stdout = prev

    try:
        yield prev
    finally:
        y.sys.stdout = cur


@y.main_entry_point
async def cli_cmd_codec(args):
    with switch_stdout() as f:
        d = y.sys.stdin.buffer.read()

        if args[0] == '-c':
            f.buffer.write(y.lzma.compress(d))
        elif args[0] == '-d':
            f.buffer.write(y.lzma.decompress(d))
        else:
            raise Exception('shit')

        f.flush()

+++++++++++++++++++
@y.contextlib.contextmanager
def switch_stdout():
    cur = y.sys.stdout
    prev = cur.slave()

    y.sys.stdout = prev

    try:
        yield prev
    finally:
        y.sys.stdout = cur


@y.main_entry_point
async def cli_cmd_codec(args):
    with switch_stdout() as f:
        d = y.sys.stdin.buffer.read()

        if args[0] == '-c':
            f.buffer.write(y.lzma.compress(d))
        elif args[0] == '-d':
            f.buffer.write(y.lzma.decompress(d))
        else:
            raise Exception('shit')

        f.flush()

--------------------&/ya/cli_eval.py
@y.main_entry_point
async def cli_dev_eval(args):
   await run_eval(args)


async def run_eval(args):
   repl = {
      'layers': 'y.gen_all_texts(only_print_layers=True)'
   }

   if not args:
      for k, v in repl.items():
         y.xprint_bb(k, '=', v)

      return

   for a in args:
      try:
         print(eval(repl.get(a, a)))
      except:
         y.print_tbx(tb_line='can not run ' + a)

+++++++++++++++++++
@y.main_entry_point
async def cli_dev_eval(args):
   await run_eval(args)


async def run_eval(args):
   repl = {
      'layers': 'y.gen_all_texts(only_print_layers=True)'
   }

   if not args:
      for k, v in repl.items():
         y.xprint_bb(k, '=', v)

      return

   for a in args:
      try:
         print(eval(repl.get(a, a)))
      except:
         y.print_tbx(tb_line='can not run ' + a)

--------------------&/ya/cli_selftest.py
def self_test1():
   @y.cached(seed=1)
   def f1(a, b):
      return a + b

   @y.cached(seed=187564)
   def f2(a, b):
      return a + b

   def f3(a, b):
      return a + b

   for i in range(0, 5):
      y.xprint_blue(f1(i, i * 13 - 17), f2(i, i * 13 - 17), f3(i, i * 13 - 17))


def self_test2():
   for color in y.color_map_func():
      y.xxprint('{color}color{}'.format(color=color))


def self_test4():
   with y.abort_on_error():
      async def ff(ctl):
         async def func(x):
            return x * x
  
         print(await ctl.loop.map(func, range(0, 1000)).wait(), file=y.stderr)

      y.print_all_threads()
      y.spawn(ff).wait_sync()

   
def iter_all_tests():
    yield self_test4
    yield self_test1
    yield self_test2
    yield self_test3


@y.verbose_entry_point
def cli_test_self(args, verbose):
   print(1, file=y.stderr)
   
   with y.abort_on_error():
      for f in iter_all_tests():
         f()

+++++++++++++++++++
def self_test1():
   @y.cached(seed=1)
   def f1(a, b):
      return a + b

   @y.cached(seed=187564)
   def f2(a, b):
      return a + b

   def f3(a, b):
      return a + b

   for i in range(0, 5):
      y.xprint_blue(f1(i, i * 13 - 17), f2(i, i * 13 - 17), f3(i, i * 13 - 17))


def self_test2():
   for color in y.color_map_func():
      y.xxprint('{color}color{}'.format(color=color))


def self_test4():
   with y.abort_on_error():
      async def ff(ctl):
         async def func(x):
            return x * x
  
         print(await ctl.loop.map(func, range(0, 1000)).wait(), file=y.stderr)

      y.print_all_threads()
      y.spawn(ff).wait_sync()

   
def iter_all_tests():
    yield self_test4
    yield self_test1
    yield self_test2
    yield self_test3


@y.verbose_entry_point
def cli_test_self(args, verbose):
   print(1, file=y.stderr)
   
   with y.abort_on_error():
      for f in iter_all_tests():
         f()

--------------------&/ya/cli_docker.py
def build_docker(cwd):
    data = y.subprocess.check_output(['docker build .'], cwd=cwd, shell=True, env=y.os.environ).decode('utf-8')
    lines = data.split('\n')
    line = lines[len(lines) - 2]

    y.info('{bb}new docker image{dw}\n' + data.strip() + '{}{}')

    return line.split(' ')[2]


def path_to_images():
    return y.globals.script_dir + '/images'


@y.main_entry_point
async def cli_docker_build(args):
    assert args, 'empty arguments'

    path = path_to_images()

    for t in args:
        new_ver = build_docker(path + '/' + t)

        with y.open_pdb() as db:
            db.images[t] = db.images.get(t, []) + [new_ver]


def data_for_container(cont):
   path = path_to_images() + '/' + cont
   
   with y.open_pdb() as db:
       if cont not in db.images:
           raise Exception('no containers for ' + cont)

       return {'data': db.images[cont], 'path': path}


@y.main_entry_point
async def cli_docker_run(arg):
   assert arg, 'empty arguments'

   cont = arg[0]
   data = data_for_container(cont)
   path = data['path']
   latest = data['data'][-1]

   y.os.execv('/bin/bash', ['/bin/bash', path + '/run.sh'] + arg[1:] + [latest])


def get_running():
    out = y.subprocess.check_output(['docker container ls'], shell=True).decode('utf-8')
    res = dict((y[1], y[0]) for y in (x.split() for x in out.split('\n')[1:] if x))

    return res
   
   
@y.main_entry_point
async def cli_docker_list(arg):
    info = get_running()

    def is_running(cont):
        try:
            return data_for_container(cont)['data'][-1] in info
        except Exception as e:
            return False

    text = {
        False: '{br}-{}',
        True: '{bg}+{}',
    }

    for i in y.os.listdir(path_to_images()):
        print(text[is_running(i)], '{bb}' + i + '{}')


@y.main_entry_point
async def cli_docker_shell(arg):
    assert arg, 'empty arguments'

    cont = arg[0]
    cont_image = data_for_container(cont)['data'][-1]
    cont_id = get_running()[cont_image]

    y.os.execvp('docker', ['docker', 'exec', '-ti', cont_id, '/bin/bash'])

+++++++++++++++++++
def build_docker(cwd):
    data = y.subprocess.check_output(['docker build .'], cwd=cwd, shell=True, env=y.os.environ).decode('utf-8')
    lines = data.split('\n')
    line = lines[len(lines) - 2]

    y.info('{bb}new docker image{dw}\n' + data.strip() + '{}{}')

    return line.split(' ')[2]


def path_to_images():
    return y.globals.script_dir + '/images'


@y.main_entry_point
async def cli_docker_build(args):
    assert args, 'empty arguments'

    path = path_to_images()

    for t in args:
        new_ver = build_docker(path + '/' + t)

        with y.open_pdb() as db:
            db.images[t] = db.images.get(t, []) + [new_ver]


def data_for_container(cont):
   path = path_to_images() + '/' + cont
   
   with y.open_pdb() as db:
       if cont not in db.images:
           raise Exception('no containers for ' + cont)

       return {'data': db.images[cont], 'path': path}


@y.main_entry_point
async def cli_docker_run(arg):
   assert arg, 'empty arguments'

   cont = arg[0]
   data = data_for_container(cont)
   path = data['path']
   latest = data['data'][-1]

   y.os.execv('/bin/bash', ['/bin/bash', path + '/run.sh'] + arg[1:] + [latest])


def get_running():
    out = y.subprocess.check_output(['docker container ls'], shell=True).decode('utf-8')
    res = dict((y[1], y[0]) for y in (x.split() for x in out.split('\n')[1:] if x))

    return res
   
   
@y.main_entry_point
async def cli_docker_list(arg):
    info = get_running()

    def is_running(cont):
        try:
            return data_for_container(cont)['data'][-1] in info
        except Exception as e:
            return False

    text = {
        False: '{br}-{}',
        True: '{bg}+{}',
    }

    for i in y.os.listdir(path_to_images()):
        print(text[is_running(i)], '{bb}' + i + '{}')


@y.main_entry_point
async def cli_docker_shell(arg):
    assert arg, 'empty arguments'

    cont = arg[0]
    cont_image = data_for_container(cont)['data'][-1]
    cont_id = get_running()[cont_image]

    y.os.execvp('docker', ['docker', 'exec', '-ti', cont_id, '/bin/bash'])

--------------------&/ya/extra_nodes.py
def iter_workspace():
    path = 'export PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin'

    yield {
        'output': 'workspace',
        'inputs': ['package_dir', 'work_dir', 'install_dir', 'cache_dir', 'source_dir', 'release_upm'],
        'build': [],
    }

    yield {
        'output': 'install_dir',
        'inputs': [],
        'build': [
            path,
            'rm -rf "$PD" 2> /dev/null || true',
            'mkdir -p "$PD"',
        ],
    }

    yield {
        'output': 'work_dir',
        'inputs': [],
        'build': [
            path,
            'rm -rf "$WD" 2> /dev/null || true',
            'mkdir -p "$WD"',
        ],
    }

    yield {
        'output': 'package_dir',
        'inputs': [],
        'build': [
            path,
            'mkdir -p "$RD"',
        ],
    }

    yield {
        'output': 'cache_dir',
        'inputs': [],
        'build': [
            path,
            'mkdir -p "$MD"',
        ],
    }

    yield {
        'output': 'source_dir',
        'inputs': [],
        'build': [
            path,
            'mkdir -p "$SD"',
            '(rm -rf $SD/upm || true) 2> /dev/null'
        ],
    }

    yield {
        'output': 'release_upm',
        'inputs': ['source_dir'],
        'build': [
            path,
            '($UPM cmd release > $SD/upm.tmp) && chmod +x $SD/upm.tmp && $SD/upm.tmp help && mv $SD/upm.tmp $SD/upm',
        ],
    }

+++++++++++++++++++
def iter_workspace():
    path = 'export PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin'

    yield {
        'output': 'workspace',
        'inputs': ['package_dir', 'work_dir', 'install_dir', 'cache_dir', 'source_dir', 'release_upm'],
        'build': [],
    }

    yield {
        'output': 'install_dir',
        'inputs': [],
        'build': [
            path,
            'rm -rf "$PD" 2> /dev/null || true',
            'mkdir -p "$PD"',
        ],
    }

    yield {
        'output': 'work_dir',
        'inputs': [],
        'build': [
            path,
            'rm -rf "$WD" 2> /dev/null || true',
            'mkdir -p "$WD"',
        ],
    }

    yield {
        'output': 'package_dir',
        'inputs': [],
        'build': [
            path,
            'mkdir -p "$RD"',
        ],
    }

    yield {
        'output': 'cache_dir',
        'inputs': [],
        'build': [
            path,
            'mkdir -p "$MD"',
        ],
    }

    yield {
        'output': 'source_dir',
        'inputs': [],
        'build': [
            path,
            'mkdir -p "$SD"',
            '(rm -rf $SD/upm || true) 2> /dev/null'
        ],
    }

    yield {
        'output': 'release_upm',
        'inputs': ['source_dir'],
        'build': [
            path,
            '($UPM cmd release > $SD/upm.tmp) && chmod +x $SD/upm.tmp && $SD/upm.tmp help && mv $SD/upm.tmp $SD/upm',
        ],
    }

--------------------&/ya/v2_to_v3.py
import base64
import itertools
import hashlib


def mn(x):
    return '$MD' + x[3:]


def iter_deps(root):
    rn = root['trash']['restore_node']

    for d in root['deps']:
        yield rn(d)


def mgr_pkg(x):
    return '$MD' + x[3:]


def mgr_pkg_mark(x):
    return mgr_pkg(x) + '/build'


def gen_pkg_path(v):
    return '$RD/' + y.to_visible_name(v)


def uniq_deps(d):
    return y.uniq_list_2(d, gen_pkg_path)


def rmmkcd(q, suffix=''):
    return 'rm -rf {q} || true; mkdir -p {q}{s}; cd {q}{s}'.format(q=q, s=suffix)


def prepare_prepare(data, target):
    return '\n'.join(data).replace('$(CUR_DIR)', '$MD/' + target[4:])


def print_one_node(root):
    rn = root['trash']['restore_node']
    root_node = root['node']
    extra = root_node.get('extra_cmd', [])
    target = gen_pkg_path(root)
    nodes = list(uniq_deps([rn(x) for x in root['deps']]))
    naked = root_node.get('naked', False)
    inputs = [y.build_scripts_path()] + [mgr_pkg_mark(x[0]) for x in nodes] + [x['output'] for x in extra]

    int_node = {
        'output': target,
        'inputs': list(inputs),
    }

    def iter_part1():
        if not naked:
            yield '. "$2" && source init $@'

        prepare = prepare_prepare(root_node.get('prepare', []), target)
        meta = y.meta_to_build(root_node.get('meta', {}))
        data = '\n'.join([meta, prepare]).strip()
        data = data.replace('{pkgroot}', mn(target)) + '\n'
        data = base64.b64encode(data.encode('utf-8'))

        for x in root_node.get('build', []):
            yield x

        if naked:
            yield 'source write_build_file "' + data.decode('utf-8') + '"'
        else:
            yield 'source fini "' + data.decode('utf-8') + '"'

    int_node['build'] = list(iter_part1())

    return [int_node] + extra

+++++++++++++++++++
import base64
import itertools
import hashlib


def mn(x):
    return '$MD' + x[3:]


def iter_deps(root):
    rn = root['trash']['restore_node']

    for d in root['deps']:
        yield rn(d)


def mgr_pkg(x):
    return '$MD' + x[3:]


def mgr_pkg_mark(x):
    return mgr_pkg(x) + '/build'


def gen_pkg_path(v):
    return '$RD/' + y.to_visible_name(v)


def uniq_deps(d):
    return y.uniq_list_2(d, gen_pkg_path)


def rmmkcd(q, suffix=''):
    return 'rm -rf {q} || true; mkdir -p {q}{s}; cd {q}{s}'.format(q=q, s=suffix)


def prepare_prepare(data, target):
    return '\n'.join(data).replace('$(CUR_DIR)', '$MD/' + target[4:])


def print_one_node(root):
    rn = root['trash']['restore_node']
    root_node = root['node']
    extra = root_node.get('extra_cmd', [])
    target = gen_pkg_path(root)
    nodes = list(uniq_deps([rn(x) for x in root['deps']]))
    naked = root_node.get('naked', False)
    inputs = [y.build_scripts_path()] + [mgr_pkg_mark(x[0]) for x in nodes] + [x['output'] for x in extra]

    int_node = {
        'output': target,
        'inputs': list(inputs),
    }

    def iter_part1():
        if not naked:
            yield '. "$2" && source init $@'

        prepare = prepare_prepare(root_node.get('prepare', []), target)
        meta = y.meta_to_build(root_node.get('meta', {}))
        data = '\n'.join([meta, prepare]).strip()
        data = data.replace('{pkgroot}', mn(target)) + '\n'
        data = base64.b64encode(data.encode('utf-8'))

        for x in root_node.get('build', []):
            yield x

        if naked:
            yield 'source write_build_file "' + data.decode('utf-8') + '"'
        else:
            yield 'source fini "' + data.decode('utf-8') + '"'

    int_node['build'] = list(iter_part1())

    return [int_node] + extra

--------------------&/ya/tc_util.py
def cons_to_name_x(c):
    if not c:
        return 'nop'

    try:
        c = c['target']
    except KeyError:
        pass

    res = ''

    for k, f in (('os', 1), ('libc', 1), ('arch', 2)):
        if k in c:
            res += c[k][:f]

    return res


def small_repr(c):
    return cons_to_name_x(c)


def small_repr_cons(c):
    return small_repr(c.get('host', c['target'])) + '$' + small_repr(c['target'])


def is_cross(cc):
    if not cc:
        return False

    return small_repr(cc['host']) != small_repr(cc['target'])


def subst_info(info):
    info = y.dc(info)

    if 'host' not in info:
        info['host'] = current_host_platform()

    if 'target' not in info:
        info['target'] = y.dc(info['host'])

    return info


def iter_all_targets():
                                                                                                                                                                                                                                                                                                           
    for a in ('x86_64',):
        yield {
            'arch': a,
            'os': 'darwin',
        }


@y.singleton
def rev_target_map():
    res = {}

    for x in iter_all_targets():
        res[small_repr(x)] = x

    return res


def to_full_target(name):
    return rev_target_map()[name]


def iter_all_arch():
    yield from sorted(frozenset(x['arch'] for x in iter_all_targets()))


def iter_all_os():
    yield from sorted(frozenset(x['os'] for x in iter_all_targets()))


@y.singleton
def current_host_platform():
    res = {
        'arch': y.platform.machine(),
        'os': y.platform.system().lower(),
    }

    if res['os'] == 'linux':
        if 'alpine' in y.platform.uname().version.lower():
            res['libc'] = 'musl'
        else:
            res['libc'] = 'glibc'

    return res

+++++++++++++++++++
def cons_to_name_x(c):
    if not c:
        return 'nop'

    try:
        c = c['target']
    except KeyError:
        pass

    res = ''

    for k, f in (('os', 1), ('libc', 1), ('arch', 2)):
        if k in c:
            res += c[k][:f]

    return res


def small_repr(c):
    return cons_to_name_x(c)


def small_repr_cons(c):
    return small_repr(c.get('host', c['target'])) + '$' + small_repr(c['target'])


def is_cross(cc):
    if not cc:
        return False

    return small_repr(cc['host']) != small_repr(cc['target'])


def subst_info(info):
    info = y.dc(info)

    if 'host' not in info:
        info['host'] = current_host_platform()

    if 'target' not in info:
        info['target'] = y.dc(info['host'])

    return info


def iter_all_targets():
                                                                                                                                                                                                                                                                                                           
    for a in ('x86_64',):
        yield {
            'arch': a,
            'os': 'darwin',
        }


@y.singleton
def rev_target_map():
    res = {}

    for x in iter_all_targets():
        res[small_repr(x)] = x

    return res


def to_full_target(name):
    return rev_target_map()[name]


def iter_all_arch():
    yield from sorted(frozenset(x['arch'] for x in iter_all_targets()))


def iter_all_os():
    yield from sorted(frozenset(x['os'] for x in iter_all_targets()))


@y.singleton
def current_host_platform():
    res = {
        'arch': y.platform.machine(),
        'os': y.platform.system().lower(),
    }

    if res['os'] == 'linux':
        if 'alpine' in y.platform.uname().version.lower():
            res['libc'] = 'musl'
        else:
            res['libc'] = 'glibc'

    return res

--------------------&/ya/noid_calcer.py
def calc_noid_base(v):
    if 'noid' in v:
        # assert v['noid'] == calc_noid_base_really(v)
        return v['noid']

    return calc_noid_base_really(v)


def calc_noid_base_really(v):
    return 'i:' + y.key_struct_ptr([v['node'], v['deps']])[2:]


def calc_noid(v):
    return 'i:' + y.key_struct_ptr([calc_noid_base(v), v['trash']['extra']])[2:]

+++++++++++++++++++
def calc_noid_base(v):
    if 'noid' in v:
        # assert v['noid'] == calc_noid_base_really(v)
        return v['noid']

    return calc_noid_base_really(v)


def calc_noid_base_really(v):
    return 'i:' + y.key_struct_ptr([v['node'], v['deps']])[2:]


def calc_noid(v):
    return 'i:' + y.key_struct_ptr([calc_noid_base(v), v['trash']['extra']])[2:]

--------------------&/ya/meta_build.py
def meta_to_build(meta):
    def iter():
        kind = set(meta['kind'])

        is_lib = 'library' in kind
        is_bin = 'tool' in kind

        yield 'export CMAKE_PREFIX_PATH="{pkgroot}:$CMAKE_PREFIX_PATH"'

        if is_lib:
            yield 'export CPPFLAGS="$CPPFLAGS -I{pkgroot}/include"'
            yield 'export LDFLAGS="-L{pkgroot}/lib $LDFLAGS"'
            yield 'export PKG_CONFIG_PATH="{pkgroot}/lib/pkgconfig:$PKG_CONFIG_PATH"'

        if is_bin:
            yield 'export PATH="{pkgroot}/bin:$PATH"'

        for p in meta.get('provides', []):
            if is_lib:
                if 'lib' in p:
                    yield 'export LIBS="{lib} $LIBS"'.format(lib='-l' + p['lib'])

                if 'extra' in p:
                    for e in p['extra']:
                        if 'libs' in e:
                            yield 'export LIBS="{extra} $LIBS"'.format(extra=e['libs'])

                        if 'ipath' in e:
                            yield 'export CPPFLAGS="$CPPFLAGS -I{ipath}"'.format(ipath=e['ipath'])

                if 'configure' in p:
                    cfg = p['configure']

                    if 'opt' in cfg:
                        yield 'export COFLAGS="$COFLAGS {opt}"'.format(opt=cfg['opt'])

                    if 'opts' in cfg:
                        for o in cfg['opts']:
                            yield 'export COFLAGS="$COFLAGS {opt}"'.format(opt=o)

            if 'env' in p:
                yield 'export {k}={v}'.format(k=p['env'], v=p['value'])

    return '\n'.join(iter()) + '\n'

+++++++++++++++++++
def meta_to_build(meta):
    def iter():
        kind = set(meta['kind'])

        is_lib = 'library' in kind
        is_bin = 'tool' in kind

        yield 'export CMAKE_PREFIX_PATH="{pkgroot}:$CMAKE_PREFIX_PATH"'

        if is_lib:
            yield 'export CPPFLAGS="$CPPFLAGS -I{pkgroot}/include"'
            yield 'export LDFLAGS="-L{pkgroot}/lib $LDFLAGS"'
            yield 'export PKG_CONFIG_PATH="{pkgroot}/lib/pkgconfig:$PKG_CONFIG_PATH"'

        if is_bin:
            yield 'export PATH="{pkgroot}/bin:$PATH"'

        for p in meta.get('provides', []):
            if is_lib:
                if 'lib' in p:
                    yield 'export LIBS="{lib} $LIBS"'.format(lib='-l' + p['lib'])

                if 'extra' in p:
                    for e in p['extra']:
                        if 'libs' in e:
                            yield 'export LIBS="{extra} $LIBS"'.format(extra=e['libs'])

                        if 'ipath' in e:
                            yield 'export CPPFLAGS="$CPPFLAGS -I{ipath}"'.format(ipath=e['ipath'])

                if 'configure' in p:
                    cfg = p['configure']

                    if 'opt' in cfg:
                        yield 'export COFLAGS="$COFLAGS {opt}"'.format(opt=cfg['opt'])

                    if 'opts' in cfg:
                        for o in cfg['opts']:
                            yield 'export COFLAGS="$COFLAGS {opt}"'.format(opt=o)

            if 'env' in p:
                yield 'export {k}={v}'.format(k=p['env'], v=p['value'])

    return '\n'.join(iter()) + '\n'

--------------------&/ya/cli_fetchurl.py
@y.main_entry_point
async def cli_cmd_fetch(args):
    if len(args) > 1:
        url = args[0]
        path = args[1]
        root = y.os.path.dirname(path)
        name = y.os.path.basename(path)
    else:
        url = args[0]
        root = './'
        name = y.os.path.basename(url)

    y.fetch_http(root, url, name=name, untar=False)

+++++++++++++++++++
@y.main_entry_point
async def cli_cmd_fetch(args):
    if len(args) > 1:
        url = args[0]
        path = args[1]
        root = y.os.path.dirname(path)
        name = y.os.path.basename(path)
    else:
        url = args[0]
        root = './'
        name = y.os.path.basename(url)

    y.fetch_http(root, url, name=name, untar=False)

--------------------&/ya/all_funcs.py
class FuncAggr(object):
    def __init__(self, cb):
        self.cb = cb
        self.v = []

    def on_new_data(self, iface):
        yield y.EOP(y.ACCEPT('mf:new functions', 'mf:splitted'))

        for row in iface.iter_data():
            data = row.data

            if data:
                self.cb(data['func'])
            else:
                self.v.append(1)

                if len(self.v) == 2:
                    yield y.FIN()

            yield y.EOP()


def gen_package_name(x):
    res = x['gen'] + '-' + x['base']

    if 'num' in x:
        res += str(x['num'])

    return res


def fix_pkg_name(res, descr):
    res = y.dc(res)

    res['node']['name'] = gen_package_name(descr)
    res['node']['gen'] = descr['gen']

    return res

+++++++++++++++++++
class FuncAggr(object):
    def __init__(self, cb):
        self.cb = cb
        self.v = []

    def on_new_data(self, iface):
        yield y.EOP(y.ACCEPT('mf:new functions', 'mf:splitted'))

        for row in iface.iter_data():
            data = row.data

            if data:
                self.cb(data['func'])
            else:
                self.v.append(1)

                if len(self.v) == 2:
                    yield y.FIN()

            yield y.EOP()


def gen_package_name(x):
    res = x['gen'] + '-' + x['base']

    if 'num' in x:
        res += str(x['num'])

    return res


def fix_pkg_name(res, descr):
    res = y.dc(res)

    res['node']['name'] = gen_package_name(descr)
    res['node']['gen'] = descr['gen']

    return res

--------------------&/ya/gen_id.py
import os


def calc_pkg_full_name(url):
    if url.endswith('download'):
        url = os.path.dirname(url)

    return os.path.basename(url)


def remove_compressor_name(x):
    for i in ('.tgz', '.tbz', '.txz', '.gz', '.bz2', '.xz', '.tar'):
        if x.endswith(i):
            x = x[0:len(x) - len(i)]

    return x


def to_visible_name_0(pkg, good_id):
    def iter_parts():
        yield pkg['name'].replace('_', '')
        yield y.small_repr(pkg.get('constraint'))
        yield 'v4' + good_id[:10][2:]
        yield pkg['codec']

    return '-'.join(iter_parts())


def to_visible_name_4(root):
    key = y.calc_noid(root)

    try:
        return root[key]
    except KeyError:
        root[key] = to_visible_name_0(root['node'], good_id=key).lower()

    return root[key]


def to_visible_name(root):
    return root['trash']['replacer'](to_visible_name_4(root))


def to_pretty_name(t):
    if len(t) < 10:
        return t

    p = t.find('-v5')

    if p < 0:
        return t

    t = t[:p]

    return t

+++++++++++++++++++
import os


def calc_pkg_full_name(url):
    if url.endswith('download'):
        url = os.path.dirname(url)

    return os.path.basename(url)


def remove_compressor_name(x):
    for i in ('.tgz', '.tbz', '.txz', '.gz', '.bz2', '.xz', '.tar'):
        if x.endswith(i):
            x = x[0:len(x) - len(i)]

    return x


def to_visible_name_0(pkg, good_id):
    def iter_parts():
        yield pkg['name'].replace('_', '')
        yield y.small_repr(pkg.get('constraint'))
        yield 'v4' + good_id[:10][2:]
        yield pkg['codec']

    return '-'.join(iter_parts())


def to_visible_name_4(root):
    key = y.calc_noid(root)

    try:
        return root[key]
    except KeyError:
        root[key] = to_visible_name_0(root['node'], good_id=key).lower()

    return root[key]


def to_visible_name(root):
    return root['trash']['replacer'](to_visible_name_4(root))


def to_pretty_name(t):
    if len(t) < 10:
        return t

    p = t.find('-v5')

    if p < 0:
        return t

    t = t[:p]

    return t

--------------------&/ya/gen_towers.py
ic = y.inc_counter()


@y.singleton
def is_debug():
    return 'debug' in y.config.get('tow', '')


@y.cached
def subst_by_platform(os):
    common = {
        'intl': 'gettext',
        'iconv': 'libiconv',
        'c++': 'libcxx',
        'm4': 'quasar-m4',
        'termcap': 'ncurses',
        'ncurses': 'ncurses',
    }

    by_os = {
        'linux': common.copy(),
        'darwin': common.copy(),
    }

    by_os['linux'].update({'ncurses': 'netbsd-curses'})

    return by_os[os]


class Func(object):
    def do_subst(self, x):
        s = subst_by_platform(self.data.info['os'])

        x = s.get(x, x)
        x = s.get(x, x)

        return x

    def __init__(self, x, data):
        self.x = x
        self.inc_count = ic()
        self.data = data
        self.i = 0

    def out_deps(self):
        y.xprint_db('{dr}' + str(self) + '{}', '->', '(' + ', '.join([str(self.data.func_by_num[i]) for i in self.deps]) + ')')

    def contains(self):
        return self.code().get('meta', {}).get('contains', [])

    @property
    def __name__(self):
        return str(self)

    def __str__(self):
        return '<' + self.base + '-' + str(self.i) + '-' + self.compact_kind() + '-' + self.data.info['os'] + '>'

    def compact_kind(self):
        res = ''

        if self.is_tool:
            res += 't'

        if self.is_library:
            res += 'l'

        return res

    @property
    def is_library(self):
        return 'library' in self.kind

    @property
    def is_tool(self):
        return 'tool' in self.kind

    @property
    def kind(self):
        return self.x['kind']

    @y.cached_method
    def code(self):
        return self.x['code']()

    @property
    def base(self):
        return self.x['base']

    @y.cached_method
    def raw_depends(self):
        code = self.code()

        if code:
            return [self.do_subst(x) for x in self.code().get('meta', {}).get('depends', [])]

        return []

    def depends(self):
        return self.raw_depends()

    @y.cached_method
    def all_depends(self):
        def it():
            for x in self.depends():
                yield x
                yield from self.data.by_name[x].all_depends()

        return frozenset(it())

    @y.cached_method
    def dep_lib_list(self):
        def iter():
            for x in self.dep_list():
                if self.data.by_name[x].is_library:
                    yield x

        return frozenset(iter())

    @y.cached_method
    def dep_tool_list(self):
        def iter():
            for x in self.dep_list():
                if not self.data.by_name[x].is_library:
                    yield x

        return frozenset(iter())

    def extra_libs(self):
        return self.data.extra_libs()

    #@y.cached_method
    def dep_list(self):
        def iter1():
            yield from self.depends()

            for d in self.extra_libs():
                if self.base in self.data.find_func(d).all_depends():
                    continue

                if self.base == d:
                    continue

                code = self.code()

                if not code:
                    continue

                if 'code' not in code:
                    continue

                yield d

        return frozenset(iter1())

    @y.cached_method
    def run_func(self):
        data = y.dc(self.c())
        data['deps'] = y.uniq_list_x(data['deps'] + self.data.calc(self.deps))
        data['node']['codec'] = self.codec

        y.apply_meta(data['node']['meta'], y.join_metas([y.restore_node_node(d).get('meta', {}) for d in data['deps']]))

        return y.fix_pkg_name(data, self.z)

    @y.cached_method
    def c(self):
        return y.to_v2(self.code(), self.data.info)

    @property
    def f(self):
        return self.ff

    @property
    def z(self):
        return self.zz

    @y.cached_method
    def ff(self):
        return y.gen_func(self.run_func)

    @property
    @y.cached_method
    def zz(self):
        return {
            'code': self.ff,
            'base': self.base,
            'gen': 'tow',
            'kind': self.kind,
            'repacks': {},
            'info': self.data.info,
        }

    def clone(self):
        return Func(self.x, self.data)

    def calc_deps(self):
        return self.data.optimize(self.data.select_deps(self.base) + self.data.last_elements(self.data.special, must_have=False))


class SpecialFunc(Func):
    def __init__(self, x, data):
        Func.__init__(self, x, data)

    def depends(self):
        return self.data.by_kind[self.base]

    @y.cached_method
    def contains(self):
        def it():
            for x in self.depends():
                yield x
                yield from self.data.by_name[x].contains()

        return frozenset(it())

    @y.cached_method
    def f(self):
        return self.slice(self.z['code']())

    @property
    @y.cached_method
    def z(self):
        return {
            'code': y.pkg_splitter(self.zz, 'run'),
            'base': self.base,
            'gen': 'tow',
            'kind': self.kind + ['split', 'run'],
            'info': self.data.info,
            'repacks': {},
        }

    @y.cached_method
    def c(self):
        f = y.join_funcs(lambda: self.data.calc(self.deps), ex_code='(cd $IDIR/bin && (rm python* pydoc* || true)) 2> /dev/null')

        return y.restore_node(f())

    def clone(self):
        return SpecialFunc(self.x, self.data)

    def calc_deps(self):
        return self.data.last_elements(self.depends())


class Solver(object):
    def __init__(self, data, seed=1):
        self._data = data
        self._seed = seed
        self._r, self._w = y.make_engine(self._data, ntn=lambda x: x.base, dep_list=lambda x: x.dep_list(), seed=self._seed)
        self.inc_count = ic()

    def next_solver(self):
        return Solver(self._data, self._seed * 13 + 17)

    def iter_items(self):
        for el in self._r():
            self._w(el['i'])
            yield el['x']

    def iter_solvers(self, num):
        cur = self
        yield cur

        for i in range(0, num - 1):
            cur = cur.next_solver()
            yield cur

    def iter_infinity(self, num):
        for s in self.iter_solvers(num):
            for i in s.iter_items():
                yield i.clone()


class Data(object):
    def __init__(self, info, data):
        self.info = info

        self.dd = y.collections.defaultdict(list)
        self.func_by_num = []
        self.inc_count = ic()

        def iter_objects():
            for x in sorted(data, key=lambda x: x['func']['base']):
                yield self.create_object(x['func'])

        self.data = list(iter_objects())
        self.by_name = dict((x.base, x) for x in self.data)
        self.by_kind = y.collections.defaultdict(list)

        for x in self.data:
            for k in x.kind:
                self.by_kind[k].append(x.base)

    def extra_libs(self):
        tg = self.info

        if tg['os'] == 'linux':
            return ('make', 'musl', 'bestbox')

        return ('make',)

    def create_object(self, x):
        if x['base'] in self.special:
            return SpecialFunc(x, self)

        return Func(x, self)

    def optimize(self, deps):
        def it():
            for i in deps:
                yield from self.func_by_num[i].contains()

        contains = frozenset(it())

        def iter_deps():
            for d in deps:
                f = self.func_by_num[d]

                if f.is_library:
                    yield d
                elif f.base in contains:
                    pass
                else:
                    yield d

        return frozenset(iter_deps())

    @property
    def special(self):
        return ['box']

    def last_elements(self, lst, must_have=True):
        def iter():
            for k in lst:
                if k in self.dd or must_have:
                    yield self.dd[k][-1]

        return list(iter())

    def prepare_funcs(self, num):
        solver = Solver(self.data)

        for func in solver.iter_infinity(num):
            func.i = len(self.func_by_num)
            self.func_by_num.append(func)
            func.deps = sorted(frozenset(func.calc_deps()), key=lambda x: -x)
            self.dd[func.base].append(func.i)
            func.codec = 'pg'

    def find_first(self, name):
        return self.dd.get(name, [-1])[0]

    def register(self):
        for v in self.func_by_num:
            yield y.ELEM({'func', v.z})
        #for v in [self.func_by_num[self.last_elements(['box'], must_have=True)[0]]]:
            #yield y.ELEM({'func': v.z})

    def iter_deps(self):
        for f in self.func_by_num:
            for d in f.deps:
                yield f.i, d

    def exec_seq(self):
        return list(y.execution_sequence(self.iter_deps()))

    def out(self):
        for x in self.func_by_num:
            x.out_deps()

    def full_deps(self, name):
        return self.full_lib_deps(name) | self.full_tool_deps(name)

    @y.cached_method
    def full_lib_deps(self, name):
        my_deps = self.by_name[name].dep_lib_list()

        def iter_lst():
            for y in my_deps:
                yield y
                yield from self.full_lib_deps(y)

        return frozenset(iter_lst())

    @y.cached_method
    def full_tool_deps(self, name):
        return frozenset(self.by_name[name].dep_tool_list())

    def find_func(self, name):
        return self.by_name[name]

    def select_deps(self, name):
        return self.last_elements(self.full_deps(name))

    @y.cached_method
    def calc(self, deps):
        return [self.func_by_num[d].f() for d in deps]


def make_proper_permutation(iface):
    yield y.EOP(y.ACCEPT('mf:original'), y.STATEFUL(), y.PROVIDES('mf:new functions'))

    class State(object):
        def __init__(self):
            self.data = []
            init_0(self.data)

    by_module = y.collections.defaultdict(State)
                
    for row in iface.iter_data():
        if not row.data:
            break
        
        by_module[parse_arch(row.data['func']['module'])].data.append(row)
        yield y.EOP()

    for mod, data in by_module.items():
        print(mod, data.data, file=y.stderr)
        
    for mod, data in by_module.items():
        os, arch = mod.split('_', 1)
        dt = Data({'os': os, 'arch': arch}, [x.data for x in data.data])
        dt.prepare_funcs(2)
        dt.out()

        for x in dt.register():
            yield y.EOP(x)

    yield y.FIN()

    
def parse_arch(s):
    res = s.split('.')[1]

    print(res, file=y.stderr)

    return res


def init_0(where):
    @y.ygenerator(where=where)
    def box0():
        return {
            'meta': {
                'kind': ['special', 'tool'],
            },
        }

+++++++++++++++++++
ic = y.inc_counter()


@y.singleton
def is_debug():
    return 'debug' in y.config.get('tow', '')


@y.cached
def subst_by_platform(os):
    common = {
        'intl': 'gettext',
        'iconv': 'libiconv',
        'c++': 'libcxx',
        'm4': 'quasar-m4',
        'termcap': 'ncurses',
        'ncurses': 'ncurses',
    }

    by_os = {
        'linux': common.copy(),
        'darwin': common.copy(),
    }

    by_os['linux'].update({'ncurses': 'netbsd-curses'})

    return by_os[os]


class Func(object):
    def do_subst(self, x):
        s = subst_by_platform(self.data.info['os'])

        x = s.get(x, x)
        x = s.get(x, x)

        return x

    def __init__(self, x, data):
        self.x = x
        self.inc_count = ic()
        self.data = data
        self.i = 0

    def out_deps(self):
        y.xprint_db('{dr}' + str(self) + '{}', '->', '(' + ', '.join([str(self.data.func_by_num[i]) for i in self.deps]) + ')')

    def contains(self):
        return self.code().get('meta', {}).get('contains', [])

    @property
    def __name__(self):
        return str(self)

    def __str__(self):
        return '<' + self.base + '-' + str(self.i) + '-' + self.compact_kind() + '-' + self.data.info['os'] + '>'

    def compact_kind(self):
        res = ''

        if self.is_tool:
            res += 't'

        if self.is_library:
            res += 'l'

        return res

    @property
    def is_library(self):
        return 'library' in self.kind

    @property
    def is_tool(self):
        return 'tool' in self.kind

    @property
    def kind(self):
        return self.x['kind']

    @y.cached_method
    def code(self):
        return self.x['code']()

    @property
    def base(self):
        return self.x['base']

    @y.cached_method
    def raw_depends(self):
        code = self.code()

        if code:
            return [self.do_subst(x) for x in self.code().get('meta', {}).get('depends', [])]

        return []

    def depends(self):
        return self.raw_depends()

    @y.cached_method
    def all_depends(self):
        def it():
            for x in self.depends():
                yield x
                yield from self.data.by_name[x].all_depends()

        return frozenset(it())

    @y.cached_method
    def dep_lib_list(self):
        def iter():
            for x in self.dep_list():
                if self.data.by_name[x].is_library:
                    yield x

        return frozenset(iter())

    @y.cached_method
    def dep_tool_list(self):
        def iter():
            for x in self.dep_list():
                if not self.data.by_name[x].is_library:
                    yield x

        return frozenset(iter())

    def extra_libs(self):
        return self.data.extra_libs()

    #@y.cached_method
    def dep_list(self):
        def iter1():
            yield from self.depends()

            for d in self.extra_libs():
                if self.base in self.data.find_func(d).all_depends():
                    continue

                if self.base == d:
                    continue

                code = self.code()

                if not code:
                    continue

                if 'code' not in code:
                    continue

                yield d

        return frozenset(iter1())

    @y.cached_method
    def run_func(self):
        data = y.dc(self.c())
        data['deps'] = y.uniq_list_x(data['deps'] + self.data.calc(self.deps))
        data['node']['codec'] = self.codec

        y.apply_meta(data['node']['meta'], y.join_metas([y.restore_node_node(d).get('meta', {}) for d in data['deps']]))

        return y.fix_pkg_name(data, self.z)

    @y.cached_method
    def c(self):
        return y.to_v2(self.code(), self.data.info)

    @property
    def f(self):
        return self.ff

    @property
    def z(self):
        return self.zz

    @y.cached_method
    def ff(self):
        return y.gen_func(self.run_func)

    @property
    @y.cached_method
    def zz(self):
        return {
            'code': self.ff,
            'base': self.base,
            'gen': 'tow',
            'kind': self.kind,
            'repacks': {},
            'info': self.data.info,
        }

    def clone(self):
        return Func(self.x, self.data)

    def calc_deps(self):
        return self.data.optimize(self.data.select_deps(self.base) + self.data.last_elements(self.data.special, must_have=False))


class SpecialFunc(Func):
    def __init__(self, x, data):
        Func.__init__(self, x, data)

    def depends(self):
        return self.data.by_kind[self.base]

    @y.cached_method
    def contains(self):
        def it():
            for x in self.depends():
                yield x
                yield from self.data.by_name[x].contains()

        return frozenset(it())

    @y.cached_method
    def f(self):
        return self.slice(self.z['code']())

    @property
    @y.cached_method
    def z(self):
        return {
            'code': y.pkg_splitter(self.zz, 'run'),
            'base': self.base,
            'gen': 'tow',
            'kind': self.kind + ['split', 'run'],
            'info': self.data.info,
            'repacks': {},
        }

    @y.cached_method
    def c(self):
        f = y.join_funcs(lambda: self.data.calc(self.deps), ex_code='(cd $IDIR/bin && (rm python* pydoc* || true)) 2> /dev/null')

        return y.restore_node(f())

    def clone(self):
        return SpecialFunc(self.x, self.data)

    def calc_deps(self):
        return self.data.last_elements(self.depends())


class Solver(object):
    def __init__(self, data, seed=1):
        self._data = data
        self._seed = seed
        self._r, self._w = y.make_engine(self._data, ntn=lambda x: x.base, dep_list=lambda x: x.dep_list(), seed=self._seed)
        self.inc_count = ic()

    def next_solver(self):
        return Solver(self._data, self._seed * 13 + 17)

    def iter_items(self):
        for el in self._r():
            self._w(el['i'])
            yield el['x']

    def iter_solvers(self, num):
        cur = self
        yield cur

        for i in range(0, num - 1):
            cur = cur.next_solver()
            yield cur

    def iter_infinity(self, num):
        for s in self.iter_solvers(num):
            for i in s.iter_items():
                yield i.clone()


class Data(object):
    def __init__(self, info, data):
        self.info = info

        self.dd = y.collections.defaultdict(list)
        self.func_by_num = []
        self.inc_count = ic()

        def iter_objects():
            for x in sorted(data, key=lambda x: x['func']['base']):
                yield self.create_object(x['func'])

        self.data = list(iter_objects())
        self.by_name = dict((x.base, x) for x in self.data)
        self.by_kind = y.collections.defaultdict(list)

        for x in self.data:
            for k in x.kind:
                self.by_kind[k].append(x.base)

    def extra_libs(self):
        tg = self.info

        if tg['os'] == 'linux':
            return ('make', 'musl', 'bestbox')

        return ('make',)

    def create_object(self, x):
        if x['base'] in self.special:
            return SpecialFunc(x, self)

        return Func(x, self)

    def optimize(self, deps):
        def it():
            for i in deps:
                yield from self.func_by_num[i].contains()

        contains = frozenset(it())

        def iter_deps():
            for d in deps:
                f = self.func_by_num[d]

                if f.is_library:
                    yield d
                elif f.base in contains:
                    pass
                else:
                    yield d

        return frozenset(iter_deps())

    @property
    def special(self):
        return ['box']

    def last_elements(self, lst, must_have=True):
        def iter():
            for k in lst:
                if k in self.dd or must_have:
                    yield self.dd[k][-1]

        return list(iter())

    def prepare_funcs(self, num):
        solver = Solver(self.data)

        for func in solver.iter_infinity(num):
            func.i = len(self.func_by_num)
            self.func_by_num.append(func)
            func.deps = sorted(frozenset(func.calc_deps()), key=lambda x: -x)
            self.dd[func.base].append(func.i)
            func.codec = 'pg'

    def find_first(self, name):
        return self.dd.get(name, [-1])[0]

    def register(self):
        for v in self.func_by_num:
            yield y.ELEM({'func', v.z})
        #for v in [self.func_by_num[self.last_elements(['box'], must_have=True)[0]]]:
            #yield y.ELEM({'func': v.z})

    def iter_deps(self):
        for f in self.func_by_num:
            for d in f.deps:
                yield f.i, d

    def exec_seq(self):
        return list(y.execution_sequence(self.iter_deps()))

    def out(self):
        for x in self.func_by_num:
            x.out_deps()

    def full_deps(self, name):
        return self.full_lib_deps(name) | self.full_tool_deps(name)

    @y.cached_method
    def full_lib_deps(self, name):
        my_deps = self.by_name[name].dep_lib_list()

        def iter_lst():
            for y in my_deps:
                yield y
                yield from self.full_lib_deps(y)

        return frozenset(iter_lst())

    @y.cached_method
    def full_tool_deps(self, name):
        return frozenset(self.by_name[name].dep_tool_list())

    def find_func(self, name):
        return self.by_name[name]

    def select_deps(self, name):
        return self.last_elements(self.full_deps(name))

    @y.cached_method
    def calc(self, deps):
        return [self.func_by_num[d].f() for d in deps]


def make_proper_permutation(iface):
    yield y.EOP(y.ACCEPT('mf:original'), y.STATEFUL(), y.PROVIDES('mf:new functions'))

    class State(object):
        def __init__(self):
            self.data = []
            init_0(self.data)

    by_module = y.collections.defaultdict(State)
                
    for row in iface.iter_data():
        if not row.data:
            break
        
        by_module[parse_arch(row.data['func']['module'])].data.append(row)
        yield y.EOP()

    for mod, data in by_module.items():
        print(mod, data.data, file=y.stderr)
        
    for mod, data in by_module.items():
        os, arch = mod.split('_', 1)
        dt = Data({'os': os, 'arch': arch}, [x.data for x in data.data])
        dt.prepare_funcs(2)
        dt.out()

        for x in dt.register():
            yield y.EOP(x)

    yield y.FIN()

    
def parse_arch(s):
    res = s.split('.')[1]

    print(res, file=y.stderr)

    return res


def init_0(where):
    @y.ygenerator(where=where)
    def box0():
        return {
            'meta': {
                'kind': ['special', 'tool'],
            },
        }

disable caching
--------------------&/ya/toolchain.py
@y.singleton
def iter_all_tools():
    ff = y.fix_v2

    def do():
        for x in y.iter_system_tools():
            yield ff(x)

    return list(do())


@y.singleton
def group_by_cc():
    res = {}

    for x in iter_all_tools():
        assert x
        assert 'codec' in x['node']

        k = y.small_repr_cons(x['node']['constraint'])

        if k in res:
            res[k].append(x)
        else:
            res[k] = [x]

        res['cc:' + k] = x['node']['constraint']

    return res


def find_toolchain_by_cc(cc):
    return y.dc(group_by_cc()[y.small_repr_cons(cc)])


@y.singleton
def get_all_constraints():
    res = []
    cc = group_by_cc()

    for k in sorted(cc.keys()):
        if k.startswith('cc:'):
            res.append(cc[k])

    return res


def score_tc(c, l, cpp):
    s = 0

    for t in (c, l, cpp):
        st = str(t)

        if 'clang' in st:
            s += 10

        if 'clang++' in st:
            s += 20

        if 'lld' in st:
            s += 100

    return s


def join_tc_meta(tcs):
    return {
        'kind': y.uniq_list_3(sum((x['meta']['kind'] for x in tcs), [])),
        'provides': sum((x['meta']['provides'] for x in tcs), []),
    }


def join_toolchains(info, tcs):
    nodes = [x['node'] for x in tcs]
    res = {
        'node': {
            'build': [],
            'prepare': sum((x.get('prepare', []) for x in nodes), []),
            'name': 'tc-' + '-'.join(x['name'] for x in nodes),
            'version': y.burn(nodes),
            'constraint': info,
            'meta': join_tc_meta(nodes),
        },
        'deps': [y.store_node(x) for x in tcs],
    }

    return y.fix_v2(res)


def score_toolchains(lst, info):
    def flt(kind):
        for o in lst:
            if kind in o['node']['meta']['kind']:
                yield o

    cc = list(flt('c'))
    cxx = list(flt('c++'))
    link = list(flt('linker'))

    def gen_all():
        for c in cc:
            for cpp in cxx:
                for l in link:
                    yield {'c': c, 'l': l, 'c++': cpp, 's': score_tc(c, l, cpp)}

    toolchains = list(sorted(list(gen_all()), key=lambda x: -x['s']))

    return [join_toolchains(info, [x['c'], x['c++'], x['l']]) for x in toolchains]


@y.cached
def iterate_best_compilers(info):
    return score_toolchains(find_toolchain_by_cc(info), info)


def find_compiler_x(info):
    def do():
        for x in iterate_best_compilers(info):
            x = y.dc(x)
            x['node']['constraint'] = info

            yield y.store_node(x)

    return list(do())[:10]


def join_versions(deps):
    def iter_v():
        for d in deps:
            yield y.restore_node_node(d)['version']

    return '-'.join(iter_v())


@y.cached
def find_compiler_id(info):
    for x in find_compiler_x(info):
        return x

    raise Exception('shit happen %s' % info)


@y.cached
def find_compilers(info):
    def iter_compilers():
        if y.is_cross(info):
            host = info['host']

            yield find_compiler_id({'target': host, 'host': host})

        yield find_compiler_id(info)

    return list(iter_compilers())

+++++++++++++++++++
@y.singleton
def iter_all_tools():
    ff = y.fix_v2

    def do():
        for x in y.iter_system_tools():
            yield ff(x)

    return list(do())


@y.singleton
def group_by_cc():
    res = {}

    for x in iter_all_tools():
        assert x
        assert 'codec' in x['node']

        k = y.small_repr_cons(x['node']['constraint'])

        if k in res:
            res[k].append(x)
        else:
            res[k] = [x]

        res['cc:' + k] = x['node']['constraint']

    return res


def find_toolchain_by_cc(cc):
    return y.dc(group_by_cc()[y.small_repr_cons(cc)])


@y.singleton
def get_all_constraints():
    res = []
    cc = group_by_cc()

    for k in sorted(cc.keys()):
        if k.startswith('cc:'):
            res.append(cc[k])

    return res


def score_tc(c, l, cpp):
    s = 0

    for t in (c, l, cpp):
        st = str(t)

        if 'clang' in st:
            s += 10

        if 'clang++' in st:
            s += 20

        if 'lld' in st:
            s += 100

    return s


def join_tc_meta(tcs):
    return {
        'kind': y.uniq_list_3(sum((x['meta']['kind'] for x in tcs), [])),
        'provides': sum((x['meta']['provides'] for x in tcs), []),
    }


def join_toolchains(info, tcs):
    nodes = [x['node'] for x in tcs]
    res = {
        'node': {
            'build': [],
            'prepare': sum((x.get('prepare', []) for x in nodes), []),
            'name': 'tc-' + '-'.join(x['name'] for x in nodes),
            'version': y.burn(nodes),
            'constraint': info,
            'meta': join_tc_meta(nodes),
        },
        'deps': [y.store_node(x) for x in tcs],
    }

    return y.fix_v2(res)


def score_toolchains(lst, info):
    def flt(kind):
        for o in lst:
            if kind in o['node']['meta']['kind']:
                yield o

    cc = list(flt('c'))
    cxx = list(flt('c++'))
    link = list(flt('linker'))

    def gen_all():
        for c in cc:
            for cpp in cxx:
                for l in link:
                    yield {'c': c, 'l': l, 'c++': cpp, 's': score_tc(c, l, cpp)}

    toolchains = list(sorted(list(gen_all()), key=lambda x: -x['s']))

    return [join_toolchains(info, [x['c'], x['c++'], x['l']]) for x in toolchains]


@y.cached
def iterate_best_compilers(info):
    return score_toolchains(find_toolchain_by_cc(info), info)


def find_compiler_x(info):
    def do():
        for x in iterate_best_compilers(info):
            x = y.dc(x)
            x['node']['constraint'] = info

            yield y.store_node(x)

    return list(do())[:10]


def join_versions(deps):
    def iter_v():
        for d in deps:
            yield y.restore_node_node(d)['version']

    return '-'.join(iter_v())


@y.cached
def find_compiler_id(info):
    for x in find_compiler_x(info):
        return x

    raise Exception('shit happen %s' % info)


@y.cached
def find_compilers(info):
    def iter_compilers():
        if y.is_cross(info):
            host = info['host']

            yield find_compiler_id({'target': host, 'host': host})

        yield find_compiler_id(info)

    return list(iter_compilers())

disable caching
disable caching
disable caching
--------------------&/ya/ygen.py
def subst_some_values(v):
    def gen_some_subst(k, v):
        yield k, v
        yield '_' + k + '_', v.replace('.', '_').replace('-', '_')

    if 'code' in v and '{' in v['code']:
        v = y.dc(v)

        for x in ('version', 'name', 'num'):
            if x in v:
                for p1, p2 in gen_some_subst(x, v[x]):
                    v['code'] = v['code'].replace('{' + p1 + '}', p2)

    return v


def exec_plugin_code(iface):
    yield y.EOP(y.ACCEPT('mf:plugin'), y.PROVIDES('mf:original'))

    for data in iface.iter_data():
        if not data.data:
            yield y.FIN()
            y.os.abort()
        
        code = data.data['el']
        cc = data.data['cc']
        name = code['name']
        name = name.replace('/', '.')

        if name.endswith('.py'):
            name = name[:-3]

        y.xprint_blue('ygen', code, name, cc)
            
        mod = __yexec__(code['data'], module_name=name, arch=cc)

        try:
            for x in mod.event:
                yield x
        except AttributeError:
            pass

    yield y.EOP()


def ygenerator(where=None):
    def functor(func):
        base_name = func.__name__[:-1]
        new_f = y.compose_simple(func, y.dc, subst_some_values)
        descr = {
            'gen': 'human',
            'base': base_name.replace('_', '-'),
            'kind': new_f()['meta']['kind'],
            'code': new_f,
            'module': func.__module__,
        }

        assert 'codec' not in new_f()

        ev = y.ELEM({'func': descr})

        if where is not None:
            where.append(ev)
        else:
            fg = func.__globals__
            fg['event'] = fg.get('event', []) + [ev]

        return func

    return functor

+++++++++++++++++++
def subst_some_values(v):
    def gen_some_subst(k, v):
        yield k, v
        yield '_' + k + '_', v.replace('.', '_').replace('-', '_')

    if 'code' in v and '{' in v['code']:
        v = y.dc(v)

        for x in ('version', 'name', 'num'):
            if x in v:
                for p1, p2 in gen_some_subst(x, v[x]):
                    v['code'] = v['code'].replace('{' + p1 + '}', p2)

    return v


def exec_plugin_code(iface):
    yield y.EOP(y.ACCEPT('mf:plugin'), y.PROVIDES('mf:original'))

    for data in iface.iter_data():
        if not data.data:
            yield y.FIN()
            y.os.abort()
        
        code = data.data['el']
        cc = data.data['cc']
        name = code['name']
        name = name.replace('/', '.')

        if name.endswith('.py'):
            name = name[:-3]

        y.xprint_blue('ygen', code, name, cc)
            
        mod = __yexec__(code['data'], module_name=name, arch=cc)

        try:
            for x in mod.event:
                yield x
        except AttributeError:
            pass

    yield y.EOP()


def ygenerator(where=None):
    def functor(func):
        base_name = func.__name__[:-1]
        new_f = y.compose_simple(func, y.dc, subst_some_values)
        descr = {
            'gen': 'human',
            'base': base_name.replace('_', '-'),
            'kind': new_f()['meta']['kind'],
            'code': new_f,
            'module': func.__module__,
        }

        assert 'codec' not in new_f()

        ev = y.ELEM({'func': descr})

        if where is not None:
            where.append(ev)
        else:
            fg = func.__globals__
            fg['event'] = fg.get('event', []) + [ev]

        return func

    return functor

--------------------&/ya/subst.py
def subst_kv_base(data, *iterables):
    for k, v in y.itertools.chain(*iterables):
        data = data.replace(k, v)

    return data

+++++++++++++++++++
def subst_kv_base(data, *iterables):
    for k, v in y.itertools.chain(*iterables):
        data = data.replace(k, v)

    return data

--------------------&/ya/main.py
async def gen_full_dump(iter_cc):
    portion = await gen_mk_data(list(iter_cc()))
    lst = [y.restore_node_node(d) for d in sorted(portion)]

    y.stdout.write(y.json.dumps(sorted(lst, key=lambda x: x['name']), indent=4, sort_keys=True))


async def gen_mk_data(cc):
    funcs = []

    await y.pubsub.run(init=[y.mf_function_holder_gen(cc, funcs.append)])

    return funcs


async def main_makefile(iter_cc, internal=False):
    cc = list(iter_cc())
    portion = await gen_mk_data(cc)

    return await y.build_makefile([x['code']() for x in portion], internal=internal)

+++++++++++++++++++
async def gen_full_dump(iter_cc):
    portion = await gen_mk_data(list(iter_cc()))
    lst = [y.restore_node_node(d) for d in sorted(portion)]

    y.stdout.write(y.json.dumps(sorted(lst, key=lambda x: x['name']), indent=4, sort_keys=True))


async def gen_mk_data(cc):
    funcs = []

    await y.pubsub.run(init=[y.mf_function_holder_gen(cc, funcs.append)])

    return funcs


async def main_makefile(iter_cc, internal=False):
    cc = list(iter_cc())
    portion = await gen_mk_data(cc)

    return await y.build_makefile([x['code']() for x in portion], internal=internal)

--------------------&/ya/prop_db.py
def compactify(l):
    return list(reversed(list(y.uniq_list_0(reversed(l)))))


class PropertyDB(object):
    def __init__(self, db):
        self.db = db
        self.ensure('images', {})
        self.ensure('kv', {})

        for k in list(self.db.keys()):
            if k not in ('kv', 'images'):
                self.db.pop(k)

        for k in list(self.images.keys()):
            self.images[k] = compactify(self.images[k])

    def ensure(self, k, d):
        y.get_key(self.db, k, d)

    @property
    def images(self):
        return self.db['images']

    @property
    def kv(self):
        return self.db['kv']


@y.contextlib.contextmanager
def open_pdb():
    with y.open_simple_db('~/.upmdb') as db:
        yield PropertyDB(db)

+++++++++++++++++++
def compactify(l):
    return list(reversed(list(y.uniq_list_0(reversed(l)))))


class PropertyDB(object):
    def __init__(self, db):
        self.db = db
        self.ensure('images', {})
        self.ensure('kv', {})

        for k in list(self.db.keys()):
            if k not in ('kv', 'images'):
                self.db.pop(k)

        for k in list(self.images.keys()):
            self.images[k] = compactify(self.images[k])

    def ensure(self, k, d):
        y.get_key(self.db, k, d)

    @property
    def images(self):
        return self.db['images']

    @property
    def kv(self):
        return self.db['kv']


@y.contextlib.contextmanager
def open_pdb():
    with y.open_simple_db('~/.upmdb') as db:
        yield PropertyDB(db)

--------------------&/ya/decor.py
def gen_func(func):
    d = gen_func.__dict__

    try:
        d['']
    except KeyError:
        d[''] = y.compose_simple(y.call_v2, y.fix_v2, y.store_node)

    return d[''](func)

+++++++++++++++++++
def gen_func(func):
    d = gen_func.__dict__

    try:
        d['']
    except KeyError:
        d[''] = y.compose_simple(y.call_v2, y.fix_v2, y.store_node)

    return d[''](func)

--------------------&/ya/cli_db.py
@y.main_entry_point
async def cli_db_set(args):
    assert len(args) == 2

    with y.open_pdb() as db:
        db.kv[args[0]] = args[1]


@y.main_entry_point
async def cli_db_get(arg):
    assert len(arg) == 1

    with y.open_pdb() as db:
        print(db.kv.get(arg[0], '{br}no such key{}'))


@y.main_entry_point
async def cli_db_dump(args):
    with y.open_pdb() as db:
        print(y.json.dumps(db.db, indent=4, sort_keys=True))

+++++++++++++++++++
@y.main_entry_point
async def cli_db_set(args):
    assert len(args) == 2

    with y.open_pdb() as db:
        db.kv[args[0]] = args[1]


@y.main_entry_point
async def cli_db_get(arg):
    assert len(arg) == 1

    with y.open_pdb() as db:
        print(db.kv.get(arg[0], '{br}no such key{}'))


@y.main_entry_point
async def cli_db_dump(args):
    with y.open_pdb() as db:
        print(y.json.dumps(db.db, indent=4, sort_keys=True))

--------------------&/ya/graph_wiz.py
async def build_dot_script():
    mk = await y.main_makefile(internal=True)
    mk = await y.decode_mk(mk)

    return build_dot_script_0(mk)


def build_dot_script_0(mk):
    lst = mk.lst

    def fix(x):
        return x[1:].replace('/', '-').replace('-', '')

    def iter():
        yield 'digraph G {'

        for c in lst:
            if c.get('cmd'):
                for a in mk.num_to_str(c['deps1']):
                    for b in mk.num_to_str(c['deps2']):
                        yield '    ' + fix(a) + ' -> ' + fix(b) + ';'

        yield '}'

    return '\n'.join(iter()) + '\n'

+++++++++++++++++++
async def build_dot_script():
    mk = await y.main_makefile(internal=True)
    mk = await y.decode_mk(mk)

    return build_dot_script_0(mk)


def build_dot_script_0(mk):
    lst = mk.lst

    def fix(x):
        return x[1:].replace('/', '-').replace('-', '')

    def iter():
        yield 'digraph G {'

        for c in lst:
            if c.get('cmd'):
                for a in mk.num_to_str(c['deps1']):
                    for b in mk.num_to_str(c['deps2']):
                        yield '    ' + fix(a) + ' -> ' + fix(b) + ';'

        yield '}'

    return '\n'.join(iter()) + '\n'

--------------------&/ya/helpers.py
def find_tool_uncached_0(tool, path):
    for p in y.itertools.chain(path, y.os.environ['PATH'].split(':')):
        pp = y.os.path.join(p, tool)

        if y.os.path.isfile(pp):
            yield pp


def find_tool_uncached(tool, path):
    for x in find_tool_uncached_0(tool, path):
        return x


@y.singleton
def getuser():
    return y.os.getusername()


@y.singleton
def user_home():
    return y.os.path.expanduser('~')


def upm_root():
    return user_home() + '/upm_root'


@y.cached
def find_tool(name):
    return list(find_tool_uncached_0(name, []))


@y.singleton
def docker_binary():
    return find_tool('docker')[0]

+++++++++++++++++++
def find_tool_uncached_0(tool, path):
    for p in y.itertools.chain(path, y.os.environ['PATH'].split(':')):
        pp = y.os.path.join(p, tool)

        if y.os.path.isfile(pp):
            yield pp


def find_tool_uncached(tool, path):
    for x in find_tool_uncached_0(tool, path):
        return x


@y.singleton
def getuser():
    return y.os.getusername()


@y.singleton
def user_home():
    return y.os.path.expanduser('~')


def upm_root():
    return user_home() + '/upm_root'


@y.cached
def find_tool(name):
    return list(find_tool_uncached_0(name, []))


@y.singleton
def docker_binary():
    return find_tool('docker')[0]

disable caching
--------------------&/ya/cli_source.py
def fetch_data(url):
    def fetch_1(url):
        import urllib.request as urllib2

        return urllib2.urlopen(url).read()

    def fetch_2(url):
        return y.subprocess.check_output(['curl -s -S --retry 3 -L -k -o - ' + url], shell=True)

    def fetch_3(url):
        return y.subprocess.check_output(['curl -s -S --retry 3 -L -o - ' + url], shell=True)

    e = None

    for f in (fetch_1, fetch_2, fetch_1, fetch_3):
        try:
            return f(url)
        except Exception as err:
            e = err
            y.xprint_r(e)

    if e:
        raise e


def fetch_http(root, url, name=None, untar=True):
    name = name or y.os.path.basename(url)
    fname = y.os.path.join(root, name)
    data = fetch_data(url)

    try:
        y.os.makedirs(root)
    except OSError:
        pass

    with open(fname, 'w') as f:
        f.buffer.write(data)

    if untar:
        if '.zip' in name:
            y.subprocess.check_output(['unzip ' + name], cwd=root, shell=True)
        else:
            y.subprocess.check_output(['tar -xf ' + name], cwd=root, shell=True)

    return fname


@y.main_entry_point
async def cli_pkg_source(arg):
    parser = y.argparse.ArgumentParser()

    parser.add_argument('--path', default='data', action='store', help='Where to store all')
    parser.add_argument('targets', nargs=y.argparse.REMAINDER)

    args = parser.parse_args(arg)
    args.path = y.os.path.abspath(args.path)

    async def find_func():
        funcs = await y.gen_mk_data(list(y.iter_cc()))

        def do():
            for d in funcs:
                n = (d['gen'] + '-' + d['base']).replace('-', '_')
                c = d['code']

                yield n, c

        return dict(do())

    funcs = await find_func()

    @y.lookup
    def lookup(name):
        return funcs[name]

    def iter_urls():
        for t in args.targets:
            if t.startswith('http'):
                yield url
            else:
                t = t.replace('-', '_')
                node = y.restore_node_node(eval('y.' + t)())
                url = node.get('src') or node.get('url')

                if url:
                    yield url

                urls = node.get('urls')

                if urls:
                    for url in urls:
                        yield url
   
    for url in iter_urls():
        print('will fetch', url, fetch_http(args.path, url))

+++++++++++++++++++
def fetch_data(url):
    def fetch_1(url):
        import urllib.request as urllib2

        return urllib2.urlopen(url).read()

    def fetch_2(url):
        return y.subprocess.check_output(['curl -s -S --retry 3 -L -k -o - ' + url], shell=True)

    def fetch_3(url):
        return y.subprocess.check_output(['curl -s -S --retry 3 -L -o - ' + url], shell=True)

    e = None

    for f in (fetch_1, fetch_2, fetch_1, fetch_3):
        try:
            return f(url)
        except Exception as err:
            e = err
            y.xprint_r(e)

    if e:
        raise e


def fetch_http(root, url, name=None, untar=True):
    name = name or y.os.path.basename(url)
    fname = y.os.path.join(root, name)
    data = fetch_data(url)

    try:
        y.os.makedirs(root)
    except OSError:
        pass

    with open(fname, 'w') as f:
        f.buffer.write(data)

    if untar:
        if '.zip' in name:
            y.subprocess.check_output(['unzip ' + name], cwd=root, shell=True)
        else:
            y.subprocess.check_output(['tar -xf ' + name], cwd=root, shell=True)

    return fname


@y.main_entry_point
async def cli_pkg_source(arg):
    parser = y.argparse.ArgumentParser()

    parser.add_argument('--path', default='data', action='store', help='Where to store all')
    parser.add_argument('targets', nargs=y.argparse.REMAINDER)

    args = parser.parse_args(arg)
    args.path = y.os.path.abspath(args.path)

    async def find_func():
        funcs = await y.gen_mk_data(list(y.iter_cc()))

        def do():
            for d in funcs:
                n = (d['gen'] + '-' + d['base']).replace('-', '_')
                c = d['code']

                yield n, c

        return dict(do())

    funcs = await find_func()

    @y.lookup
    def lookup(name):
        return funcs[name]

    def iter_urls():
        for t in args.targets:
            if t.startswith('http'):
                yield url
            else:
                t = t.replace('-', '_')
                node = y.restore_node_node(eval('y.' + t)())
                url = node.get('src') or node.get('url')

                if url:
                    yield url

                urls = node.get('urls')

                if urls:
                    for url in urls:
                        yield url
   
    for url in iter_urls():
        print('will fetch', url, fetch_http(args.path, url))

--------------------&/ya/gen_common.py
def fix_user_data(iter):
    for f in iter:
        yield y.dc(f)


def common_plugins(iface, cc):
    yield y.EOP(y.ACCEPT(), y.PROVIDES('mf:plugin'))
    
    for el in sorted(y.globals.file_data, key=lambda x: y.burn([4, x['name']])):
        if el['name'].startswith('pl/'):
            yield y.ELEM({'el': el, 'cc': cc})

    yield y.FIN()


def common_plugins_gen(cc):
    def cc_plugins(iface):
        yield from common_plugins(iface, cc)

    cc_plugins.__name__ = 'cc_plugins_' + y.small_repr(cc)
        
    return cc_plugins
    

def mf_function_holder(cc, cb, iface):
    yield y.EOP(y.ACCEPT())

    lst_f = [y.make_proper_permutation] + [common_plugins_gen(x) for x in cc] + [
        y.FuncAggr(cb).on_new_data,
        y.exec_plugin_code,
    ]

    for l in lst_f:
        yield y.DEFUN(l)

    yield y.FIN()


def mf_function_holder_gen(cc, cb):
    def func(iface):
        yield from mf_function_holder(cc, cb, iface)

    func.__name__ = 'mf_function_holder_generator_' + '_'.join(str(x) for x in cc)

    return func


def aggr_flag(name, metas):
    data = sum((m.get(name, []) for m in metas), [])

    try:
        return sorted(frozenset(data))
    except TypeError:
        return data


def join_metas(metas, merge=['flags']):
    return dict((x, aggr_flag(x, metas)) for x in merge)


def apply_meta(to, fr):
    to.update(join_metas([to, fr]))

+++++++++++++++++++
def fix_user_data(iter):
    for f in iter:
        yield y.dc(f)


def common_plugins(iface, cc):
    yield y.EOP(y.ACCEPT(), y.PROVIDES('mf:plugin'))
    
    for el in sorted(y.globals.file_data, key=lambda x: y.burn([4, x['name']])):
        if el['name'].startswith('pl/'):
            yield y.ELEM({'el': el, 'cc': cc})

    yield y.FIN()


def common_plugins_gen(cc):
    def cc_plugins(iface):
        yield from common_plugins(iface, cc)

    cc_plugins.__name__ = 'cc_plugins_' + y.small_repr(cc)
        
    return cc_plugins
    

def mf_function_holder(cc, cb, iface):
    yield y.EOP(y.ACCEPT())

    lst_f = [y.make_proper_permutation] + [common_plugins_gen(x) for x in cc] + [
        y.FuncAggr(cb).on_new_data,
        y.exec_plugin_code,
    ]

    for l in lst_f:
        yield y.DEFUN(l)

    yield y.FIN()


def mf_function_holder_gen(cc, cb):
    def func(iface):
        yield from mf_function_holder(cc, cb, iface)

    func.__name__ = 'mf_function_holder_generator_' + '_'.join(str(x) for x in cc)

    return func


def aggr_flag(name, metas):
    data = sum((m.get(name, []) for m in metas), [])

    try:
        return sorted(frozenset(data))
    except TypeError:
        return data


def join_metas(metas, merge=['flags']):
    return dict((x, aggr_flag(x, metas)) for x in merge)


def apply_meta(to, fr):
    to.update(join_metas([to, fr]))

--------------------&/ya/v1_to_v2.py
def call_v2(func):
    data = func()

    if y.is_pointer(data):
        data = y.restore_node(data)

    return data


@y.cached()
def to_v2(data, info):
    print(data, info, file=y.stderr)
    node = y.copy.copy(data)
    node.pop('deps', None)

    code = node.pop('code', '')
    prepare = node.pop('prepare', '')
    full = '\n'.join((code, prepare))

    node['constraint'] = info
    node['prepare'] = y.to_lines(prepare)
    node['build'] = y.to_lines(code)

    if all((y not in full) for y in ('#pragma cc', './configure', 'YMAKE', '$CC', '$CXX', 'gcc', 'clang')):
        compilers = []
    else:
        compilers = y.find_compilers(info)

    return y.fix_v2({
        'node': node,
        'deps': list(y.itertools.chain(compilers, data.get('deps', [])))
    })

+++++++++++++++++++
def call_v2(func):
    data = func()

    if y.is_pointer(data):
        data = y.restore_node(data)

    return data


@y.cached()
def to_v2(data, info):
    print(data, info, file=y.stderr)
    node = y.copy.copy(data)
    node.pop('deps', None)

    code = node.pop('code', '')
    prepare = node.pop('prepare', '')
    full = '\n'.join((code, prepare))

    node['constraint'] = info
    node['prepare'] = y.to_lines(prepare)
    node['build'] = y.to_lines(code)

    if all((y not in full) for y in ('#pragma cc', './configure', 'YMAKE', '$CC', '$CXX', 'gcc', 'clang')):
        compilers = []
    else:
        compilers = y.find_compilers(info)

    return y.fix_v2({
        'node': node,
        'deps': list(y.itertools.chain(compilers, data.get('deps', [])))
    })

disable caching
--------------------&/ut/stage0.py
def run_stage0(g):
    def iter_modules():
        yield 'ut/iface.py'
        yield 'ut/mod_load.py'
        yield 'ut/stage1.py'

    def iter_data():
        for i in iter_modules():
            yield g.by_name[i]['data']

        yield '\nrun_stage1(_globals)\n'

    ctx = {'_globals': g}
    exec(g.compile('\n'.join(iter_data()), '0:stage1.py', 'exec'), ctx)
    ctx.clear()

+++++++++++++++++++
def run_stage0(g):
    def iter_modules():
        yield 'ut/iface.py'
        yield 'ut/mod_load.py'
        yield 'ut/stage1.py'

    def iter_data():
        for i in iter_modules():
            yield g.by_name[i]['data']

        yield '\nrun_stage1(_globals)\n'

    ctx = {'_globals': g}
    exec(g.compile('\n'.join(iter_data()), '0:stage1.py', 'exec'), ctx)
    ctx.clear()

--------------------&/ut/cli_pgmake.py
@y.main_entry_point
async def cli_cmd_pgmake(args):
    p = y.argparse.ArgumentParser()

    p.add_argument('-j', '--threads', default=1, action='store', help='set num threads')
    p.add_argument('-f', '--path', default='', action='store', help='path to Makefile, "-" - read from stdin')
    p.add_argument('-s', '--set', default=[], action='append', help='set shell variable for makefile')
    p.add_argument('targets', nargs=y.argparse.REMAINDER)

    args = p.parse_args(args)
    mk = await y.open_mk_file(args.path)

    def iter_vars():
        for i in args.set:
            k, v = i.split('=')

            yield '$' + k, v

    await mk.build_kw(shell_vars=dict(iter_vars()), threads=args.threads, targets=args.targets, pre_run=[])

+++++++++++++++++++
@y.main_entry_point
async def cli_cmd_pgmake(args):
    p = y.argparse.ArgumentParser()

    p.add_argument('-j', '--threads', default=1, action='store', help='set num threads')
    p.add_argument('-f', '--path', default='', action='store', help='path to Makefile, "-" - read from stdin')
    p.add_argument('-s', '--set', default=[], action='append', help='set shell variable for makefile')
    p.add_argument('targets', nargs=y.argparse.REMAINDER)

    args = p.parse_args(args)
    mk = await y.open_mk_file(args.path)

    def iter_vars():
        for i in args.set:
            k, v = i.split('=')

            yield '$' + k, v

    await mk.build_kw(shell_vars=dict(iter_vars()), threads=args.threads, targets=args.targets, pre_run=[])

--------------------&/ut/micro_cli.py
@y.verbose_entry_point
async def cli_test_offload(args):
    print(await y.async_loop.offload(lambda: y.subprocess.check_output("ls -la", shell=True)), file=y.stderr)


@y.verbose_entry_point
async def cli_test_ctx(args):
    async def func1():
        c = y.current_coro()

        while True:
            await c.sleep(1)
            print(c)

    async def func2():
        c = y.current_coro()

        while True:
            await c.sleep(2)
            print(c)

    a1 = y.current_coro().spawn(func1)
    a2 = y.current_coro().spawn(func2)

    await a1
    await a2


@y.asyncio.coroutine
def awkward_suspend():
    yield


@y.verbose_entry_point
async def cli_test_queue(args):
    q = y.QQ(y.async_loop)
    #q = y.MTQ()
    #q = y.PQ()

    async def func1(ctl):
        while True:
            for i in range(0, 2000):
                print(await q.async_pop(), file=y.stderr)
                await ctl.sched_yield()
                q.push(int(y.random.random() * 1000))
                q.push(int(y.random.random() * 1000))

    async def func3(ctl):
        while True:
            for i in range(0, 500):
                print(await q.async_pop(), file=y.stderr)
                await q.async_pop()
                await ctl.sched_yield()
                q.push(int(y.random.random() * 1000))

    async def func2(ctl):
        while True:
            for i in range(0, 100):
                q.push(int(y.random.random() * 1000))

            await ctl.sched_yield()

            for i in range(0, 100):
                await q.async_pop()

    c = []

    for i in range(0, 20):
        c.append(y.spawn(func1, 'func1_' + str(i)))
        c.append(y.spawn(func2, 'func2_' + str(i)))
        c.append(y.spawn(func3, 'func3_' + str(i)))

    for x in c:
        await x


@y.verbose_entry_point
async def cli_test_pubsub(args):
    ps = y.PubSubLoop()

    async def f1(ctl, inq):
        yield y.EOP(y.ACCEPT('A'), y.PROVIDES('B'))
        yield y.EOP(y.ELEM(2))

        async for i in inq:
            i = i.data.data
            print('f1', i)
            yield y.EOP(y.ELEM(i))

        yield y.FIN()

    async def f2(ctl, inq):
        yield y.EOP(y.ACCEPT('B'), y.PROVIDES('A'))
        yield y.EOP(y.ELEM(1))

        async for i in inq:
            i = i.data.data
            print('f2', i)
            yield y.EOP(y.ELEM(i))

        yield y.FIN()

    ps.wrap_coro(f1)
    ps.wrap_coro(f2)

    await ps.run()


@y.verbose_entry_point
async def cli_test_template(args):
    d = y.collections.deque([1, 2, 3])

    if args[0] == 'sync':
        for i in y.deque_iter_sync(d):
            print(i)
    else:
        async for i in y.deque_iter_async(d):
            print(i)


@y.verbose_entry_point
async def cli_misc_timeout(args):
    import os

    tout = int(args[0])
    pid = os.fork()

    if pid:
        y.time.sleep(tout)
        os.kill(pid, y.signal.SIGINT)
        os.waitpid(pid, 0)
        os._exit(0)
    else:
        os.execv(args[1], args[1:])

   
@y.verbose_entry_point
async def cli_test_wait(args):
    while True:
        await y.current_coro().sleep(1)


@y.verbose_entry_point
async def cli_test_green(args):
    async def func1():
        c = y.current_coro()

        while True:
            await c.sleep(1)
            print(c)

    def func2(ctl):
        c = y.current_coro()

        while True:
            yield from y.current_coro().slave ** c.sleep(2)
            print(c)

    a1 = y.current_coro().spawn(func1)
    a2 = y.current_coro().spawn(func2)

    await a1
    await a2


@y.verbose_entry_point
async def cli_test_preproc(args):
    test_preproc_x(args)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  

+++++++++++++++++++
@y.verbose_entry_point
async def cli_test_offload(args):
    print(await y.async_loop.offload(lambda: y.subprocess.check_output("ls -la", shell=True)), file=y.stderr)


@y.verbose_entry_point
async def cli_test_ctx(args):
    async def func1():
        c = y.current_coro()

        while True:
            await c.sleep(1)
            print(c)

    async def func2():
        c = y.current_coro()

        while True:
            await c.sleep(2)
            print(c)

    a1 = y.current_coro().spawn(func1)
    a2 = y.current_coro().spawn(func2)

    await a1
    await a2


@y.asyncio.coroutine
def awkward_suspend():
    yield


@y.verbose_entry_point
async def cli_test_queue(args):
    q = y.QQ(y.async_loop)
    #q = y.MTQ()
    #q = y.PQ()

    async def func1(ctl):
        while True:
            for i in range(0, 2000):
                print(await q.async_pop(), file=y.stderr)
                await ctl.sched_yield()
                q.push(int(y.random.random() * 1000))
                q.push(int(y.random.random() * 1000))

    async def func3(ctl):
        while True:
            for i in range(0, 500):
                print(await q.async_pop(), file=y.stderr)
                await q.async_pop()
                await ctl.sched_yield()
                q.push(int(y.random.random() * 1000))

    async def func2(ctl):
        while True:
            for i in range(0, 100):
                q.push(int(y.random.random() * 1000))

            await ctl.sched_yield()

            for i in range(0, 100):
                await q.async_pop()

    c = []

    for i in range(0, 20):
        c.append(y.spawn(func1, 'func1_' + str(i)))
        c.append(y.spawn(func2, 'func2_' + str(i)))
        c.append(y.spawn(func3, 'func3_' + str(i)))

    for x in c:
        await x


@y.verbose_entry_point
async def cli_test_pubsub(args):
    ps = y.PubSubLoop()

    async def f1(ctl, inq):
        yield y.EOP(y.ACCEPT('A'), y.PROVIDES('B'))
        yield y.EOP(y.ELEM(2))

        async for i in inq:
            i = i.data.data
            print('f1', i)
            yield y.EOP(y.ELEM(i))

        yield y.FIN()

    async def f2(ctl, inq):
        yield y.EOP(y.ACCEPT('B'), y.PROVIDES('A'))
        yield y.EOP(y.ELEM(1))

        async for i in inq:
            i = i.data.data
            print('f2', i)
            yield y.EOP(y.ELEM(i))

        yield y.FIN()

    ps.wrap_coro(f1)
    ps.wrap_coro(f2)

    await ps.run()


@y.verbose_entry_point
async def cli_test_template(args):
    d = y.collections.deque([1, 2, 3])

    if args[0] == 'sync':
        for i in y.deque_iter_sync(d):
            print(i)
    else:
        async for i in y.deque_iter_async(d):
            print(i)


@y.verbose_entry_point
async def cli_misc_timeout(args):
    import os

    tout = int(args[0])
    pid = os.fork()

    if pid:
        y.time.sleep(tout)
        os.kill(pid, y.signal.SIGINT)
        os.waitpid(pid, 0)
        os._exit(0)
    else:
        os.execv(args[1], args[1:])

   
@y.verbose_entry_point
async def cli_test_wait(args):
    while True:
        await y.current_coro().sleep(1)


@y.verbose_entry_point
async def cli_test_green(args):
    async def func1():
        c = y.current_coro()

        while True:
            await c.sleep(1)
            print(c)

    def func2(ctl):
        c = y.current_coro()

        while True:
            yield from y.current_coro().slave ** c.sleep(2)
            print(c)

    a1 = y.current_coro().spawn(func1)
    a2 = y.current_coro().spawn(func2)

    await a1
    await a2


@y.verbose_entry_point
async def cli_test_preproc(args):
    test_preproc_x(args)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  

--------------------&/ut/gc_utils.py
@y.contextlib.contextmanager
def without_gc(print_stats=False):
    ygc = y.gc

    try:
        ygc.disable()

        yield ygc
    finally:
        ygc.enable()

        if print_stats:
            if ygc.garbage:
                y.xprint_r('gc garbage left:', ygc.garbage)

+++++++++++++++++++
@y.contextlib.contextmanager
def without_gc(print_stats=False):
    ygc = y.gc

    try:
        ygc.disable()

        yield ygc
    finally:
        ygc.enable()

        if print_stats:
            if ygc.garbage:
                y.xprint_r('gc garbage left:', ygc.garbage)

--------------------&/ut/color.py
ATTRIBUTES = dict(
    list(zip(
        [
            'bold',
            'dark',
            '',
            'underline',
            'blink',
            '',
            'reverse',
            'concealed'
        ], list(range(1, 9)))))

del ATTRIBUTES['']

ATTRIBUTES['light'] = ATTRIBUTES['bold']

HIGHLIGHTS = dict(
    list(zip([
        'on_grey',
        'on_red',
        'on_green',
        'on_yellow',
        'on_blue',
        'on_magenta',
        'on_cyan',
        'on_white'
    ], list(range(40, 48)))))

COLORS = dict(
    list(zip([
        'steel',
        'red',
        'green',
        'yellow',
        'blue',
        'magenta',
        'cyan',
        'white',
    ], list(range(30, 38)))))

COLORS['reset'] = 0


def get_code(code):
    return "\033[{}m".format(code)


def get_color_0(color, on_color):
    res = ''

    if color is not None:
        res += get_code(COLORS[color])

    if on_color is not None:
        res += get_code(HIGHLIGHTS[on_color])

    return res


def color_key(color, on_color):
    return str(color) + '-' + str(on_color)


def iter_all_colors():
    for c in list(COLORS.keys()) + [None]:
        for o in list(HIGHLIGHTS.keys()) + [None]:
            yield color_key(c, o), get_color_0(c, o)


CC = dict(iter_all_colors())


def get_color_ext(color, on_color=None, attrs=[]):
    res = CC[color_key(color, on_color)]

    for attr in attrs:
        res += get_code(ATTRIBUTES[attr])

    return res


def iter_synonyms():
    for c in COLORS:
        if c == 'reset':
            continue

        yield c[0], c
        yield c, c


def iter_combo():
    attrs = [[], ['bold'], ['dark'], ['bold', 'dark']]

    for s, c in iter_synonyms():
        for a in attrs:
            if len(s) == 1:
                aa = [x[0] for x in a]
            else:
                aa = a

            name = ''.join(aa + [s])
            b = [x for x in a]

            yield name, c, b
            yield '{' + name + '}', c, b


def iter_full_table():
    for n, c, a in iter_combo():
        yield n, get_color_ext(c, on_color=None, attrs=a)

    for r in ('', 'rst', 'reset'):
        yield r, get_code(0)
        yield '{' + r + '}', get_code(0)


COLOR_TABLE = dict(iter_full_table())


def get_color(n):
    return COLOR_TABLE[n]


def colorize(text, color):
    return get_color(color) + text + get_color('')

+++++++++++++++++++
ATTRIBUTES = dict(
    list(zip(
        [
            'bold',
            'dark',
            '',
            'underline',
            'blink',
            '',
            'reverse',
            'concealed'
        ], list(range(1, 9)))))

del ATTRIBUTES['']

ATTRIBUTES['light'] = ATTRIBUTES['bold']

HIGHLIGHTS = dict(
    list(zip([
        'on_grey',
        'on_red',
        'on_green',
        'on_yellow',
        'on_blue',
        'on_magenta',
        'on_cyan',
        'on_white'
    ], list(range(40, 48)))))

COLORS = dict(
    list(zip([
        'steel',
        'red',
        'green',
        'yellow',
        'blue',
        'magenta',
        'cyan',
        'white',
    ], list(range(30, 38)))))

COLORS['reset'] = 0


def get_code(code):
    return "\033[{}m".format(code)


def get_color_0(color, on_color):
    res = ''

    if color is not None:
        res += get_code(COLORS[color])

    if on_color is not None:
        res += get_code(HIGHLIGHTS[on_color])

    return res


def color_key(color, on_color):
    return str(color) + '-' + str(on_color)


def iter_all_colors():
    for c in list(COLORS.keys()) + [None]:
        for o in list(HIGHLIGHTS.keys()) + [None]:
            yield color_key(c, o), get_color_0(c, o)


CC = dict(iter_all_colors())


def get_color_ext(color, on_color=None, attrs=[]):
    res = CC[color_key(color, on_color)]

    for attr in attrs:
        res += get_code(ATTRIBUTES[attr])

    return res


def iter_synonyms():
    for c in COLORS:
        if c == 'reset':
            continue

        yield c[0], c
        yield c, c


def iter_combo():
    attrs = [[], ['bold'], ['dark'], ['bold', 'dark']]

    for s, c in iter_synonyms():
        for a in attrs:
            if len(s) == 1:
                aa = [x[0] for x in a]
            else:
                aa = a

            name = ''.join(aa + [s])
            b = [x for x in a]

            yield name, c, b
            yield '{' + name + '}', c, b


def iter_full_table():
    for n, c, a in iter_combo():
        yield n, get_color_ext(c, on_color=None, attrs=a)

    for r in ('', 'rst', 'reset'):
        yield r, get_code(0)
        yield '{' + r + '}', get_code(0)


COLOR_TABLE = dict(iter_full_table())


def get_color(n):
    return COLOR_TABLE[n]


def colorize(text, color):
    return get_color(color) + text + get_color('')

--------------------&/ut/coro.py
import time
import queue
import collections as cc
import sys
import collections.abc
import heapq
import threading
import weakref
import contextvars as cv


CURRENT_CORO = cv.ContextVar('CURRENT_CORO')
NOV = '$'


def current_coro():
    return CURRENT_CORO.get()


@y.contextlib.contextmanager
def with_contextvar(coro):
    token = CURRENT_CORO.set(coro)

    try:
        yield
    finally:
        CURRENT_CORO.reset(token)


def wrap_context(func):
    @y.functools.wraps(func)
    def func1(self):
        with with_contextvar(self):
            return func(self)

    @y.functools.wraps(func)
    def wrapped(self):
        return self.ctx.run(func1, self)

    return wrapped


def set_name(func, name):
    func.__name__ = name

    return func


def factory(where):
    if where == 'timer':
        return y.MTQ


def nope():
    pass


@y.singleton
def is_dbg():
    return 'debug' in y.config.get('coro', '')


class X(object):
    debug = True


def is_debug(ctx=X):
    return ctx.debug and is_dbg()


def gen_int_uid():
    return int(y.random.random() * 100000000000)


class SchedAction(collections.abc.Awaitable):
    def __str__(self):
        return '<sched ' + self.name + ', from ' + self.loop_name + ', action ' + self.action.__name__ + ', ' + str(self.id) + '>'

    def __repr__(self):
        return str(self)

    def __await__(self):
        yield self

    __iter__ = __await__

    def __init__(self, id, loop_name, action):
        self.id = id
        self.loop_name = loop_name
        self.name = loop_name + '_' + action.__name__
        self.action = action

    def sched_action(self, coro):
        return self.__dict__.pop('action')(coro)


class Future(collections.abc.Awaitable):
    def __str__(self):
        return '<fut ' + self.name + ', from loop ' + self.ln + ', ' + str(self.id) + '>'

    def __repr__(self):
        return str(self)

    def __await__(self):
        yield self
        return self.result()

    __iter__ = __await__

    def __init__(self, id, loop_name, action):
        self.ln = loop_name
        self.id = id
        self.cb = []
        self.name = 'fut_' + action.__name__
        self.action = action

    @property
    def __name__(self):
        return self.name

    def signal(self):
        self.set_result([None])

    def set_result(self, res):
        self.run_job(lambda: res)

    def run_job(self, job):
        self.r = y.sync_pack(job)
        self.call_all_callbacks()

    def result(self):
        try:
            return y.unpack(self.r)
        except AttributeError:
            return None

    def add_cb(self, cb):
        self.cb.append(cb)

    def is_done(self):
        try:
            self.r

            return True
        except AttributeError:
            return False

    @property
    def pop(self):
        return self.__dict__.pop

    def call_all_callbacks(self):
        for c in self.pop('cb'):
            c()

    def sched_action(self, coro):
        try:
            self.add_cb(coro.reschedule)
            self.pop('action')()
        except Exception as e:
            print(e, str(coro), str(self), str(self.result()), file=y.stderr)
            y.prompt('/sa')
            coro.reschedule()


class MinHeap(object):
    def __init__(self):
        self.v = []

    def pack(self, key, val):
        return (key, gen_int_uid(), val)

    def unpack(self, x):
        return (x[0], x[2])

    def push(self, k, v):
        heapq.heappush(self.v, self.pack(k, v))

    def pop(self):
        return self.unpack(heapq.heappop(self.v))

    def min_element(self):
        return self.unpack(self.v[0])

    def pop_smallest(self, maxk):
        while self.v:
            mink, v = self.min_element()

            if mink <= maxk:
                yield self.pop()
            else:
                return

    def min_key(self):
        return self.min_element()[0]

    def empty(self):
        return not self.v


class ReadFile(object):
    def __init__(self, name, loop):
        self.loop = loop
        self.name = name
        self.f = None

    async def open(self):
        self.f = await self.loop.offload(set_name(lambda: open(self.name, 'rb'), 'open_file'))

    async def close(self):
        await self.loop.offload(self.f.close)
        self.f = None

    async def read(self):
        assert self.f
        return await self.loop.offload(self.f.read)

    async def read_line(self):
        assert self.f
        return await self.loop.offload(self.f.readline)


class TimeScheduler(object):
    def __init__(self, loop, name):
        self.loop = loop
        self.name = name
        self.h = MinHeap()

    @property
    def tq(self):
        return self.loop.timer_queue

    def add(self, deadline, cb):
        self.h.push(deadline, cb)

    def iter_next(self):
        return list(self.h.pop_smallest(time.time()))

    def next_deadline(self):
        return self.h.min_key()

    def empty(self):
        return self.h.empty()

    async def sleep(self, tout):
        return await self.sleep_deadline(time.time() + tout)

    async def sleep_deadline(self, dd):
        return await current_coro().loop.offload(set_name(lambda: time.sleep(max(dd - time.time(), 0)), 'sleep_' + str(int(dd))))

    async def wait_queue(self):
        self.process_queue()

        tout = y.TOut()

        while self.empty():
            if tout.current() > 0:
                await self.sleep(tout.current())

            tout.bad()

            self.process_queue()

    async def step(self):
        await self.wait_queue()
        await self.sleep_deadline(self.next_deadline())

        for d, cb in self.iter_next():
            cb()

    def process_queue(self):
        while (val := self.tq.try_pop()) != NOV:
            self.add(*val)

    async def system_time_checker(self):
        while True:
            await self.step()

    def respawn(self):
        self.loop.spawn(self.system_time_checker, self.name, debug=False)


COROS = {}


def coro_rescheduler(coro, i):
    coro.loop.loop.thrs[i].reschedule(coro)


def yield_action(coro):
    coro.reschedule()


class Green(object):
    def __init__(self, func, loop):
        self.f = func
        self.g = self.f(self)
        self.a = loop.create_future(nope)
        self.s = 'CREATED'
        self.cr_await = None

    def __pow__(self, other):
        self.cr_await = other

        try:
            yield from other.__await__()
        finally:
            self.cr_await = None

    def __await__(self):
        return self.a.__await__()

    def send(self, v):
        assert not self.is_closed()

        try:
            self.s = 'RUNNING'

            try:
                return self.g.send(v)
            finally:
                self.s = 'SUSPENDED'
        except StopIteration as e:
            self.s = 'CLOSED'
            self.a.set_result(e.value)

            raise e
        except:
            self.s = 'CLOSED'

            def func():
                raise

            self.a.run_job(func)

    def is_closed(self):
        return self.s == 'CLOSED'

    def throw(self, *args):
        assert not self.is_closed()

        self.g.throw(*args)

    def close(self):
        assert not self.is_closed()

        self.close()

    @property
    def __name__(self):
        return self.f.__name__

    @property
    def cr_code(self):
        return self.f.__code__

    @property
    def cr_frame(self):
        return self.g.gi_frame

    @property
    def cr_origin(self):
        return None

    @property
    def cr_running(self):
        return self.s
 

class Coro(collections.abc.Coroutine):
    def __init__(self, loop, coro, ctx, name, debug):
        if not y.inspect.iscoroutinefunction(coro):
            x = coro
            coro = lambda: Green(x, loop)

        self.debug = debug
        self.ctx = ctx

        try:
            self.id = current_coro().l.next_id()
        except LookupError:
            self.id = loop.next_id()

        self.n = name
        self.l = loop
        self.f = self.create_future(nope)
        self.change_state(coro)
        self.s = y.collections.deque()

        COROS[self.id] = self

    def change_state(self, coro):
        self.c = coro

        try:
            self.r = self.c(self)
        except TypeError:
            self.r = self.c()

    def __str__(self):
        state = str(y.inspect.getcoroutinestate(self))[5:].lower()

        return '<' + self.r.__class__.__name__.lower() + ' ' + self.name + ', ' + str(self.loop) + ', ' + state + ', id ' + str(self.id) + '>'

    def __repr__(self):
        return str(self)

    @property
    def thread_id(self):
        return self.loop.thread_id

    @property
    def thread_count(self):
        return self.loop.thread_count

    async def go_to_thread(self, i):
        assert i < self.thread_count
        assert i >= 0

        while self.thread_id != i:
            await self.sched_yield()
            await self.create_sched_action(set_name(lambda x: coro_rescheduler(x, i), 'coro_rescheduler_' + str(i)))

    @property
    def name(self):
        return self.n

    @property
    def __name__(self):
        return self.name

    @property
    def slave(self):
        return self.r

    @property
    def loop(self):
        return self.l

    def result(self):
        return self.f.result()

    def step(self):
        try:
            return self.step_0()
        except StopIteration as e:
            COROS.pop(self.id)

            is_debug(self) and y.debug(str(self), 'here we are', e)

            self.f.set_result(e.value)

            raise

    @wrap_context
    def step_0(self):
        return self.slave.send(None)

    def next(self):
        return (self.step() or self.l).sched_action(self)

    def reschedule(self):
        self.l.reschedule(self)

    def send(self, v):
        y.os.abort()

    @wrap_context
    def throw(self, *args):
        return self.slave.throw(*args)

    @wrap_context
    def close(self):
        return self.slave.close()

    def __await__(self):
        return self.f.__await__()

    def spawn(self, coro, name=None, debug=None):
        if debug is None:
            debug = self.debug

        name = name or coro.__name__
        res = self.l.spawn_impl(coro, self, self.name + '_' + name, debug)

        self.s.append(res)

        return res

    def create_future(self, action):
        return self.l.create_future(action)

    def create_sched_action(self, action):
        return self.l.create_sched_action(action)

    def create_yield(self):
        return self.l.create_yield()

    async def sched_yield(self):
        return await self.l.sched_yield()

    async def sleep(self, tout):
        return await self.l.sleep(tout)

    async def sleep_deadline(self, d):
        return await self.l.sleep_deadline(d)

    def await_sync(self):
        while True:
            try:
                return self.f.result()
            except AttributeError:
                pass

            time.sleep(0.01)

    @property
    def cr_await(self):
        return self.slave.cr_await

    @property
    def cr_code(self):
        return self.slave.cr_code

    @property
    def cr_frame(self):
        return self.slave.cr_frame

    @property
    def cr_origin(self):
        return self.slave.cr_origin

    @property
    def cr_running(self):
        return self.slave.cr_running


class ThreadLoop(object):
    def __init__(self, ctx, i, name, loop):
        self.next_id = y.inc_counter()
        self.ctx = ctx
        self.rng = y.PCGRandom(3, i)
        self.i = i
        self.name = name
        self.loop = loop
        self.q = cc.deque()
        self.t = y.threading.Thread(target=self.thr_loop)

    @property
    def thread_id(self):
        return self.i

    @property
    def thread_count(self):
        return len(self.loop.thrs)

    @property
    def int_random(self):
        return self.rng.next_random

    @property
    def float_random(self):
        return self.rng.next_float

    def __str__(self):
        return '<loop ' + self.name + '>'

    def __repr__(self):
        return str(self)

    def start(self):
        self.t.start()

    def thr_loop(self):
        try:
            self.ctx.run(self.drive_sync)
        except:
            y.os.abort()

    async def read_file(self, name):
        rf = ReadFile(name, self)

        await rf.open()

        if rf.f:
            return rf

        raise Exception('can not open file ' + name)

    def schedule(self, coro, ctx, name, debug):
        res = Coro(self, coro, ctx, name, debug)

        is_debug(res) and y.debug('spawn', str(res))
        self.reschedule(res)

        return res

    def spawn(self, coro, name=None, debug=True):
        return self.spawn_impl(coro, self, name, debug)

    def spawn_impl(self, coro, parent, name, debug):
        name = name or coro.__name__

        return self.schedule(coro, parent.ctx.copy(), name, debug)

    def reschedule(self, coro):
        coro.l = self
        self.q.append(coro.id)

        is_debug(coro) and y.debug('reschedule', str(coro))

    def iter_thrs1(self):
        if 0:
            while True:
                yield self.i
                time.sleep(0.001)

        for i in range(0, 20):
            yield self.i + i
            time.sleep(0)

        c = self.i

        while True:
            yield c

            time.sleep(0.001)

            c = c + 1 + 5 * self.float_random()

            if c > 1000:
                c = 0

    def get_next(self):
        tt = self.loop.thrs

        for j in self.iter_thrs1():
            try:
                c_id = tt[int(j) % len(tt)].q.popleft()
            except IndexError:
                continue

            c = COROS[c_id]
            c.l = self

            return c

    def one_step_sync(self, c): 
        try:
            return c.next()
        except StopIteration as s:
            return

    def sched_action(self, x):
        return self.reschedule(x)

    def drive_sync(self):
        while True:
            self.one_step_sync(self.get_next())
            time.sleep(0)

    async def sched_yield(self):
        return await self.create_yield()

    def create_yield(self):
        return self.create_sched_action(yield_action)

    def create_sched_action(self, action):
        return SchedAction(self.next_id(), self.name, action)

    def create_future(self, action):
        return Future(self.next_id(), str(self), action)

    async def sleep_deadline(self, dd):
        name = 'sleep_deadline_' + str(int(dd))
        fut = self.create_future(set_name(lambda: self.loop.timer_queue.push((dd, fut.signal)), name))

        return await fut

    async def sleep(self, tout):
        if tout < 0.02:
            return await self.sched_yield()

        t1 = time.time()

        try:
            return await self.sleep_deadline(t1 + tout)
        finally:
            is_debug() and y.debug('sleep for', time.time() - t1, tout)

    async def offload(self, job):
        async def async_job(ctl):
            return y.sync_pack(job)

        return y.unpack(await self.spawn(async_job, 'async_' + job.__name__, debug=('sleep' not in job.__name__)))


class CoroLoop(object):
    def __init__(self, name, scheduler=None):
        self.ctx = cv.copy_context()
        self.name = name
        self.timer_queue = factory('timer')(self)
        self.timers = [TimeScheduler(self, 'system_tc_' + str(i)) for i in range(0, 5)]
        self.thrs = [ThreadLoop(self.ctx.copy(), i, name + '_' + str(i), self) for i in range(0, 20)]

        for t in self.thrs:
            t.start()

        for t in self.timers:
            t.respawn()

        #self.spawn(self.collect_stats)

    def __str__(self):
        return '<loop ' + self.name + '>'

    def __repr__(self):
        return str(self)

    async def collect_stats(self):
        cc = y.current_coro()

        while True:
            for i in range(0, len(self.thrs)):
                await cc.go_to_thread(i)
                print('awake in', cc)
                await cc.sleep(0.5)

    @property
    def spawn(self):
        return self.get_random_queue().spawn

    @property
    def sleep(self):
        return self.get_random_queue().sleep

    @property
    def offload(self):
        return self.get_random_queue().offload

    def get_random_queue(self):
        return y.random.choice(self.thrs)

+++++++++++++++++++
import time
import queue
import collections as cc
import sys
import collections.abc
import heapq
import threading
import weakref
import contextvars as cv


CURRENT_CORO = cv.ContextVar('CURRENT_CORO')
NOV = '$'


def current_coro():
    return CURRENT_CORO.get()


@y.contextlib.contextmanager
def with_contextvar(coro):
    token = CURRENT_CORO.set(coro)

    try:
        yield
    finally:
        CURRENT_CORO.reset(token)


def wrap_context(func):
    @y.functools.wraps(func)
    def func1(self):
        with with_contextvar(self):
            return func(self)

    @y.functools.wraps(func)
    def wrapped(self):
        return self.ctx.run(func1, self)

    return wrapped


def set_name(func, name):
    func.__name__ = name

    return func


def factory(where):
    if where == 'timer':
        return y.MTQ


def nope():
    pass


@y.singleton
def is_dbg():
    return 'debug' in y.config.get('coro', '')


class X(object):
    debug = True


def is_debug(ctx=X):
    return ctx.debug and is_dbg()


def gen_int_uid():
    return int(y.random.random() * 100000000000)


class SchedAction(collections.abc.Awaitable):
    def __str__(self):
        return '<sched ' + self.name + ', from ' + self.loop_name + ', action ' + self.action.__name__ + ', ' + str(self.id) + '>'

    def __repr__(self):
        return str(self)

    def __await__(self):
        yield self

    __iter__ = __await__

    def __init__(self, id, loop_name, action):
        self.id = id
        self.loop_name = loop_name
        self.name = loop_name + '_' + action.__name__
        self.action = action

    def sched_action(self, coro):
        return self.__dict__.pop('action')(coro)


class Future(collections.abc.Awaitable):
    def __str__(self):
        return '<fut ' + self.name + ', from loop ' + self.ln + ', ' + str(self.id) + '>'

    def __repr__(self):
        return str(self)

    def __await__(self):
        yield self
        return self.result()

    __iter__ = __await__

    def __init__(self, id, loop_name, action):
        self.ln = loop_name
        self.id = id
        self.cb = []
        self.name = 'fut_' + action.__name__
        self.action = action

    @property
    def __name__(self):
        return self.name

    def signal(self):
        self.set_result([None])

    def set_result(self, res):
        self.run_job(lambda: res)

    def run_job(self, job):
        self.r = y.sync_pack(job)
        self.call_all_callbacks()

    def result(self):
        try:
            return y.unpack(self.r)
        except AttributeError:
            return None

    def add_cb(self, cb):
        self.cb.append(cb)

    def is_done(self):
        try:
            self.r

            return True
        except AttributeError:
            return False

    @property
    def pop(self):
        return self.__dict__.pop

    def call_all_callbacks(self):
        for c in self.pop('cb'):
            c()

    def sched_action(self, coro):
        try:
            self.add_cb(coro.reschedule)
            self.pop('action')()
        except Exception as e:
            print(e, str(coro), str(self), str(self.result()), file=y.stderr)
            y.prompt('/sa')
            coro.reschedule()


class MinHeap(object):
    def __init__(self):
        self.v = []

    def pack(self, key, val):
        return (key, gen_int_uid(), val)

    def unpack(self, x):
        return (x[0], x[2])

    def push(self, k, v):
        heapq.heappush(self.v, self.pack(k, v))

    def pop(self):
        return self.unpack(heapq.heappop(self.v))

    def min_element(self):
        return self.unpack(self.v[0])

    def pop_smallest(self, maxk):
        while self.v:
            mink, v = self.min_element()

            if mink <= maxk:
                yield self.pop()
            else:
                return

    def min_key(self):
        return self.min_element()[0]

    def empty(self):
        return not self.v


class ReadFile(object):
    def __init__(self, name, loop):
        self.loop = loop
        self.name = name
        self.f = None

    async def open(self):
        self.f = await self.loop.offload(set_name(lambda: open(self.name, 'rb'), 'open_file'))

    async def close(self):
        await self.loop.offload(self.f.close)
        self.f = None

    async def read(self):
        assert self.f
        return await self.loop.offload(self.f.read)

    async def read_line(self):
        assert self.f
        return await self.loop.offload(self.f.readline)


class TimeScheduler(object):
    def __init__(self, loop, name):
        self.loop = loop
        self.name = name
        self.h = MinHeap()

    @property
    def tq(self):
        return self.loop.timer_queue

    def add(self, deadline, cb):
        self.h.push(deadline, cb)

    def iter_next(self):
        return list(self.h.pop_smallest(time.time()))

    def next_deadline(self):
        return self.h.min_key()

    def empty(self):
        return self.h.empty()

    async def sleep(self, tout):
        return await self.sleep_deadline(time.time() + tout)

    async def sleep_deadline(self, dd):
        return await current_coro().loop.offload(set_name(lambda: time.sleep(max(dd - time.time(), 0)), 'sleep_' + str(int(dd))))

    async def wait_queue(self):
        self.process_queue()

        tout = y.TOut()

        while self.empty():
            if tout.current() > 0:
                await self.sleep(tout.current())

            tout.bad()

            self.process_queue()

    async def step(self):
        await self.wait_queue()
        await self.sleep_deadline(self.next_deadline())

        for d, cb in self.iter_next():
            cb()

    def process_queue(self):
        while (val := self.tq.try_pop()) != NOV:
            self.add(*val)

    async def system_time_checker(self):
        while True:
            await self.step()

    def respawn(self):
        self.loop.spawn(self.system_time_checker, self.name, debug=False)


COROS = {}


def coro_rescheduler(coro, i):
    coro.loop.loop.thrs[i].reschedule(coro)


def yield_action(coro):
    coro.reschedule()


class Green(object):
    def __init__(self, func, loop):
        self.f = func
        self.g = self.f(self)
        self.a = loop.create_future(nope)
        self.s = 'CREATED'
        self.cr_await = None

    def __pow__(self, other):
        self.cr_await = other

        try:
            yield from other.__await__()
        finally:
            self.cr_await = None

    def __await__(self):
        return self.a.__await__()

    def send(self, v):
        assert not self.is_closed()

        try:
            self.s = 'RUNNING'

            try:
                return self.g.send(v)
            finally:
                self.s = 'SUSPENDED'
        except StopIteration as e:
            self.s = 'CLOSED'
            self.a.set_result(e.value)

            raise e
        except:
            self.s = 'CLOSED'

            def func():
                raise

            self.a.run_job(func)

    def is_closed(self):
        return self.s == 'CLOSED'

    def throw(self, *args):
        assert not self.is_closed()

        self.g.throw(*args)

    def close(self):
        assert not self.is_closed()

        self.close()

    @property
    def __name__(self):
        return self.f.__name__

    @property
    def cr_code(self):
        return self.f.__code__

    @property
    def cr_frame(self):
        return self.g.gi_frame

    @property
    def cr_origin(self):
        return None

    @property
    def cr_running(self):
        return self.s
 

class Coro(collections.abc.Coroutine):
    def __init__(self, loop, coro, ctx, name, debug):
        if not y.inspect.iscoroutinefunction(coro):
            x = coro
            coro = lambda: Green(x, loop)

        self.debug = debug
        self.ctx = ctx

        try:
            self.id = current_coro().l.next_id()
        except LookupError:
            self.id = loop.next_id()

        self.n = name
        self.l = loop
        self.f = self.create_future(nope)
        self.change_state(coro)
        self.s = y.collections.deque()

        COROS[self.id] = self

    def change_state(self, coro):
        self.c = coro

        try:
            self.r = self.c(self)
        except TypeError:
            self.r = self.c()

    def __str__(self):
        state = str(y.inspect.getcoroutinestate(self))[5:].lower()

        return '<' + self.r.__class__.__name__.lower() + ' ' + self.name + ', ' + str(self.loop) + ', ' + state + ', id ' + str(self.id) + '>'

    def __repr__(self):
        return str(self)

    @property
    def thread_id(self):
        return self.loop.thread_id

    @property
    def thread_count(self):
        return self.loop.thread_count

    async def go_to_thread(self, i):
        assert i < self.thread_count
        assert i >= 0

        while self.thread_id != i:
            await self.sched_yield()
            await self.create_sched_action(set_name(lambda x: coro_rescheduler(x, i), 'coro_rescheduler_' + str(i)))

    @property
    def name(self):
        return self.n

    @property
    def __name__(self):
        return self.name

    @property
    def slave(self):
        return self.r

    @property
    def loop(self):
        return self.l

    def result(self):
        return self.f.result()

    def step(self):
        try:
            return self.step_0()
        except StopIteration as e:
            COROS.pop(self.id)

            is_debug(self) and y.debug(str(self), 'here we are', e)

            self.f.set_result(e.value)

            raise

    @wrap_context
    def step_0(self):
        return self.slave.send(None)

    def next(self):
        return (self.step() or self.l).sched_action(self)

    def reschedule(self):
        self.l.reschedule(self)

    def send(self, v):
        y.os.abort()

    @wrap_context
    def throw(self, *args):
        return self.slave.throw(*args)

    @wrap_context
    def close(self):
        return self.slave.close()

    def __await__(self):
        return self.f.__await__()

    def spawn(self, coro, name=None, debug=None):
        if debug is None:
            debug = self.debug

        name = name or coro.__name__
        res = self.l.spawn_impl(coro, self, self.name + '_' + name, debug)

        self.s.append(res)

        return res

    def create_future(self, action):
        return self.l.create_future(action)

    def create_sched_action(self, action):
        return self.l.create_sched_action(action)

    def create_yield(self):
        return self.l.create_yield()

    async def sched_yield(self):
        return await self.l.sched_yield()

    async def sleep(self, tout):
        return await self.l.sleep(tout)

    async def sleep_deadline(self, d):
        return await self.l.sleep_deadline(d)

    def await_sync(self):
        while True:
            try:
                return self.f.result()
            except AttributeError:
                pass

            time.sleep(0.01)

    @property
    def cr_await(self):
        return self.slave.cr_await

    @property
    def cr_code(self):
        return self.slave.cr_code

    @property
    def cr_frame(self):
        return self.slave.cr_frame

    @property
    def cr_origin(self):
        return self.slave.cr_origin

    @property
    def cr_running(self):
        return self.slave.cr_running


class ThreadLoop(object):
    def __init__(self, ctx, i, name, loop):
        self.next_id = y.inc_counter()
        self.ctx = ctx
        self.rng = y.PCGRandom(3, i)
        self.i = i
        self.name = name
        self.loop = loop
        self.q = cc.deque()
        self.t = y.threading.Thread(target=self.thr_loop)

    @property
    def thread_id(self):
        return self.i

    @property
    def thread_count(self):
        return len(self.loop.thrs)

    @property
    def int_random(self):
        return self.rng.next_random

    @property
    def float_random(self):
        return self.rng.next_float

    def __str__(self):
        return '<loop ' + self.name + '>'

    def __repr__(self):
        return str(self)

    def start(self):
        self.t.start()

    def thr_loop(self):
        try:
            self.ctx.run(self.drive_sync)
        except:
            y.os.abort()

    async def read_file(self, name):
        rf = ReadFile(name, self)

        await rf.open()

        if rf.f:
            return rf

        raise Exception('can not open file ' + name)

    def schedule(self, coro, ctx, name, debug):
        res = Coro(self, coro, ctx, name, debug)

        is_debug(res) and y.debug('spawn', str(res))
        self.reschedule(res)

        return res

    def spawn(self, coro, name=None, debug=True):
        return self.spawn_impl(coro, self, name, debug)

    def spawn_impl(self, coro, parent, name, debug):
        name = name or coro.__name__

        return self.schedule(coro, parent.ctx.copy(), name, debug)

    def reschedule(self, coro):
        coro.l = self
        self.q.append(coro.id)

        is_debug(coro) and y.debug('reschedule', str(coro))

    def iter_thrs1(self):
        if 0:
            while True:
                yield self.i
                time.sleep(0.001)

        for i in range(0, 20):
            yield self.i + i
            time.sleep(0)

        c = self.i

        while True:
            yield c

            time.sleep(0.001)

            c = c + 1 + 5 * self.float_random()

            if c > 1000:
                c = 0

    def get_next(self):
        tt = self.loop.thrs

        for j in self.iter_thrs1():
            try:
                c_id = tt[int(j) % len(tt)].q.popleft()
            except IndexError:
                continue

            c = COROS[c_id]
            c.l = self

            return c

    def one_step_sync(self, c): 
        try:
            return c.next()
        except StopIteration as s:
            return

    def sched_action(self, x):
        return self.reschedule(x)

    def drive_sync(self):
        while True:
            self.one_step_sync(self.get_next())
            time.sleep(0)

    async def sched_yield(self):
        return await self.create_yield()

    def create_yield(self):
        return self.create_sched_action(yield_action)

    def create_sched_action(self, action):
        return SchedAction(self.next_id(), self.name, action)

    def create_future(self, action):
        return Future(self.next_id(), str(self), action)

    async def sleep_deadline(self, dd):
        name = 'sleep_deadline_' + str(int(dd))
        fut = self.create_future(set_name(lambda: self.loop.timer_queue.push((dd, fut.signal)), name))

        return await fut

    async def sleep(self, tout):
        if tout < 0.02:
            return await self.sched_yield()

        t1 = time.time()

        try:
            return await self.sleep_deadline(t1 + tout)
        finally:
            is_debug() and y.debug('sleep for', time.time() - t1, tout)

    async def offload(self, job):
        async def async_job(ctl):
            return y.sync_pack(job)

        return y.unpack(await self.spawn(async_job, 'async_' + job.__name__, debug=('sleep' not in job.__name__)))


class CoroLoop(object):
    def __init__(self, name, scheduler=None):
        self.ctx = cv.copy_context()
        self.name = name
        self.timer_queue = factory('timer')(self)
        self.timers = [TimeScheduler(self, 'system_tc_' + str(i)) for i in range(0, 5)]
        self.thrs = [ThreadLoop(self.ctx.copy(), i, name + '_' + str(i), self) for i in range(0, 20)]

        for t in self.thrs:
            t.start()

        for t in self.timers:
            t.respawn()

        #self.spawn(self.collect_stats)

    def __str__(self):
        return '<loop ' + self.name + '>'

    def __repr__(self):
        return str(self)

    async def collect_stats(self):
        cc = y.current_coro()

        while True:
            for i in range(0, len(self.thrs)):
                await cc.go_to_thread(i)
                print('awake in', cc)
                await cc.sleep(0.5)

    @property
    def spawn(self):
        return self.get_random_queue().spawn

    @property
    def sleep(self):
        return self.get_random_queue().sleep

    @property
    def offload(self):
        return self.get_random_queue().offload

    def get_random_queue(self):
        return y.random.choice(self.thrs)

--------------------&/ut/make_util.py
def new_cmd():
    return {
        'cmd': [],
    }


@y.singleton
def good_sym():
    a = [chr(ord('a') + x) for x in range(0, 26)]
    b = [x.upper() for x in a]
    c = [i for i in range(0, 10)]

    return frozenset(a + b + c)


def sanitize_string(s):
    gs = good_sym()

    def iter_good():
        for c in s:
            if c in gs:
                yield c
            else:
                yield '_'

    return ''.join(iter_good())


def select_targets(lst, targets):
    by_link = {}

    for n, l in enumerate(lst):
        for d in l['deps1']:
            by_link[d] = n

    v = set()

    def visit(n):
        if n in v:
            return

        yield n

        v.add(n)

        def iter1():
            for d in lst[n]['deps2']:
                if d in by_link:
                    yield by_link[d]

        for l in iter1():
            yield from visit(l)

    def iter():
        for t in targets:
            yield from visit(by_link[t])

    return [lst[x] for x in sorted(frozenset(iter()))]


def subst_vars(d, shell_vars):
    while '$' in d:
        for k, v in shell_vars.items():
            d = d.replace(k, v)

    return d


def remove_d(k):
    if k[0] == '$':
        return k[1:]

    return k


def super_decode(s):
    try:
        return s.decode('utf-8')
    except Exception:
        return s


def fix_shell_vars(shell_vars):
    return [(remove_d(k), v) for k, v in shell_vars.items()]


@y.cached
def cached_file_list(where):
    try:
        return frozenset([x for x in y.os.listdir(where)])
    except FileNotFoundError:
        return frozenset()


@y.cached
def find_tool_cached(tool, path):
    for p in path:
        if tool in cached_file_list(p):
            return p + '/' + tool


async def parse_makefile(data):
    lst = []
    prev = None
    cprint = y.xprint_white
    parse_flags = True
    shell_args = {}

    for line_no, l in enumerate(data.split('\n')):
        if parse_flags:
            if '=' in l:
                pos = l.find('=')
                key = l[:pos].strip()
                val = l[pos + 1:].strip()
                shell_args['$' + key] = val

                continue
            else:
                print(shell_args, file=y.sys.stderr)
                parse_flags = False

        p = l.find('##')

        if p > 5:
            l = l[:p]

        ls = l.strip()

        if not ls:
            continue

        if ls.startswith('#'):
            continue

        if l[0] != '\t':
            if prev:
                lst.append(prev)

            prev = new_cmd()

            def iter_deps(ll):
                for l in ll.strip().split(' '):
                    l = l.strip()

                    if l:
                        yield l

            try:
                a, b = ls.split(':')
            except Exception as e:
                y.info('{br}', ls, line_no, e, '{}')

                raise

            prev['deps1'] = list(iter_deps(a))
            prev['deps2'] = list(iter_deps(b))
        else:
            prev['cmd'].append(l[1:].rstrip())

    if prev:
        lst.append(prev)

    return {'lst': lst, 'flags': shell_args}


async def cheet(mk):
    @y.singleton
    def placeholder():
        bsp = mk.bsp()

        def build_scripts_path():
            return bsp

        def build_scripts_dir():
            return y.os.path.dirname(bsp)

        l = locals()

        @y.lookup
        def look(name):
            return l[name]

    try:
        y.build_scripts_dir()
    except AttributeError:
        placeholder()
        y.build_scripts_dir()


def build_run_sh(n):
    def iter_run_sh():
        yield '{br}running {bw}[cname]'
        yield '{by} run.sh:'

        for l in n['cmd']:
            yield '  ' + str(l)

    return '\n'.join(iter_run_sh())


class MakeArgs(dict):
    def __init__(self):
        self.__dict__ = self


class MakeFile(object):
    async def init(self, lst):
        try:
            return self.init_from_dict(y.decode_prof(lst))
        except Exception as e1:
            exc1 = e1

        try:
            return self.init_from_parsed(await parse_makefile(lst))
        except Exception as e2:
            exc2 = e2

        try:
            return self.init_from_parsed(await parse_makefile(lst.decode('utf-8')))
        except Exception as e2:
            exc2 = e2

        raise Exception('can not parse makefile: ' + str(exc1) + ', ' + str(exc2))

    def init_from_dict(self, d):
        self.lst = d['d']
        self.flags = d['f']
        self.strings = d['s']
        self.str_to_num = dict((x, i) for i, x in enumerate(self.strings))

        return self

    def clone(self):
        mk = MakeFile()

        mk.__dict__.update(self.__dict__)

        return mk

    def init_from_parsed(self, parsed):
        self.flags = parsed['flags']
        self.strings = []
        self.str_to_num = {}
        self.lst = [self.store_node(n) for n in parsed['lst']]

        return self

    def cvt(self, l, name):
        return self.lst_to_nums(l.get(name, []))

    def bsp(self):
        return self.strings[self.lst[0]['deps1'][0]]

    def stn(self, s):
        if s in self.str_to_num:
            return self.str_to_num[s]

        k = len(self.strings)

        self.strings.append(s)
        self.str_to_num[s] = k

        return k

    def lst_to_nums(self, l):
        return [self.stn(s) for s in l]

    def nums_to_str(self, l):
        return [self.strings[s] for s in l]

    async def select_targets(self, targets):
        mk = MakeFile()

        lst = select_targets(self.lst, self.lst_to_nums(sorted(targets)))
        lst = [self.restore_node(x) for x in lst]

        mk.init_from_parsed({'lst': lst, 'flags': y.dc(self.flags)})

        return mk

    def store_node(self, n):
        return dict((k, self.cvt(n, k)) for k in ('deps1', 'deps2', 'cmd'))

    def restore_node(self, n):
        return dict((k, self.nums_to_str(n[k])) for k in ('deps1', 'deps2', 'cmd'))

    async def build(self, args):
        mk = self.clone()

        mk.flags = y.dc(mk.flags)
        mk.flags.update(args.shell_vars)

        return await y.run_make_0(mk, args)

    async def build_kw(self, **kwargs):
        args = MakeArgs()

        args.shell_vars = kwargs.pop('shell_vars', {})
        args.threads = kwargs.pop('threads', 1)
        args.targets = kwargs.pop('targets', [])
        args.pre_run = kwargs.pop('pre_run', [])

        args.update(kwargs)

        return await self.build(args)


def dumps_mk(mk):
    return y.encode_prof({'d': mk.lst, 's': mk.strings, 'f': mk.flags})


def loads_mk(t):
    return MakeFile().init_from_dict(y.decode_prof(t))


async def open_mk_file(path, gen=None):
    if gen and path == 'gen':
        return await gen()

    if path == '-':
        data = await y.offload(y.sys.stdin.read)
    elif path:
        with open(path, 'r') as f:
            data = await y.offload(f.buffer.read)
    else:
        data = await y.offload(y.sys.stdin.read)

    mk = MakeFile()

    await mk.init(data)

    return mk

+++++++++++++++++++
def new_cmd():
    return {
        'cmd': [],
    }


@y.singleton
def good_sym():
    a = [chr(ord('a') + x) for x in range(0, 26)]
    b = [x.upper() for x in a]
    c = [i for i in range(0, 10)]

    return frozenset(a + b + c)


def sanitize_string(s):
    gs = good_sym()

    def iter_good():
        for c in s:
            if c in gs:
                yield c
            else:
                yield '_'

    return ''.join(iter_good())


def select_targets(lst, targets):
    by_link = {}

    for n, l in enumerate(lst):
        for d in l['deps1']:
            by_link[d] = n

    v = set()

    def visit(n):
        if n in v:
            return

        yield n

        v.add(n)

        def iter1():
            for d in lst[n]['deps2']:
                if d in by_link:
                    yield by_link[d]

        for l in iter1():
            yield from visit(l)

    def iter():
        for t in targets:
            yield from visit(by_link[t])

    return [lst[x] for x in sorted(frozenset(iter()))]


def subst_vars(d, shell_vars):
    while '$' in d:
        for k, v in shell_vars.items():
            d = d.replace(k, v)

    return d


def remove_d(k):
    if k[0] == '$':
        return k[1:]

    return k


def super_decode(s):
    try:
        return s.decode('utf-8')
    except Exception:
        return s


def fix_shell_vars(shell_vars):
    return [(remove_d(k), v) for k, v in shell_vars.items()]


@y.cached
def cached_file_list(where):
    try:
        return frozenset([x for x in y.os.listdir(where)])
    except FileNotFoundError:
        return frozenset()


@y.cached
def find_tool_cached(tool, path):
    for p in path:
        if tool in cached_file_list(p):
            return p + '/' + tool


async def parse_makefile(data):
    lst = []
    prev = None
    cprint = y.xprint_white
    parse_flags = True
    shell_args = {}

    for line_no, l in enumerate(data.split('\n')):
        if parse_flags:
            if '=' in l:
                pos = l.find('=')
                key = l[:pos].strip()
                val = l[pos + 1:].strip()
                shell_args['$' + key] = val

                continue
            else:
                print(shell_args, file=y.sys.stderr)
                parse_flags = False

        p = l.find('##')

        if p > 5:
            l = l[:p]

        ls = l.strip()

        if not ls:
            continue

        if ls.startswith('#'):
            continue

        if l[0] != '\t':
            if prev:
                lst.append(prev)

            prev = new_cmd()

            def iter_deps(ll):
                for l in ll.strip().split(' '):
                    l = l.strip()

                    if l:
                        yield l

            try:
                a, b = ls.split(':')
            except Exception as e:
                y.info('{br}', ls, line_no, e, '{}')

                raise

            prev['deps1'] = list(iter_deps(a))
            prev['deps2'] = list(iter_deps(b))
        else:
            prev['cmd'].append(l[1:].rstrip())

    if prev:
        lst.append(prev)

    return {'lst': lst, 'flags': shell_args}


async def cheet(mk):
    @y.singleton
    def placeholder():
        bsp = mk.bsp()

        def build_scripts_path():
            return bsp

        def build_scripts_dir():
            return y.os.path.dirname(bsp)

        l = locals()

        @y.lookup
        def look(name):
            return l[name]

    try:
        y.build_scripts_dir()
    except AttributeError:
        placeholder()
        y.build_scripts_dir()


def build_run_sh(n):
    def iter_run_sh():
        yield '{br}running {bw}[cname]'
        yield '{by} run.sh:'

        for l in n['cmd']:
            yield '  ' + str(l)

    return '\n'.join(iter_run_sh())


class MakeArgs(dict):
    def __init__(self):
        self.__dict__ = self


class MakeFile(object):
    async def init(self, lst):
        try:
            return self.init_from_dict(y.decode_prof(lst))
        except Exception as e1:
            exc1 = e1

        try:
            return self.init_from_parsed(await parse_makefile(lst))
        except Exception as e2:
            exc2 = e2

        try:
            return self.init_from_parsed(await parse_makefile(lst.decode('utf-8')))
        except Exception as e2:
            exc2 = e2

        raise Exception('can not parse makefile: ' + str(exc1) + ', ' + str(exc2))

    def init_from_dict(self, d):
        self.lst = d['d']
        self.flags = d['f']
        self.strings = d['s']
        self.str_to_num = dict((x, i) for i, x in enumerate(self.strings))

        return self

    def clone(self):
        mk = MakeFile()

        mk.__dict__.update(self.__dict__)

        return mk

    def init_from_parsed(self, parsed):
        self.flags = parsed['flags']
        self.strings = []
        self.str_to_num = {}
        self.lst = [self.store_node(n) for n in parsed['lst']]

        return self

    def cvt(self, l, name):
        return self.lst_to_nums(l.get(name, []))

    def bsp(self):
        return self.strings[self.lst[0]['deps1'][0]]

    def stn(self, s):
        if s in self.str_to_num:
            return self.str_to_num[s]

        k = len(self.strings)

        self.strings.append(s)
        self.str_to_num[s] = k

        return k

    def lst_to_nums(self, l):
        return [self.stn(s) for s in l]

    def nums_to_str(self, l):
        return [self.strings[s] for s in l]

    async def select_targets(self, targets):
        mk = MakeFile()

        lst = select_targets(self.lst, self.lst_to_nums(sorted(targets)))
        lst = [self.restore_node(x) for x in lst]

        mk.init_from_parsed({'lst': lst, 'flags': y.dc(self.flags)})

        return mk

    def store_node(self, n):
        return dict((k, self.cvt(n, k)) for k in ('deps1', 'deps2', 'cmd'))

    def restore_node(self, n):
        return dict((k, self.nums_to_str(n[k])) for k in ('deps1', 'deps2', 'cmd'))

    async def build(self, args):
        mk = self.clone()

        mk.flags = y.dc(mk.flags)
        mk.flags.update(args.shell_vars)

        return await y.run_make_0(mk, args)

    async def build_kw(self, **kwargs):
        args = MakeArgs()

        args.shell_vars = kwargs.pop('shell_vars', {})
        args.threads = kwargs.pop('threads', 1)
        args.targets = kwargs.pop('targets', [])
        args.pre_run = kwargs.pop('pre_run', [])

        args.update(kwargs)

        return await self.build(args)


def dumps_mk(mk):
    return y.encode_prof({'d': mk.lst, 's': mk.strings, 'f': mk.flags})


def loads_mk(t):
    return MakeFile().init_from_dict(y.decode_prof(t))


async def open_mk_file(path, gen=None):
    if gen and path == 'gen':
        return await gen()

    if path == '-':
        data = await y.offload(y.sys.stdin.read)
    elif path:
        with open(path, 'r') as f:
            data = await y.offload(f.buffer.read)
    else:
        data = await y.offload(y.sys.stdin.read)

    mk = MakeFile()

    await mk.init(data)

    return mk

disable caching
disable caching
--------------------&/ut/stage1.py
def create_main(g):
    def re_exec(g):
        code = """
def new_main(loader, g):
    builtin = dict((x['name'].replace('/', '.')[:-3], x) for x in g.file_data)
    g.builtin_modules = builtin
    mod = loader('0', g).create_module('ut.mod_load')
    mod.bootstrap(g)

new_main(loader, _globals)
"""
        ctx = {'loader': Loader, '_globals': g}
        exec(g.compile(code, '2:stage1.py', 'exec'), ctx)
        ctx.clear()

    return re_exec


def run_stage1(g):
    ctx = {'re_exec': create_main(g), '_globals': g}
    exec(g.compile('re_exec(_globals)', '1:stage1.py', 'exec'), ctx)
    ctx.clear()

+++++++++++++++++++
def create_main(g):
    def re_exec(g):
        code = """
def new_main(loader, g):
    builtin = dict((x['name'].replace('/', '.')[:-3], x) for x in g.file_data)
    g.builtin_modules = builtin
    mod = loader('0', g).create_module('ut.mod_load')
    mod.bootstrap(g)

new_main(loader, _globals)
"""
        ctx = {'loader': Loader, '_globals': g}
        exec(g.compile(code, '2:stage1.py', 'exec'), ctx)
        ctx.clear()

    return re_exec


def run_stage1(g):
    ctx = {'re_exec': create_main(g), '_globals': g}
    exec(g.compile('re_exec(_globals)', '1:stage1.py', 'exec'), ctx)
    ctx.clear()

--------------------&/ut/make_exec.py
@y.singleton
def is_debug():
    return 'debug' in y.config.get('make', '')


async def run_makefile(mk, targets, threads, pre_run=[]):
    mmk = mk

    async def run_build_2(ctl):
        mk = mmk

        await y.cheet(mk)

        if pre_run:
            await run_par_build(ctl, await mk.select_targets(pre_run), 1, False)

        if targets:
            mk = await mk.select_targets(targets)

        return await run_par_build(ctl, mk, threads, True)

    return await y.spawn(run_build_2)


def wrap_gen(func):
    async def wrapper(ctl, inq):
        async for x in func(ctl, inq):
            yield x

    return wrapper


def CHANNEL(data):
    return y.DATA(tags=['mk:channel'], data=data)


class Builder(object):
    def __init__(self, ctl, mk, threads, check):
        self.check = check
        self.mk = mk
        self.threads = threads
        self.ctl = ctl
        self.lst = [item_factory(x, self, n) for n, x in enumerate(mk.lst)]

        by_dep = {}

        for x in self.lst:
            for d in x.deps1:
                by_dep[d] = x

        for k in by_dep.keys():
            self.resolve_path(k)

        self.by_dep = by_dep

    @property
    def shell_vars(self):
        return self.mk.flags

    @y.cached_method
    def resolve_path(self, d):
        return y.subst_vars(self.mk.strings[d], self.shell_vars)

    async def runner(self, ctl, inq):
        yield y.EOP(y.ACCEPT('mk:build', 'mk:channel'), y.PROVIDES('mk:ready'))

        async for el in inq:
            el = el.data.data

            is_debug() and y.debug('got', str(el))

            if el.get('action', '') == 'finish':
                yield y.FIN()

                return

            if (item := el.pop('item', None)) is not None:
                is_debug() and y.debug('run cmd', item)
                retcode = await item.run_cmd(ctl)
                is_debug() and y.debug('done run cmd', item, retcode)

                if retcode:
                    yield CHANNEL({'action': 'finish', 'status': 'failure'})
                    yield y.FIN()

                    return

                if item.my_name == '_all':
                    yield CHANNEL({'action': 'finish', 'status': 'success'})
                    yield y.FIN()

                    return

                yield y.EOP(y.ELEM({'ready': item}))
            else:
                yield y.EOP()

        assert False

    async def producer(self, ctl, inq):
        def iter_data():
            yield from self.lst

            lstl = len(self.lst)
            deps = sum([x.deps1 for x in self.lst], [])

            class ItemAll(object):
                @property
                def n(self):
                    return {'deps1': self.deps1, 'deps2': self.deps2, 'cmd': []}

                @property
                def my_name(self):
                    return '_all'

                @property
                def deps1(self):
                    return [self.num]

                @property
                def deps2(self):
                    return deps

                @property
                def num(self):
                    return lstl + 100000

                async def run_cmd(self, ctl):
                    y.build_results({
                        'status': 'fini',
                        'message': 'build complete',
                        'target': self.my_name,
                    })

                    return 0

            yield ItemAll()

        async def next_el():
            is_debug() and y.debug('wait next el')

            async for el in inq:
                el = el.data.data
                is_debug() and y.debug('got', el)
                return el

        rq, wq = y.make_engine(iter_data(), lambda x: x.deps1[0], dep_list=lambda x: sorted(frozenset(x.deps2)))

        if 0:
            while True:
                for i in list(rq()):
                    print(str(i['x']), file=y.stderr)
                    wq(i)

        by_n = {}
        complete = set()

        yield y.EOP(y.ACCEPT('mk:ready', 'mk:channel'), y.PROVIDES('mk:build'))

        def fmt_in_fly(data):
            return '(' + ', '.join([x['x'].my_name for x in data.values()]) + ')'

        while True:
            for i, el in enumerate(rq()):
                item = el['x']
                by_n[item.num] = el

                is_debug() and y.debug('yield ready', y.pretty_dumps(item), 'in fly', fmt_in_fly(by_n))

                yield y.ELEM({'item': item})
                yield y.EOP()

            yield y.EOP()

            el = await next_el()

            if el.get('action', '') == 'finish':
                yield y.FIN()

                return

            if (item := el.get('ready')) is not None:
                key = y.burn(item.n)
                assert key not in complete
                complete.add(key)
                wq(by_n.pop(item.num)['i'])
                is_debug() and y.debug('got complete', item, 'in fly', fmt_in_fly(by_n))

        assert False

    async def run(self):
        p = y.PubSubLoop(self.ctl)

        def iter_workers():
            yield y.set_name(wrap_gen(self.producer), 'producer_0')

            for i in range(0, self.threads):
                yield y.set_name(wrap_gen(self.runner), 'runner_' + str(i))

        return await p.run(coro=list(iter_workers()))


def item_factory(n, p, i):
    if n.get('cmd'):
        return Item(n, p, i)

    return ItemBase(n, p, i)


class ItemBase(object):
    def __init__(self, n, p, i):
        self.n = n
        self.p = p
        self.i = i

    def __str__(self):
        return y.json.dumps(self.__json__(), sort_keys=True)

    def __json__(self):
        return {
            'num': self.num,
            'cmd': self.cmd,
            'output': self.deps1[0],
            'inputs': self.deps2,
            'id': id(self),
        }

    @property
    def check(self):
        return self.p.check

    @property
    def num(self):
        return self.i

    @property
    def my_name(self):
        return ', '.join(self.str_deps1)

    @property
    def deps1(self):
        return self.n['deps1']

    @property
    def str_deps1(self):
        return self.p.mk.nums_to_str(self.deps1)

    @property
    def deps2(self):
        return self.n.get('deps2', [])

    @property
    def str_deps2(self):
        return self.p.mk.nums_to_str(self.deps2)

    @property
    def cmd(self):
        return self.n.get('cmd', [])

    @property
    def str_cmd(self):
        return self.p.mk.nums_to_str(self.cmd)

    @property
    def resolve_path(self):
        return self.p.resolve_path

    async def run_cmd(self, ctl):
        return 0


class Item(ItemBase):
    def __init__(self, n, p, i):
        ItemBase.__init__(self, n, p, i)

        assert self.cmd

        self.path = list(self.iter_search_path())
        self.shell = self.find_shell()
        assert self.shell
        self.env = self.prepare_env()

    def __json__(self):
        res = ItemBase.__json__(self)

        res.update({
            'shell': self.shell,
            'env': self.env,
        })

        return res

    @property
    def shell_vars(self):
        return self.p.shell_vars

    def prepare_env(self):
        return dict(y.itertools.chain({'OUTER_SHELL': self.shell}.items(), y.fix_shell_vars(self.shell_vars)))

    def find_tool(self, tool):
        if tool[0] == '/':
            return tool

        return y.find_tool_cached(tool, self.path)

    def iter_search_path(self):
        for d in self.deps2:
            yield y.os.path.join(y.os.path.dirname(self.resolve_path(d)), 'bin')

        yield from y.os.environ['PATH'].split(':')

    def find_shell(self):
        if '$YSHELL' in self.shell_vars:
            shell = self.find_tool(self.shell_vars['$YSHELL'])

            if shell:
                return shell

            raise Exception('can not find ' + self.shell_vars['$YSHELL'])

        return self.find_tool('dash') or self.find_tool('yash') or self.find_tool('bash') or self.find_tool('sh')

    def build_cmd(self):
        env = self.env

        def iter_cmd():
            yield 'set -e'
            yield 'set -x'

            for k in sorted(env, key=lambda x: -len(x)):
                yield 'export {k}={v}'.format(k=k, v=env[k])

            yield 'mainfun() {'

            for l in self.str_cmd:
                yield l

            yield '}'
            yield 'mainfun ' + ' '.join(y.itertools.chain(self.str_deps1, self.str_deps2))

        input = '\n'.join(iter_cmd()) + '\n'
        input = input.replace('$(SHELL)', '$YSHELL')

        return input

    def check_results(self):
        for x in self.deps1:
            x = self.resolve_path(x)

            try:
                assert y.os.path.isfile(x)
            except Exception as e:
                raise Exception(x + ' not exists: ' + str(e))

    def check_done(self):
        try:
            self.check_results()

            return True
        except Exception:
            pass

        return False

    async def run_cmd(self, ctl):
        target = self.my_name

        if self.check_done():
            y.build_results({
                'message': 'use cached {target}',
                'status': 'done',
                'target': target,
            })

            return 0

        y.build_results({
            'message': 'starting {target}',
            'status': 'init',
            'target': target,
        })

        retcode, res, input = await self.run_cmd_0(ctl)

        def iter_lines():
            for l in res.strip().split('\n'):
                if 'export ' in l:
                    yield l

        msg = {
            'output': '\n'.join(iter_lines()),
            'command': input,
            'target': target,
        }

        if retcode:
            msg.update({
                'message': 'target {target} failed',
                'status': 'fail',
                'retcode': retcode,
            })
        else:
            msg.update({
                'message': 'target {target} complete',
                'status': 'done',
            })

        y.build_results(msg)

        if retcode:
            y.shut_down(5, last_msg='{br}target ' + target + ' failed, exiting now{}\n')

    async def run_cmd_0(self, ctl):
        sp = y.subprocess
        out = []
        retcode = 0
        input = self.build_cmd()

        try:
            env = y.dc(self.env)
            #naked = 'source init' not in input
            naked = False

            def fun():
                input_bin = input.encode('utf-8')
                env['RUNSH'] = y.base64.b64encode(input_bin)

                if naked:
                    stdo = y.sys.stderr
                    stde = y.sys.stderr
                else:
                    stdo = sp.PIPE
                    stde = sp.STDOUT

                p = sp.Popen([self.shell, '-s'], stdout=stdo, stderr=stde, stdin=sp.PIPE, shell=False, env=env)
                res, _ = p.communicate(input=input_bin)
                res = res or ''
                retcode = p.wait()

                return (res, retcode)

            res, retcode = await ctl.loop.offload(y.set_name(fun, 'fun_' + y.sanitize_string(self.my_name)))
            res = res.strip()

            if not res:
                res = y.build_run_sh(self.n)

            out.append(res)

            if retcode == 0:
                if self.check:
                    self.check_results()
        except sp.CalledProcessError as e:
            out.append(e.output)
            retcode = e.returncode
        except Exception:
            out.append(y.format_tbx())
            retcode = -1

        return retcode, '\n'.join(y.super_decode(o.strip()) for o in out), input


async def run_par_build(ctl, mk, threads, check):
    async def run_par_build_1(ctl):
        b = Builder(ctl, mk, threads, check)

        return await b.run()

    y.info('{br}start build{}')

    try:
        return await ctl.spawn(run_par_build_1)
    finally:
        y.info('{br}end build{}')

+++++++++++++++++++
@y.singleton
def is_debug():
    return 'debug' in y.config.get('make', '')


async def run_makefile(mk, targets, threads, pre_run=[]):
    mmk = mk

    async def run_build_2(ctl):
        mk = mmk

        await y.cheet(mk)

        if pre_run:
            await run_par_build(ctl, await mk.select_targets(pre_run), 1, False)

        if targets:
            mk = await mk.select_targets(targets)

        return await run_par_build(ctl, mk, threads, True)

    return await y.spawn(run_build_2)


def wrap_gen(func):
    async def wrapper(ctl, inq):
        async for x in func(ctl, inq):
            yield x

    return wrapper


def CHANNEL(data):
    return y.DATA(tags=['mk:channel'], data=data)


class Builder(object):
    def __init__(self, ctl, mk, threads, check):
        self.check = check
        self.mk = mk
        self.threads = threads
        self.ctl = ctl
        self.lst = [item_factory(x, self, n) for n, x in enumerate(mk.lst)]

        by_dep = {}

        for x in self.lst:
            for d in x.deps1:
                by_dep[d] = x

        for k in by_dep.keys():
            self.resolve_path(k)

        self.by_dep = by_dep

    @property
    def shell_vars(self):
        return self.mk.flags

    @y.cached_method
    def resolve_path(self, d):
        return y.subst_vars(self.mk.strings[d], self.shell_vars)

    async def runner(self, ctl, inq):
        yield y.EOP(y.ACCEPT('mk:build', 'mk:channel'), y.PROVIDES('mk:ready'))

        async for el in inq:
            el = el.data.data

            is_debug() and y.debug('got', str(el))

            if el.get('action', '') == 'finish':
                yield y.FIN()

                return

            if (item := el.pop('item', None)) is not None:
                is_debug() and y.debug('run cmd', item)
                retcode = await item.run_cmd(ctl)
                is_debug() and y.debug('done run cmd', item, retcode)

                if retcode:
                    yield CHANNEL({'action': 'finish', 'status': 'failure'})
                    yield y.FIN()

                    return

                if item.my_name == '_all':
                    yield CHANNEL({'action': 'finish', 'status': 'success'})
                    yield y.FIN()

                    return

                yield y.EOP(y.ELEM({'ready': item}))
            else:
                yield y.EOP()

        assert False

    async def producer(self, ctl, inq):
        def iter_data():
            yield from self.lst

            lstl = len(self.lst)
            deps = sum([x.deps1 for x in self.lst], [])

            class ItemAll(object):
                @property
                def n(self):
                    return {'deps1': self.deps1, 'deps2': self.deps2, 'cmd': []}

                @property
                def my_name(self):
                    return '_all'

                @property
                def deps1(self):
                    return [self.num]

                @property
                def deps2(self):
                    return deps

                @property
                def num(self):
                    return lstl + 100000

                async def run_cmd(self, ctl):
                    y.build_results({
                        'status': 'fini',
                        'message': 'build complete',
                        'target': self.my_name,
                    })

                    return 0

            yield ItemAll()

        async def next_el():
            is_debug() and y.debug('wait next el')

            async for el in inq:
                el = el.data.data
                is_debug() and y.debug('got', el)
                return el

        rq, wq = y.make_engine(iter_data(), lambda x: x.deps1[0], dep_list=lambda x: sorted(frozenset(x.deps2)))

        if 0:
            while True:
                for i in list(rq()):
                    print(str(i['x']), file=y.stderr)
                    wq(i)

        by_n = {}
        complete = set()

        yield y.EOP(y.ACCEPT('mk:ready', 'mk:channel'), y.PROVIDES('mk:build'))

        def fmt_in_fly(data):
            return '(' + ', '.join([x['x'].my_name for x in data.values()]) + ')'

        while True:
            for i, el in enumerate(rq()):
                item = el['x']
                by_n[item.num] = el

                is_debug() and y.debug('yield ready', y.pretty_dumps(item), 'in fly', fmt_in_fly(by_n))

                yield y.ELEM({'item': item})
                yield y.EOP()

            yield y.EOP()

            el = await next_el()

            if el.get('action', '') == 'finish':
                yield y.FIN()

                return

            if (item := el.get('ready')) is not None:
                key = y.burn(item.n)
                assert key not in complete
                complete.add(key)
                wq(by_n.pop(item.num)['i'])
                is_debug() and y.debug('got complete', item, 'in fly', fmt_in_fly(by_n))

        assert False

    async def run(self):
        p = y.PubSubLoop(self.ctl)

        def iter_workers():
            yield y.set_name(wrap_gen(self.producer), 'producer_0')

            for i in range(0, self.threads):
                yield y.set_name(wrap_gen(self.runner), 'runner_' + str(i))

        return await p.run(coro=list(iter_workers()))


def item_factory(n, p, i):
    if n.get('cmd'):
        return Item(n, p, i)

    return ItemBase(n, p, i)


class ItemBase(object):
    def __init__(self, n, p, i):
        self.n = n
        self.p = p
        self.i = i

    def __str__(self):
        return y.json.dumps(self.__json__(), sort_keys=True)

    def __json__(self):
        return {
            'num': self.num,
            'cmd': self.cmd,
            'output': self.deps1[0],
            'inputs': self.deps2,
            'id': id(self),
        }

    @property
    def check(self):
        return self.p.check

    @property
    def num(self):
        return self.i

    @property
    def my_name(self):
        return ', '.join(self.str_deps1)

    @property
    def deps1(self):
        return self.n['deps1']

    @property
    def str_deps1(self):
        return self.p.mk.nums_to_str(self.deps1)

    @property
    def deps2(self):
        return self.n.get('deps2', [])

    @property
    def str_deps2(self):
        return self.p.mk.nums_to_str(self.deps2)

    @property
    def cmd(self):
        return self.n.get('cmd', [])

    @property
    def str_cmd(self):
        return self.p.mk.nums_to_str(self.cmd)

    @property
    def resolve_path(self):
        return self.p.resolve_path

    async def run_cmd(self, ctl):
        return 0


class Item(ItemBase):
    def __init__(self, n, p, i):
        ItemBase.__init__(self, n, p, i)

        assert self.cmd

        self.path = list(self.iter_search_path())
        self.shell = self.find_shell()
        assert self.shell
        self.env = self.prepare_env()

    def __json__(self):
        res = ItemBase.__json__(self)

        res.update({
            'shell': self.shell,
            'env': self.env,
        })

        return res

    @property
    def shell_vars(self):
        return self.p.shell_vars

    def prepare_env(self):
        return dict(y.itertools.chain({'OUTER_SHELL': self.shell}.items(), y.fix_shell_vars(self.shell_vars)))

    def find_tool(self, tool):
        if tool[0] == '/':
            return tool

        return y.find_tool_cached(tool, self.path)

    def iter_search_path(self):
        for d in self.deps2:
            yield y.os.path.join(y.os.path.dirname(self.resolve_path(d)), 'bin')

        yield from y.os.environ['PATH'].split(':')

    def find_shell(self):
        if '$YSHELL' in self.shell_vars:
            shell = self.find_tool(self.shell_vars['$YSHELL'])

            if shell:
                return shell

            raise Exception('can not find ' + self.shell_vars['$YSHELL'])

        return self.find_tool('dash') or self.find_tool('yash') or self.find_tool('bash') or self.find_tool('sh')

    def build_cmd(self):
        env = self.env

        def iter_cmd():
            yield 'set -e'
            yield 'set -x'

            for k in sorted(env, key=lambda x: -len(x)):
                yield 'export {k}={v}'.format(k=k, v=env[k])

            yield 'mainfun() {'

            for l in self.str_cmd:
                yield l

            yield '}'
            yield 'mainfun ' + ' '.join(y.itertools.chain(self.str_deps1, self.str_deps2))

        input = '\n'.join(iter_cmd()) + '\n'
        input = input.replace('$(SHELL)', '$YSHELL')

        return input

    def check_results(self):
        for x in self.deps1:
            x = self.resolve_path(x)

            try:
                assert y.os.path.isfile(x)
            except Exception as e:
                raise Exception(x + ' not exists: ' + str(e))

    def check_done(self):
        try:
            self.check_results()

            return True
        except Exception:
            pass

        return False

    async def run_cmd(self, ctl):
        target = self.my_name

        if self.check_done():
            y.build_results({
                'message': 'use cached {target}',
                'status': 'done',
                'target': target,
            })

            return 0

        y.build_results({
            'message': 'starting {target}',
            'status': 'init',
            'target': target,
        })

        retcode, res, input = await self.run_cmd_0(ctl)

        def iter_lines():
            for l in res.strip().split('\n'):
                if 'export ' in l:
                    yield l

        msg = {
            'output': '\n'.join(iter_lines()),
            'command': input,
            'target': target,
        }

        if retcode:
            msg.update({
                'message': 'target {target} failed',
                'status': 'fail',
                'retcode': retcode,
            })
        else:
            msg.update({
                'message': 'target {target} complete',
                'status': 'done',
            })

        y.build_results(msg)

        if retcode:
            y.shut_down(5, last_msg='{br}target ' + target + ' failed, exiting now{}\n')

    async def run_cmd_0(self, ctl):
        sp = y.subprocess
        out = []
        retcode = 0
        input = self.build_cmd()

        try:
            env = y.dc(self.env)
            #naked = 'source init' not in input
            naked = False

            def fun():
                input_bin = input.encode('utf-8')
                env['RUNSH'] = y.base64.b64encode(input_bin)

                if naked:
                    stdo = y.sys.stderr
                    stde = y.sys.stderr
                else:
                    stdo = sp.PIPE
                    stde = sp.STDOUT

                p = sp.Popen([self.shell, '-s'], stdout=stdo, stderr=stde, stdin=sp.PIPE, shell=False, env=env)
                res, _ = p.communicate(input=input_bin)
                res = res or ''
                retcode = p.wait()

                return (res, retcode)

            res, retcode = await ctl.loop.offload(y.set_name(fun, 'fun_' + y.sanitize_string(self.my_name)))
            res = res.strip()

            if not res:
                res = y.build_run_sh(self.n)

            out.append(res)

            if retcode == 0:
                if self.check:
                    self.check_results()
        except sp.CalledProcessError as e:
            out.append(e.output)
            retcode = e.returncode
        except Exception:
            out.append(y.format_tbx())
            retcode = -1

        return retcode, '\n'.join(y.super_decode(o.strip()) for o in out), input


async def run_par_build(ctl, mk, threads, check):
    async def run_par_build_1(ctl):
        b = Builder(ctl, mk, threads, check)

        return await b.run()

    y.info('{br}start build{}')

    try:
        return await ctl.spawn(run_par_build_1)
    finally:
        y.info('{br}end build{}')

--------------------&/ut/geom.py
class Point(object):
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def add_vector(self, dx, dy):
        return Point(self.x + dx, self.y + dy)


class Rect(Point):
    def __init__(self, p, w, h):
        Point.__init__(self, p.x, p.y)
        self.w = w
        self.h = h

    def add_border(self, w=1, h=1):
        return Rect(self.add_vector(w, h), self.w - 2 * w, self.h - 2 * h)

    def to_virtual(self):
        return Rect(Point(0, 0), self.w, self.h)

    def set_width(self, w):
        return Rect(self, w, self.h)

    def set_height(self, h):
        return Rect(self, self.w, h)

    def inc_height(self, h=1):
        return self.set_height(self.h + h)

    def dec_height(self, h=1):
        return self.set_height(self.h - h)

    def move(self, dx, dy):
        return Rect(self.add_vector(dx, dy), self.w, self.h)

    def move_down(self, dy):
        return self.move(0, dy)

    def move_up(self, dy):
        return self.move(0, -dy)

    def move_right(self, dx):
        return self.move(dx, 0)

    def move_left(self, dx):
        return self.move(-dx, 0)

    def __str__(self):
        return str([self.x, self.y, self.w, self.h])


def wh_rect(w, h):
    return Rect(Point(0, 0), w, h)

+++++++++++++++++++
class Point(object):
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def add_vector(self, dx, dy):
        return Point(self.x + dx, self.y + dy)


class Rect(Point):
    def __init__(self, p, w, h):
        Point.__init__(self, p.x, p.y)
        self.w = w
        self.h = h

    def add_border(self, w=1, h=1):
        return Rect(self.add_vector(w, h), self.w - 2 * w, self.h - 2 * h)

    def to_virtual(self):
        return Rect(Point(0, 0), self.w, self.h)

    def set_width(self, w):
        return Rect(self, w, self.h)

    def set_height(self, h):
        return Rect(self, self.w, h)

    def inc_height(self, h=1):
        return self.set_height(self.h + h)

    def dec_height(self, h=1):
        return self.set_height(self.h - h)

    def move(self, dx, dy):
        return Rect(self.add_vector(dx, dy), self.w, self.h)

    def move_down(self, dy):
        return self.move(0, dy)

    def move_up(self, dy):
        return self.move(0, -dy)

    def move_right(self, dx):
        return self.move(dx, 0)

    def move_left(self, dx):
        return self.move(-dx, 0)

    def __str__(self):
        return str([self.x, self.y, self.w, self.h])


def wh_rect(w, h):
    return Rect(Point(0, 0), w, h)

--------------------&/ut/shutdown.py
def get_white_line():
    return '{w}-----------------------------------------------{}'


def kill_all_running(*args):
    running_os = 'linux' #y.platform.system().lower()

    if running_os == 'darwin':
        return y.os.system('pkill -KILL -g {pgid}'.format(pgid=y.os.getpgid(y.os.getpid())))

    if running_os == 'linux':
        return y.os.system('pkill -KILL -P {ppid}'.format(ppid=y.os.getpid()))

    raise Exception('todo')


def run_sigint(*args):
    y.stderr.write('\r\n')
    y.stderr.flush()
    last_msg = get_white_line() + '\n{br}system failure{}\n'
    shut_down(retcode=8, last_msg=last_msg)


def shut_down(retcode=10, last_msg=''):
    y.run_handlers()
    kill_all_running()
    y.last_msg(last_msg)
    y.os._exit(retcode)


@y.defer_constructor
def init_shutdown():
    y.globals.sigint_handler = run_sigint

+++++++++++++++++++
def get_white_line():
    return '{w}-----------------------------------------------{}'


def kill_all_running(*args):
    running_os = 'linux' #y.platform.system().lower()

    if running_os == 'darwin':
        return y.os.system('pkill -KILL -g {pgid}'.format(pgid=y.os.getpgid(y.os.getpid())))

    if running_os == 'linux':
        return y.os.system('pkill -KILL -P {ppid}'.format(ppid=y.os.getpid()))

    raise Exception('todo')


def run_sigint(*args):
    y.stderr.write('\r\n')
    y.stderr.flush()
    last_msg = get_white_line() + '\n{br}system failure{}\n'
    shut_down(retcode=8, last_msg=last_msg)


def shut_down(retcode=10, last_msg=''):
    y.run_handlers()
    kill_all_running()
    y.last_msg(last_msg)
    y.os._exit(retcode)


@y.defer_constructor
def init_shutdown():
    y.globals.sigint_handler = run_sigint

--------------------&/ut/py_runtime.py
def monkey_patch():
    i = y.inspect
    getmodule = i.getmodule

    def my_get_module(name, _filename=None):
        if _filename:
            try:
                return __loader__._by_name[_filename[:-3].replace('/', '.')]
            except Exception:
                y.print_tbx()

        return getmodule(name, _filename=_filename)

    i.getmodule = my_get_module


monkey_patch()


def patch_ssl():
    ssl = y.ssl
    _create_default_context = ssl.create_default_context

    def create_default_context(*args, **kwargs):
        ctx = _create_default_context(*args, **kwargs)
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        return ctx

    ssl.create_default_context = create_default_context
    ssl._create_default_https_context = create_default_context


patch_ssl()


def my_eh(typ, val, tb):
    print(typ, val, tb)


class PGProfiler(object):
    def __init__(self):
        self.d = []
        self.i = {}
        self.w = True
        self.t = y.threading.get_ident
        self.n = 0

    def my_trace(self, frame, event, arg):
        if not self.w:
            return

        self.n += 1

        lineno = frame.f_lineno
        path = frame.f_code.co_filename

        self.d.append((self.get_id(lineno), self.get_id(path), self.get_id(self.t())))

        return self.my_trace

    def heavy(self):
        lines = calc_text(frame, path)
        data ='\n'.join(lines[lineno-2:lineno + 1])

        try:
            arg = str(arg)
        except Exception as e:
            arg = e

        print(frame, event, arg, data)

    def get_id(self, k):
        i = self.i

        if k not in i:
            i[k] = len(i)

        return i[k]

    def dumps(self):
        try:
            self.w = False
            res = {'d': self.d, 'i': self.i}

            return y.encode_prof(res)
        finally:
            self.w = True

    def loads(self, v):
        res = y.decode_prof(v)

        self.i = res['i']
        self.d = res['d']

    def load_from_file(self, path):
        with open(path, 'r') as f:
            self.loads(f.buffer.read())

    def show_stats(self):
        def iter_keys():
            for l, f, t in self.d:
                yield (l, f)

        i = self.i
        i = dict((y, x) for x, y in i.items())
        d = y.collections.defaultdict(int)

        for x in iter_keys():
            d[x] += 1

        def iter_nk():
            for k, v in d.items():
                nk = str(i[k[1]]) + ':' + str(i[k[0]])

                yield nk, v

        res = sorted(list(iter_nk()), key=lambda x: -x[1])

        for i, j in res:
            print(i, j)

    def run(self, args):
        self.load_from_file(args[0])
        self.show_stats()


def my_exept_hook(type, value, traceback):
    print(type, value, traceback)


@y.defer_constructor
def init():
    @y.main_entry_point
    async def cli_dev_profile(args):
        PGProfiler().run(args)

    y.sys.excepthook = my_exept_hook

    if 'pg' in y.config.get('profile', ''):
        prof = PGProfiler()

        @y.run_at_exit
        def dump_data():
            try:
                with open('data.prof', 'w') as f:
                    data = prof.dumps()
                    f.buffer.write(data)
            except Exception as e:
                y.stderr.write(str(e) + '\n')

        y.globals.trace_function = prof.my_trace


def iter_frames(frame=None):
    frame = frame or y.inspect.currentframe()

    while frame:
        yield frame
        frame = frame.f_back


@y.cached
def text_from_file(path):
    return open(path).read().split('\n')


def mod_key(f):
    try:
        return len(f.f_globals['__ytext__'])
    except Exception:
        pass

    return -1


@y.cached(key=mod_key)
def text_from_module(f):
    return f.f_globals['__ytext__'].split('\n')


def calc_text(f, fname):
    for i in (lambda: text_from_module(f), lambda: text_from_file(fname), lambda: []):
        try:
            return i()
        except Exception:
            pass


def iter_tb_info(tb):
    while tb:
        f = tb.tb_frame
        co = f.f_code
        lineno = tb.tb_lineno - 1
        filename = co.co_filename
        name = co.co_name
        tb = tb.tb_next

        yield filename, lineno, name, f


def iter_frame_info(frames):
    for f in frames:
        fname = f.f_code.co_filename or f.f_globals['__file__']
        ln = f.f_lineno - 1
        func_name = f.f_code.co_name

        yield fname, ln, func_name, f


def iter_full_info(iter):
    for fname, ln, func_name, f in iter:
        lines = calc_text(f, fname)

        if not lines:
            lines = []

        if len(lines) < ln:
            text = []
        else:
            def iter():
                for i, l in enumerate(lines[ln - 1: ln + 2]):
                    if not l.strip():
                        continue

                    yield i + ln - 1, l.replace('\t', '    ')

            text = list(iter())

        yield (fname, ln, func_name, text)


def max_substr(lines):
    def calc(ss):
        for _, l in lines:
            if not l.startswith(ss):
                if ss:
                    return ss[:-1]
                else:
                    return ss

        return calc(ss + ' ')

    return calc('')


def format_trace(l):
    fname, ln, func_name, text = l

    yield ' {bw}In {bdg}' + fname + '{}, in {bg}' + func_name + '{}:{}'

    if not text:
        return

    ss = max_substr(text)

    l1 = text[0][0]
    l2 = text[-1][0]

    max_len = len(str(l2))

    for lnn, t in text:
        yield (6 - len(str(lnn))) * ' ' + '{bb}' + str(lnn) + ': ' + {ln: '{br}'}.get(lnn, '{bw}') + t[len(ss):] + '{}{}'


def format_tbv(tb_line=''):
    value = y.sys.exc_info()[1]
    type = y.sys.exc_info()[0]

    if tb_line:
        tb_line = ', ' + tb_line

    return '{r}Exception of type {type}: {exc}{tb_line}:{}'.replace('{type}', str(type)).replace('{exc}', str(value)).replace('{tb_line}', tb_line)


def current_frame():
    try:
        raise ZeroDivisionError
    except ZeroDivisionError:
        return y.sys.exc_info()[2].tb_frame.f_back


def format_tbx(tb_line='', frame=None):
    if not y.verbose:
        return format_tbv(tb_line=tb_line)

    if frame:
        tb = None
    else:
        tb = y.sys.exc_info()[2]

    def iter_exc():
        yield format_tbv(tb_line=tb_line)

        for x in iter_full_info(reversed(list(iter_tb_info(tb)))):
            for l in format_trace(x):
                yield l

    def iter_fr():
        yield '{g}Traceback: {line}{}'.replace('{line}', tb_line)

        for x in iter_full_info(list(iter_frame_info(iter_frames(frame or current_frame())))):
            for l in format_trace(x):
                yield l

    return '\n'.join((tb and iter_exc or iter_fr)())


def print_tbx(*args, **kwargs):
    try:
        y.xxprint(format_tbx(*args, **kwargs))
    except Exception as e:
        y.traceback.print_exc(e)


def print_all_stacks():
    try:
        for k, v in list(y.sys._current_frames().items()):
            y.print_tbx(tb_line=str(k), frame=v)
    except Exception:
        y.print_tbx()


class AbortHandler(object):
    def __init__(self):
        self.sys = y.sys
        self.f1 = format_tbx
        self.f2 = y.traceback.format_exc
        self.cf = current_frame

    def handle(self):
        o = self.sys.stderr

        try:
            try:
                o.write(self.f1() + '\n')
                if y.verbose:
                    o.write(self.f1(frame=self.cf()) + '\n')
            except:
                o.write(self.f2())
        finally:
            o.flush()


y.globals.abort_handler = AbortHandler().handle

+++++++++++++++++++
def monkey_patch():
    i = y.inspect
    getmodule = i.getmodule

    def my_get_module(name, _filename=None):
        if _filename:
            try:
                return __loader__._by_name[_filename[:-3].replace('/', '.')]
            except Exception:
                y.print_tbx()

        return getmodule(name, _filename=_filename)

    i.getmodule = my_get_module


monkey_patch()


def patch_ssl():
    ssl = y.ssl
    _create_default_context = ssl.create_default_context

    def create_default_context(*args, **kwargs):
        ctx = _create_default_context(*args, **kwargs)
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        return ctx

    ssl.create_default_context = create_default_context
    ssl._create_default_https_context = create_default_context


patch_ssl()


def my_eh(typ, val, tb):
    print(typ, val, tb)


class PGProfiler(object):
    def __init__(self):
        self.d = []
        self.i = {}
        self.w = True
        self.t = y.threading.get_ident
        self.n = 0

    def my_trace(self, frame, event, arg):
        if not self.w:
            return

        self.n += 1

        lineno = frame.f_lineno
        path = frame.f_code.co_filename

        self.d.append((self.get_id(lineno), self.get_id(path), self.get_id(self.t())))

        return self.my_trace

    def heavy(self):
        lines = calc_text(frame, path)
        data ='\n'.join(lines[lineno-2:lineno + 1])

        try:
            arg = str(arg)
        except Exception as e:
            arg = e

        print(frame, event, arg, data)

    def get_id(self, k):
        i = self.i

        if k not in i:
            i[k] = len(i)

        return i[k]

    def dumps(self):
        try:
            self.w = False
            res = {'d': self.d, 'i': self.i}

            return y.encode_prof(res)
        finally:
            self.w = True

    def loads(self, v):
        res = y.decode_prof(v)

        self.i = res['i']
        self.d = res['d']

    def load_from_file(self, path):
        with open(path, 'r') as f:
            self.loads(f.buffer.read())

    def show_stats(self):
        def iter_keys():
            for l, f, t in self.d:
                yield (l, f)

        i = self.i
        i = dict((y, x) for x, y in i.items())
        d = y.collections.defaultdict(int)

        for x in iter_keys():
            d[x] += 1

        def iter_nk():
            for k, v in d.items():
                nk = str(i[k[1]]) + ':' + str(i[k[0]])

                yield nk, v

        res = sorted(list(iter_nk()), key=lambda x: -x[1])

        for i, j in res:
            print(i, j)

    def run(self, args):
        self.load_from_file(args[0])
        self.show_stats()


def my_exept_hook(type, value, traceback):
    print(type, value, traceback)


@y.defer_constructor
def init():
    @y.main_entry_point
    async def cli_dev_profile(args):
        PGProfiler().run(args)

    y.sys.excepthook = my_exept_hook

    if 'pg' in y.config.get('profile', ''):
        prof = PGProfiler()

        @y.run_at_exit
        def dump_data():
            try:
                with open('data.prof', 'w') as f:
                    data = prof.dumps()
                    f.buffer.write(data)
            except Exception as e:
                y.stderr.write(str(e) + '\n')

        y.globals.trace_function = prof.my_trace


def iter_frames(frame=None):
    frame = frame or y.inspect.currentframe()

    while frame:
        yield frame
        frame = frame.f_back


@y.cached
def text_from_file(path):
    return open(path).read().split('\n')


def mod_key(f):
    try:
        return len(f.f_globals['__ytext__'])
    except Exception:
        pass

    return -1


@y.cached(key=mod_key)
def text_from_module(f):
    return f.f_globals['__ytext__'].split('\n')


def calc_text(f, fname):
    for i in (lambda: text_from_module(f), lambda: text_from_file(fname), lambda: []):
        try:
            return i()
        except Exception:
            pass


def iter_tb_info(tb):
    while tb:
        f = tb.tb_frame
        co = f.f_code
        lineno = tb.tb_lineno - 1
        filename = co.co_filename
        name = co.co_name
        tb = tb.tb_next

        yield filename, lineno, name, f


def iter_frame_info(frames):
    for f in frames:
        fname = f.f_code.co_filename or f.f_globals['__file__']
        ln = f.f_lineno - 1
        func_name = f.f_code.co_name

        yield fname, ln, func_name, f


def iter_full_info(iter):
    for fname, ln, func_name, f in iter:
        lines = calc_text(f, fname)

        if not lines:
            lines = []

        if len(lines) < ln:
            text = []
        else:
            def iter():
                for i, l in enumerate(lines[ln - 1: ln + 2]):
                    if not l.strip():
                        continue

                    yield i + ln - 1, l.replace('\t', '    ')

            text = list(iter())

        yield (fname, ln, func_name, text)


def max_substr(lines):
    def calc(ss):
        for _, l in lines:
            if not l.startswith(ss):
                if ss:
                    return ss[:-1]
                else:
                    return ss

        return calc(ss + ' ')

    return calc('')


def format_trace(l):
    fname, ln, func_name, text = l

    yield ' {bw}In {bdg}' + fname + '{}, in {bg}' + func_name + '{}:{}'

    if not text:
        return

    ss = max_substr(text)

    l1 = text[0][0]
    l2 = text[-1][0]

    max_len = len(str(l2))

    for lnn, t in text:
        yield (6 - len(str(lnn))) * ' ' + '{bb}' + str(lnn) + ': ' + {ln: '{br}'}.get(lnn, '{bw}') + t[len(ss):] + '{}{}'


def format_tbv(tb_line=''):
    value = y.sys.exc_info()[1]
    type = y.sys.exc_info()[0]

    if tb_line:
        tb_line = ', ' + tb_line

    return '{r}Exception of type {type}: {exc}{tb_line}:{}'.replace('{type}', str(type)).replace('{exc}', str(value)).replace('{tb_line}', tb_line)


def current_frame():
    try:
        raise ZeroDivisionError
    except ZeroDivisionError:
        return y.sys.exc_info()[2].tb_frame.f_back


def format_tbx(tb_line='', frame=None):
    if not y.verbose:
        return format_tbv(tb_line=tb_line)

    if frame:
        tb = None
    else:
        tb = y.sys.exc_info()[2]

    def iter_exc():
        yield format_tbv(tb_line=tb_line)

        for x in iter_full_info(reversed(list(iter_tb_info(tb)))):
            for l in format_trace(x):
                yield l

    def iter_fr():
        yield '{g}Traceback: {line}{}'.replace('{line}', tb_line)

        for x in iter_full_info(list(iter_frame_info(iter_frames(frame or current_frame())))):
            for l in format_trace(x):
                yield l

    return '\n'.join((tb and iter_exc or iter_fr)())


def print_tbx(*args, **kwargs):
    try:
        y.xxprint(format_tbx(*args, **kwargs))
    except Exception as e:
        y.traceback.print_exc(e)


def print_all_stacks():
    try:
        for k, v in list(y.sys._current_frames().items()):
            y.print_tbx(tb_line=str(k), frame=v)
    except Exception:
        y.print_tbx()


class AbortHandler(object):
    def __init__(self):
        self.sys = y.sys
        self.f1 = format_tbx
        self.f2 = y.traceback.format_exc
        self.cf = current_frame

    def handle(self):
        o = self.sys.stderr

        try:
            try:
                o.write(self.f1() + '\n')
                if y.verbose:
                    o.write(self.f1(frame=self.cf()) + '\n')
            except:
                o.write(self.f2())
        finally:
            o.flush()


y.globals.abort_handler = AbortHandler().handle

disable caching
disable caching
--------------------&/ut/data_format.py
import lzma
import marshal


def decode_prof(data):
    return marshal.loads(lzma.decompress(data))


def encode_prof(v):
    return lzma.compress(marshal.dumps(v))


class SimpleDB(object):
    def __init__(self, path):
        self.path = y.os.path.expanduser(path)

        try:
            y.os.makedirs(y.os.path.dirname(self.path))
        except OSError:
            pass

    def read_db(self):
        try:
            y.debug('{bb}open db ' + self.path + '{}')

            with open(self.path, 'rb') as f:
                return decode_prof(f.read())
        except Exception as e:
            y.info('{br}' + str(e) + ', can not load db, reinitialize...{}')

        return {}

    def write_db(self, data):
        y.info('{bg}write new version of ' + self.path + '{}')

        with open(self.path, 'wb') as f:
            f.write(encode_prof(data))
            f.flush()

    def rcu(self, func):
        self.write_db(func(self.read_db()))


def get_key(db, k, default):
    if k not in db:
        db[k] = default

    return db[k]


@y.contextlib.contextmanager
def open_simple_db(path):
    db = SimpleDB(path)
    data = db.read_db()
    md5 = y.burn(y.json.dumps(data, sort_keys=True))

    try:
        yield data
    finally:
        new_md5 = y.burn(y.json.dumps(data, sort_keys=True))

        if md5 == new_md5:
            y.debug('db not changed, not write it')
        else:
            db.write_db(data)

+++++++++++++++++++
import lzma
import marshal


def decode_prof(data):
    return marshal.loads(lzma.decompress(data))


def encode_prof(v):
    return lzma.compress(marshal.dumps(v))


class SimpleDB(object):
    def __init__(self, path):
        self.path = y.os.path.expanduser(path)

        try:
            y.os.makedirs(y.os.path.dirname(self.path))
        except OSError:
            pass

    def read_db(self):
        try:
            y.debug('{bb}open db ' + self.path + '{}')

            with open(self.path, 'rb') as f:
                return decode_prof(f.read())
        except Exception as e:
            y.info('{br}' + str(e) + ', can not load db, reinitialize...{}')

        return {}

    def write_db(self, data):
        y.info('{bg}write new version of ' + self.path + '{}')

        with open(self.path, 'wb') as f:
            f.write(encode_prof(data))
            f.flush()

    def rcu(self, func):
        self.write_db(func(self.read_db()))


def get_key(db, k, default):
    if k not in db:
        db[k] = default

    return db[k]


@y.contextlib.contextmanager
def open_simple_db(path):
    db = SimpleDB(path)
    data = db.read_db()
    md5 = y.burn(y.json.dumps(data, sort_keys=True))

    try:
        yield data
    finally:
        new_md5 = y.burn(y.json.dumps(data, sort_keys=True))

        if md5 == new_md5:
            y.debug('db not changed, not write it')
        else:
            db.write_db(data)

--------------------&/ut/run_sh.py
import sys
import base64


def subst(v):
    def iter_subst():
        yield ('$MD', '$PREFIX/m')
        yield ('$RD', '$PREFIX/r')
        yield ('$WD', '$PREFIX/w')
        yield ('$PD', '$PREFIX/p')

    return y.subst_kv_base(v, iter_subst())


async def build_sh_script(targets):
    res = [1]
    await y.run_makefile(y.main_makefile(), res, targets, 1)
    res = res[1:]

    def iter_cmd():
        for cmd in res:
            try:
                input = subst(cmd['input'])

                if 'EOF' in input:
                    input = input + 'EOF\n'

                yield '(echo "export PREFIX=$1"; (echo "' + base64.b64encode(input) + '" | base64 -D -i - -o -)) > data; (cat data | /usr/bin/env -i /usr/local/bin/dash -s) || exit 1'
            except Exception as e:
                y.xprint_red('------------------------------------------\n', cmd, e)

    return '\n\n'.join(iter_cmd()) + '\n'

+++++++++++++++++++
import sys
import base64


def subst(v):
    def iter_subst():
        yield ('$MD', '$PREFIX/m')
        yield ('$RD', '$PREFIX/r')
        yield ('$WD', '$PREFIX/w')
        yield ('$PD', '$PREFIX/p')

    return y.subst_kv_base(v, iter_subst())


async def build_sh_script(targets):
    res = [1]
    await y.run_makefile(y.main_makefile(), res, targets, 1)
    res = res[1:]

    def iter_cmd():
        for cmd in res:
            try:
                input = subst(cmd['input'])

                if 'EOF' in input:
                    input = input + 'EOF\n'

                yield '(echo "export PREFIX=$1"; (echo "' + base64.b64encode(input) + '" | base64 -D -i - -o -)) > data; (cat data | /usr/bin/env -i /usr/local/bin/dash -s) || exit 1'
            except Exception as e:
                y.xprint_red('------------------------------------------\n', cmd, e)

    return '\n\n'.join(iter_cmd()) + '\n'

--------------------&/ut/xpath.py
def apply_base(funcs, log):
    for f in funcs:
        try:
            yield f()
        except Exception as e:
            log.append((f, e))


def apply_any_0(funcs, log):
    for r in apply_base(funcs, log):
        return r

    raise Exception('shit happen')


def fv(f, v):
    return lambda: f(v)


def iter_lst(v, lst):
    for f in lst:
        yield fv(f, v)


def apply_any(v, lst, log):
    return apply_any_0(iter_lst(v, lst), log)


def apply_all(v, lst, log):
    return list(apply_base(iter_lst(v, lst), log))


def my_restore_node(x):
    res = y.is_pointer(x)

    if res:
        return res

    raise TypeError()


def run_xpath(val, path, log=[]):
    def try_call(x):
        return apply_any(x, (my_restore_node, lambda x: x(), lambda x: x), log)

    def param_lst(p):
        return apply_all(p, (str, int, float), log)

    def f1(a):
        x, p = a

        return x[p]

    def f2(a):
        x, p = a

        return x(p)

    def iter_funcs(pp, x):
        for f in (f1, f2):
            for p in pp:
                yield fv(f, (x, p))

        yield lambda: eval('x' + pp[0], {'x': x, 'pp': pp})
        yield lambda: eval('x.' + pp[0], {'x': x, 'pp': pp})

    x = val

    for p in path.split('/'):
        log.append(('before', x, p))
        x = try_call(apply_any_0(iter_funcs(param_lst(p), try_call(x)), log))
        log.append(('after', x, p))

    return x


def run_xpath_simple(val, path):
    log = []

    try:
        return run_xpath(val, path, log=log)
    except Exception as e:
        log.append(('at end', str(e)))

        def iter_recs():
            for l in log:
                yield '[' + ', '.join([str(x) for x in l]) + ']'

        raise Exception('shit happen %s' % '\n'.join(iter_recs()))


def xpp(val, path):
    return run_xpath_simple(val, path)


def xp(path):
    if path.startswith('//'):
        return run_xpath_simple(globals(), path[2:])

    if path.startswith('/'):
        name, path = path[1:].split('/', 1)

        for frame in y.iter_frames():
            if name in frame.f_locals:
                return run_xpath_simple(frame.f_locals[name], path)

    raise Exception('shit happen')

+++++++++++++++++++
def apply_base(funcs, log):
    for f in funcs:
        try:
            yield f()
        except Exception as e:
            log.append((f, e))


def apply_any_0(funcs, log):
    for r in apply_base(funcs, log):
        return r

    raise Exception('shit happen')


def fv(f, v):
    return lambda: f(v)


def iter_lst(v, lst):
    for f in lst:
        yield fv(f, v)


def apply_any(v, lst, log):
    return apply_any_0(iter_lst(v, lst), log)


def apply_all(v, lst, log):
    return list(apply_base(iter_lst(v, lst), log))


def my_restore_node(x):
    res = y.is_pointer(x)

    if res:
        return res

    raise TypeError()


def run_xpath(val, path, log=[]):
    def try_call(x):
        return apply_any(x, (my_restore_node, lambda x: x(), lambda x: x), log)

    def param_lst(p):
        return apply_all(p, (str, int, float), log)

    def f1(a):
        x, p = a

        return x[p]

    def f2(a):
        x, p = a

        return x(p)

    def iter_funcs(pp, x):
        for f in (f1, f2):
            for p in pp:
                yield fv(f, (x, p))

        yield lambda: eval('x' + pp[0], {'x': x, 'pp': pp})
        yield lambda: eval('x.' + pp[0], {'x': x, 'pp': pp})

    x = val

    for p in path.split('/'):
        log.append(('before', x, p))
        x = try_call(apply_any_0(iter_funcs(param_lst(p), try_call(x)), log))
        log.append(('after', x, p))

    return x


def run_xpath_simple(val, path):
    log = []

    try:
        return run_xpath(val, path, log=log)
    except Exception as e:
        log.append(('at end', str(e)))

        def iter_recs():
            for l in log:
                yield '[' + ', '.join([str(x) for x in l]) + ']'

        raise Exception('shit happen %s' % '\n'.join(iter_recs()))


def xpp(val, path):
    return run_xpath_simple(val, path)


def xp(path):
    if path.startswith('//'):
        return run_xpath_simple(globals(), path[2:])

    if path.startswith('/'):
        name, path = path[1:].split('/', 1)

        for frame in y.iter_frames():
            if name in frame.f_locals:
                return run_xpath_simple(frame.f_locals[name], path)

    raise Exception('shit happen')

--------------------&/ut/cli_misc.py
@y.verbose_entry_point
async def cli_misc_cleanup(arg):
   y.os.system("find . | grep '~' | xargs rm")
   y.os.system("find . | grep '#' | xargs rm")
   y.os.system('find . | grep "\\.tmp" | xargs rm')

   def fix1(data):
      return data.replace('    \n', '\n')

   fixers = [
      fix1,
   ]
   
   for a, b, c in y.os.walk('.'):
      for x in c:
         pp = y.os.path.join(a, x)

         if pp.endswith('.py'):
            with open(pp, 'r') as f:
               orig = f.read()

            data = orig
   
            for i in range(0, 2):
               for j in fixers:
                  data = j(data)

            if data != orig:
               with open(pp + '.$tmp', 'w') as f:
                  f.write(data)

               y.os.rename(pp + '.$tmp', pp)
   

@y.main_entry_point
async def cli_misc_help(args):
   def iter_funcs():
      allow = 'm'

      if '-v' in y.sys.argv or '-vm' in y.sys.argv:
         allow += 'v'

      mep = y.main_entry_points()
  
      for name in mep:
         t, f = mep[name]
 
         if t in allow:
            yield name.replace('_', ' ')

   arg = y.sys.argv[0]
   funcs = sorted(set(iter_funcs()))
   text = 'usage: ' + arg + ' (-v, -vm debug options)* [command] (command options)*{bb}' + '\n    '.join([''] + funcs) + '{}'
   
   y.xprint_bg(text)


@y.main_entry_point
async def cli_misc_pip(args):
    import signal

    def ff(a, b):
        return ff

    signal.signal = ff

    y.sys.argv = ['pip3'] + args
    y.sys.argv[0] = y.re.sub(r'(-script\.pyw?|\.exe)?$', '', y.sys.argv[0])

    try:
       from pip._internal.main import main
    except ImportError:
       from pip._internal import main
   
    y.sys.exit(main())


@y.main_entry_point
async def cli_dev_repl(args):
   frame = y.inspect.currentframe()
   frame = frame.f_back

   try:
      from ptpython.repl import embed
   
      embed(frame.f_globals, locals())
   except ImportError:
      y.code.interact(local=frame.f_globals)
   except Exception as e:
      y.debug('in prompt', e)

+++++++++++++++++++
@y.verbose_entry_point
async def cli_misc_cleanup(arg):
   y.os.system("find . | grep '~' | xargs rm")
   y.os.system("find . | grep '#' | xargs rm")
   y.os.system('find . | grep "\\.tmp" | xargs rm')

   def fix1(data):
      return data.replace('    \n', '\n')

   fixers = [
      fix1,
   ]
   
   for a, b, c in y.os.walk('.'):
      for x in c:
         pp = y.os.path.join(a, x)

         if pp.endswith('.py'):
            with open(pp, 'r') as f:
               orig = f.read()

            data = orig
   
            for i in range(0, 2):
               for j in fixers:
                  data = j(data)

            if data != orig:
               with open(pp + '.$tmp', 'w') as f:
                  f.write(data)

               y.os.rename(pp + '.$tmp', pp)
   

@y.main_entry_point
async def cli_misc_help(args):
   def iter_funcs():
      allow = 'm'

      if '-v' in y.sys.argv or '-vm' in y.sys.argv:
         allow += 'v'

      mep = y.main_entry_points()
  
      for name in mep:
         t, f = mep[name]
 
         if t in allow:
            yield name.replace('_', ' ')

   arg = y.sys.argv[0]
   funcs = sorted(set(iter_funcs()))
   text = 'usage: ' + arg + ' (-v, -vm debug options)* [command] (command options)*{bb}' + '\n    '.join([''] + funcs) + '{}'
   
   y.xprint_bg(text)


@y.main_entry_point
async def cli_misc_pip(args):
    import signal

    def ff(a, b):
        return ff

    signal.signal = ff

    y.sys.argv = ['pip3'] + args
    y.sys.argv[0] = y.re.sub(r'(-script\.pyw?|\.exe)?$', '', y.sys.argv[0])

    try:
       from pip._internal.main import main
    except ImportError:
       from pip._internal import main
   
    y.sys.exit(main())


@y.main_entry_point
async def cli_dev_repl(args):
   frame = y.inspect.currentframe()
   frame = frame.f_back

   try:
      from ptpython.repl import embed
   
      embed(frame.f_globals, locals())
   except ImportError:
      y.code.interact(local=frame.f_globals)
   except Exception as e:
      y.debug('in prompt', e)

--------------------&/ut/cli_release.py
@y.main_entry_point
async def cli_cmd_release(args):
   data = {'file_data': y.globals.file_data, 'script_path': y.globals.script_path, 'compile_cache': y.globals.cache}
   data = y.marshal.dumps(data)
   data = y.lzma.compress(data)
   data = y.base64.b64encode(data)

   code = 'import marshal; import lzma; import base64; fd = marshal.loads(lzma.decompress(base64.b64decode("{data}"))); file_data = fd["file_data"];'
   code = code.replace('{data}', data.decode('utf-8'))

   for x in y.globals.file_data:
      if x['path'].endswith('cli'):
         break

   print(x['data'].replace('#REPLACEME', code))

+++++++++++++++++++
@y.main_entry_point
async def cli_cmd_release(args):
   data = {'file_data': y.globals.file_data, 'script_path': y.globals.script_path, 'compile_cache': y.globals.cache}
   data = y.marshal.dumps(data)
   data = y.lzma.compress(data)
   data = y.base64.b64encode(data)

   code = 'import marshal; import lzma; import base64; fd = marshal.loads(lzma.decompress(base64.b64decode("{data}"))); file_data = fd["file_data"];'
   code = code.replace('{data}', data.decode('utf-8'))

   for x in y.globals.file_data:
      if x['path'].endswith('cli'):
         break

   print(x['data'].replace('#REPLACEME', code))

--------------------&/ut/make.py
def output_build_results(arg):
    if 'target' in arg:
        arg['_target'] = y.to_pretty_name(arg.pop('target'))

    if 'output' in arg:
        data = arg.pop('output').strip()

    if (status := arg.get('status', '')) == 'fail':
        arg['message'] = arg.get('message', '') + '\n' + data

    if 'message' in arg:
        y.build_results({'info': {'message': arg.pop('message'), 'extra': arg}})

    if 'info' in arg:
        y.info(arg['info']['message'], extra=arg['info']['extra'])


async def run_make_0(mk, args):
    async def do_run(build_results):
        @y.lookup
        def lookup(name):
            return {'build_results': build_results}[name]

        return await y.run_makefile(mk, args.targets, int(args.threads), pre_run=args.pre_run)

    async def do_run_log():
        return await do_run(output_build_results)

    return await y.spawn(do_run_log)

+++++++++++++++++++
def output_build_results(arg):
    if 'target' in arg:
        arg['_target'] = y.to_pretty_name(arg.pop('target'))

    if 'output' in arg:
        data = arg.pop('output').strip()

    if (status := arg.get('status', '')) == 'fail':
        arg['message'] = arg.get('message', '') + '\n' + data

    if 'message' in arg:
        y.build_results({'info': {'message': arg.pop('message'), 'extra': arg}})

    if 'info' in arg:
        y.info(arg['info']['message'], extra=arg['info']['extra'])


async def run_make_0(mk, args):
    async def do_run(build_results):
        @y.lookup
        def lookup(name):
            return {'build_results': build_results}[name]

        return await y.run_makefile(mk, args.targets, int(args.threads), pre_run=args.pre_run)

    async def do_run_log():
        return await do_run(output_build_results)

    return await y.spawn(do_run_log)

--------------------&/ut/stagea.py
import os
import sys
import signal
import threading
import traceback
import collections
import hashlib
import json

from marshal import loads, dumps


def y_burn(p):
    return y_struct_dump_bytes(p)


def y_struct_dump_bytes(p):
    return hashlib.md5(dumps(p)).hexdigest()[:16]


def set_profile(g):
    if 'profile=pg' not in ''.join(sys.argv):
        return

    g.trace_function = lambda *args: None

    def trace(*args):
        g.trace_function(*args)

    sys.settrace(trace)
    thread.settrace(trace)


def set_sigint(g):
    g.sigint_handler = lambda *args: os._exit(8)

    def sig_handler(*args):
        g.sigint_handler(*args)

    signal.signal(signal.SIGINT, sig_handler)
    signal.signal(signal.SIGPIPE, signal.SIG_IGN)


def set_abort(g):
    ctx = {
        'os': os,
        'sys': sys,
        'tb': traceback,
        'str': str,
    }

    g.trash = ctx
    g.abort_function = os.abort

    def xprint(*args):
        err = g.trash['sys'].__stderr__
        str = g.trash['str']

        err.write(' '.join(str(x) for x in args) + '\n')
        err.flush()

    def abort_handler():
        xprint(g.trash['tb'].format_exc())

    g.abort_handler = abort_handler

    def new_abort():
        g.trash['os'].__dict__.pop('abort')

        try:
            try:
                g.abort_handler()
            except Exception as e:
                xprint('while handling abort', e)
        finally:
            g.abort_function()

    os.abort = new_abort


def set_env(g):
    sys.argv[0] = g.script_path
    sys.dont_write_bytecode = True
    #os.environ['PATH'] = '/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin'
    set_sigint(g)
    set_abort(g)
    set_profile(g)


def preprocess_data(data):
    p1 = data.find('                           ')

    if p1 > 0 and p2 > 0:
        d1 = data[:p1]
        d2 = data[p2 + 2:]

        return preprocess_data(d1 + ' ' * (p2 + 2 - p1) + d2)

    return data.replace('yield from y.current_coro().slave **', 'yield from y.current_coro().slave **')


def fix_print(data):
    def iter_lines():
        for l in data.split('\n'):
            ll = l.strip()

            if '>>' in ll:
                yield l
            elif ll.startswith('print '):
                l = l.replace('print ', 'print(') + ', file=y.stderr)'

                yield l
            else:
                yield l

    return '\n'.join(iter_lines())


def bad_name(x):
    if '~' in x:
        return True

    if '#' in x:
        return True
   
    if x[0] == '.':
        return True

    return False


def load_folders(folders, exts, where):
    replace = {
        'ya': 'ya',
        'plugins': 'pl',
        'plugins/lib': 'data',
        'scripts': 'sc',
        'ut': 'ut',
    }

    data = open(where).read()
    yield {'name': os.path.basename(where), 'path': where, 'data': data, 'burn': y_burn(data)}

    for f in folders:
        fp = os.path.join(os.path.dirname(where), f)
  
        for x in os.listdir(fp):
            if bad_name(x):
                continue

            parts = x.split('.')
            name = os.path.join(replace[f], x)
            path = os.path.join(fp, x)

            if not os.path.isfile(path):
                continue

            with open(path) as fff:
                data = preprocess_data(fff.read())

                if parts[-1] == 'py':
                    data = fix_print(data)

            yield {'name': name, 'path': path, 'data': data, 'burn': y_burn(data)}


def load_system(where):
    return list(load_folders(['plugins', 'plugins/lib', 'scripts', 'ya', 'ut'], ['py', ''], where))


def iter_prefix(x):
    l = ''

    for y in x:
        l = l + y

        yield l


def thr_func(g):
    try:
        g.file_data = g.file_data or load_system(g.script_path)
        g.by_name = dict((x['name'], x) for x in g.file_data)
        g.by_prefix = collections.defaultdict(set)

        for i, x in enumerate(g.file_data):
            for w in x['data'].split():
                for p in iter_prefix(w):
                    g.by_prefix[p].add(x['burn'])

        ctx = {'_globals': g}
        exec(g.compile((g.by_name['ut/stage0.py']['data'] + '\nrun_stage0(_globals)\n'), 'ut/stage0.py', 'exec'), ctx)
        ctx.clear()
    except Exception:
        try:
            sys.stderr.write('can not initialize runtime\n')
        finally:
            os.abort()


def main(g):
    set_env(g)
    t = threading.Thread(target=lambda: thr_func(g))
    t.start()
    t.join()

+++++++++++++++++++
import os
import sys
import signal
import threading
import traceback
import collections
import hashlib
import json

from marshal import loads, dumps


def y_burn(p):
    return y_struct_dump_bytes(p)


def y_struct_dump_bytes(p):
    return hashlib.md5(dumps(p)).hexdigest()[:16]


def set_profile(g):
    if 'profile=pg' not in ''.join(sys.argv):
        return

    g.trace_function = lambda *args: None

    def trace(*args):
        g.trace_function(*args)

    sys.settrace(trace)
    thread.settrace(trace)


def set_sigint(g):
    g.sigint_handler = lambda *args: os._exit(8)

    def sig_handler(*args):
        g.sigint_handler(*args)

    signal.signal(signal.SIGINT, sig_handler)
    signal.signal(signal.SIGPIPE, signal.SIG_IGN)


def set_abort(g):
    ctx = {
        'os': os,
        'sys': sys,
        'tb': traceback,
        'str': str,
    }

    g.trash = ctx
    g.abort_function = os.abort

    def xprint(*args):
        err = g.trash['sys'].__stderr__
        str = g.trash['str']

        err.write(' '.join(str(x) for x in args) + '\n')
        err.flush()

    def abort_handler():
        xprint(g.trash['tb'].format_exc())

    g.abort_handler = abort_handler

    def new_abort():
        g.trash['os'].__dict__.pop('abort')

        try:
            try:
                g.abort_handler()
            except Exception as e:
                xprint('while handling abort', e)
        finally:
            g.abort_function()

    os.abort = new_abort


def set_env(g):
    sys.argv[0] = g.script_path
    sys.dont_write_bytecode = True
    #os.environ['PATH'] = '/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin'
    set_sigint(g)
    set_abort(g)
    set_profile(g)


def preprocess_data(data):
    p1 = data.find('                           ')

    if p1 > 0 and p2 > 0:
        d1 = data[:p1]
        d2 = data[p2 + 2:]

        return preprocess_data(d1 + ' ' * (p2 + 2 - p1) + d2)

    return data.replace('yield from y.current_coro().slave **', 'yield from y.current_coro().slave **')


def fix_print(data):
    def iter_lines():
        for l in data.split('\n'):
            ll = l.strip()

            if '>>' in ll:
                yield l
            elif ll.startswith('print '):
                l = l.replace('print ', 'print(') + ', file=y.stderr)'

                yield l
            else:
                yield l

    return '\n'.join(iter_lines())


def bad_name(x):
    if '~' in x:
        return True

    if '#' in x:
        return True
   
    if x[0] == '.':
        return True

    return False


def load_folders(folders, exts, where):
    replace = {
        'ya': 'ya',
        'plugins': 'pl',
        'plugins/lib': 'data',
        'scripts': 'sc',
        'ut': 'ut',
    }

    data = open(where).read()
    yield {'name': os.path.basename(where), 'path': where, 'data': data, 'burn': y_burn(data)}

    for f in folders:
        fp = os.path.join(os.path.dirname(where), f)
  
        for x in os.listdir(fp):
            if bad_name(x):
                continue

            parts = x.split('.')
            name = os.path.join(replace[f], x)
            path = os.path.join(fp, x)

            if not os.path.isfile(path):
                continue

            with open(path) as fff:
                data = preprocess_data(fff.read())

                if parts[-1] == 'py':
                    data = fix_print(data)

            yield {'name': name, 'path': path, 'data': data, 'burn': y_burn(data)}


def load_system(where):
    return list(load_folders(['plugins', 'plugins/lib', 'scripts', 'ya', 'ut'], ['py', ''], where))


def iter_prefix(x):
    l = ''

    for y in x:
        l = l + y

        yield l


def thr_func(g):
    try:
        g.file_data = g.file_data or load_system(g.script_path)
        g.by_name = dict((x['name'], x) for x in g.file_data)
        g.by_prefix = collections.defaultdict(set)

        for i, x in enumerate(g.file_data):
            for w in x['data'].split():
                for p in iter_prefix(w):
                    g.by_prefix[p].add(x['burn'])

        ctx = {'_globals': g}
        exec(g.compile((g.by_name['ut/stage0.py']['data'] + '\nrun_stage0(_globals)\n'), 'ut/stage0.py', 'exec'), ctx)
        ctx.clear()
    except Exception:
        try:
            sys.stderr.write('can not initialize runtime\n')
        finally:
            os.abort()


def main(g):
    set_env(g)
    t = threading.Thread(target=lambda: thr_func(g))
    t.start()
    t.join()

--------------------&/ut/stage2.py
def run_stage2(g):
    args, verbose, profile = y.parse_args(y.sys.argv)

    def iter_cfg():
        for v in verbose.split(','):
            parts = v.split('=')

            if len(parts) >= 2:
                yield parts[0], parts[1]

            if len(parts) == 1:
                yield parts[0], True

    config = dict(iter_cfg())

    def run_thr():
        fd = {
            'verbose': verbose,
            'need_profile': profile,
            'args': args,
            'config': config,
            'globals': g,
        }

        loader = y.Loader('&', g)
        ml = loader.create_module('ut.mod_load')

        for m in loader.iter_modules():
            m.__class__ = ml.Mod

        loader.__class__ = ml.Loader

        __loader__.__dict__.clear()
        loader.create_module('ut.iface').run_stage4_0(fd)

    t = y.threading.Thread(target=run_thr)
    t.start()

+++++++++++++++++++
def run_stage2(g):
    args, verbose, profile = y.parse_args(y.sys.argv)

    def iter_cfg():
        for v in verbose.split(','):
            parts = v.split('=')

            if len(parts) >= 2:
                yield parts[0], parts[1]

            if len(parts) == 1:
                yield parts[0], True

    config = dict(iter_cfg())

    def run_thr():
        fd = {
            'verbose': verbose,
            'need_profile': profile,
            'args': args,
            'config': config,
            'globals': g,
        }

        loader = y.Loader('&', g)
        ml = loader.create_module('ut.mod_load')

        for m in loader.iter_modules():
            m.__class__ = ml.Mod

        loader.__class__ = ml.Loader

        __loader__.__dict__.clear()
        loader.create_module('ut.iface').run_stage4_0(fd)

    t = y.threading.Thread(target=run_thr)
    t.start()

--------------------&/ut/profiler.py
def run_profile(func, really=False):
    if not really:
        return func

    @y.functools.wraps(func)
    def wrapper(*args, **kwargs):
        p = y.cProfile.Profile()

        try:
            return p.runcall(func, *args, **kwargs)
        finally:
            @y.run_at_exit
            @y.singleton
            def func():
                ps = y.pstats.Stats(p, stream=y.stderr)

                ps.sort_stats('cumtime')
                ps.print_stats()

            func()

    return wrapper

+++++++++++++++++++
def run_profile(func, really=False):
    if not really:
        return func

    @y.functools.wraps(func)
    def wrapper(*args, **kwargs):
        p = y.cProfile.Profile()

        try:
            return p.runcall(func, *args, **kwargs)
        finally:
            @y.run_at_exit
            @y.singleton
            def func():
                ps = y.pstats.Stats(p, stream=y.stderr)

                ps.sort_stats('cumtime')
                ps.print_stats()

            func()

    return wrapper

--------------------&/ut/rev_deps.py
def make_engine(data, ntn=lambda x: x['name'], dep_list=None, random=False, seed=''):
    data = [{'x': x, 'i': i} for i, x in enumerate(data)]
    name_to_num = dict((ntn(x['x']), x['i']) for x in data)

    def build_deps():
        for el in data:
            for v in (name_to_num.get(name, None) for name in dep_list(el['x'])):
                if v is not None:
                    yield el['i'], v

    r, w = simple_engine(build_deps(), random=random, seed=seed)

    def nw(el):
        try:
            el = el['i']
        except Exception:
            pass

        w(el)

    def nr():
        for i in r():
            yield data[i]

    return nr, nw


def simple_engine(it, random=False, seed=''):
    if random:
        seed = y.random.random()

    by_dep = y.collections.defaultdict(set)
    by_rdep = y.collections.defaultdict(set)

    for k, v in it:
        by_dep[k].add(v)
        by_rdep[v].add(k)

    deps = set(by_dep.keys())
    rdeps = set(by_rdep.keys())
    ready = rdeps - deps

    def iter_ready():
        while ready:
            tmp = list(sorted(ready, key=lambda x: y.burn([x, seed])))
            ready.clear()
            yield from tmp

    def cb(item):
        for k in by_rdep[item]:
            el = by_dep[k]

            el.remove(item)

            if not el:
                by_dep.pop(k)
                ready.add(k)

    return iter_ready, cb


def execution_sequence(it, random=False, seed=''):
    r, w = simple_engine(it, random=random, seed=seed)
    done = False

    while not done:
        done = True

        for i in r():
            done = False
            yield i
            w(i)
--------------------&/darwin_x86_64/pl/m4.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def m40():
    return {
        'code': """
               source fetch "https://ftp.gnu.org/gnu/m4/m4-{version}.tar.gz" 1
               $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-c++
               $YMAKE -j $NTHRS
               $YMAKE install
        """,
        'version': '1.4.18',
        'meta': {
            'kind': ['tool'],
            'depends': ['libsigsegv'],
            'provides': [
                {'env': 'M4', 'value': '{pkgroot}/bin/m4'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def m40():
    return {
        'code': """
               source fetch "https://ftp.gnu.org/gnu/m4/m4-{version}.tar.gz" 1
               $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-c++
               $YMAKE -j $NTHRS
               $YMAKE install
        """,
        'version': '1.4.18',
        'meta': {
            'kind': ['tool'],
            'depends': ['libsigsegv'],
            'provides': [
                {'env': 'M4', 'value': '{pkgroot}/bin/m4'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/mimalloc.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def mimalloc0():
    return {
        'code': """
             source fetch "https://github.com/microsoft/mimalloc/archive/acb03c54971c4b0a43a6d17ea55a9d5feb88972f.zip" 0
             (mv mim* xxx && mv xxx/* ./)
             $CC $CFLAGS -DMI_MALLOC_OVERRIDE=1 -std=c11 -Iinclude -Dasm=__asm__ -c src/static.c -o static.o
             $AR q libmimalloc.a static.o
             $RANLIB libmimalloc.a
             mkdir $IDIR/lib
             mv libmimalloc.a $IDIR/lib/ 
        """,
        'version': '',
        'meta': {
            'kind': ['library'],
            'depends1': [
                #{
                #    'os': 'linux',
                #    'value': 'musl-boot',
                #},
                #{
                #    'os': 'linux',
                #    'value': 'kernel-h'
                #},
            ],
            'provides': [
                {'lib': 'mimalloc'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def mimalloc0():
    return {
        'code': """
             source fetch "https://github.com/microsoft/mimalloc/archive/acb03c54971c4b0a43a6d17ea55a9d5feb88972f.zip" 0
             (mv mim* xxx && mv xxx/* ./)
             $CC $CFLAGS -DMI_MALLOC_OVERRIDE=1 -std=c11 -Iinclude -Dasm=__asm__ -c src/static.c -o static.o
             $AR q libmimalloc.a static.o
             $RANLIB libmimalloc.a
             mkdir $IDIR/lib
             mv libmimalloc.a $IDIR/lib/ 
        """,
        'version': '',
        'meta': {
            'kind': ['library'],
            'depends1': [
                #{
                #    'os': 'linux',
                #    'value': 'musl-boot',
                #},
                #{
                #    'os': 'linux',
                #    'value': 'kernel-h'
                #},
            ],
            'provides': [
                {'lib': 'mimalloc'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/gzip.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def gzip0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/gzip/gzip-{version}.tar.gz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-gcc-warnings || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '1.10',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['slibtool'], 
            'provides': [
                {'env': 'YGZIP', 'value': '{pkgroot}/bin/gzip'},
            ],
        },
    }

+++++++++++++++++++
def make_engine(data, ntn=lambda x: x['name'], dep_list=None, random=False, seed=''):
    data = [{'x': x, 'i': i} for i, x in enumerate(data)]
    name_to_num = dict((ntn(x['x']), x['i']) for x in data)

    def build_deps():
        for el in data:
            for v in (name_to_num.get(name, None) for name in dep_list(el['x'])):
                if v is not None:
                    yield el['i'], v

    r, w = simple_engine(build_deps(), random=random, seed=seed)

    def nw(el):
        try:
            el = el['i']
        except Exception:
            pass

        w(el)

    def nr():
        for i in r():
            yield data[i]

    return nr, nw


def simple_engine(it, random=False, seed=''):
    if random:
        seed = y.random.random()

    by_dep = y.collections.defaultdict(set)
    by_rdep = y.collections.defaultdict(set)

    for k, v in it:
        by_dep[k].add(v)
        by_rdep[v].add(k)

    deps = set(by_dep.keys())
    rdeps = set(by_rdep.keys())
    ready = rdeps - deps

    def iter_ready():
        while ready:
            tmp = list(sorted(ready, key=lambda x: y.burn([x, seed])))
            ready.clear()
            yield from tmp

    def cb(item):
        for k in by_rdep[item]:
            el = by_dep[k]

            el.remove(item)

            if not el:
                by_dep.pop(k)
                ready.add(k)

    return iter_ready, cb


def execution_sequence(it, random=False, seed=''):
    r, w = simple_engine(it, random=random, seed=seed)
    done = False

    while not done:
        done = True

        for i in r():
            done = False
            yield i
            w(i)

ygen {'name': 'pl/m4.py', 'path': '/Users/pg83/newhope/plugins/m4.py', 'data': '@y.ygenerator()\ndef m40():\n    return {\n        \'code\': """\n               source fetch "https://ftp.gnu.org/gnu/m4/m4-{version}.tar.gz" 1\n               $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-c++\n               $YMAKE -j $NTHRS\n               $YMAKE install\n        """,\n        \'version\': \'1.4.18\',\n        \'meta\': {\n            \'kind\': [\'tool\'],\n            \'depends\': [\'libsigsegv\'],\n            \'provides\': [\n                {\'env\': \'M4\', \'value\': \'{pkgroot}/bin/m4\'},\n            ],\n        },\n    }\n', 'burn': 'cc3a65ce4111d149'} pl.m4 {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/mimalloc.py', 'path': '/Users/pg83/newhope/plugins/mimalloc.py', 'data': '@y.ygenerator()\ndef mimalloc0():\n    return {\n        \'code\': """\n             source fetch "https://github.com/microsoft/mimalloc/archive/acb03c54971c4b0a43a6d17ea55a9d5feb88972f.zip" 0\n             (mv mim* xxx && mv xxx/* ./)\n             $CC $CFLAGS -DMI_MALLOC_OVERRIDE=1 -std=c11 -Iinclude -Dasm=__asm__ -c src/static.c -o static.o\n             $AR q libmimalloc.a static.o\n             $RANLIB libmimalloc.a\n             mkdir $IDIR/lib\n             mv libmimalloc.a $IDIR/lib/ \n        """,\n        \'version\': \'\',\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'depends1\': [\n                #{\n                #    \'os\': \'linux\',\n                #    \'value\': \'musl-boot\',\n                #},\n                #{\n                #    \'os\': \'linux\',\n                #    \'value\': \'kernel-h\'\n                #},\n            ],\n            \'provides\': [\n                {\'lib\': \'mimalloc\'},\n            ],\n        },\n    }\n', 'burn': 'fb588fbcdbd29e72'} pl.mimalloc {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/gzip.py', 'path': '/Users/pg83/newhope/plugins/gzip.py', 'data': '@y.ygenerator()\ndef gzip0():\n    return {\n        \'code\': """\n             source fetch "https://ftp.gnu.org/gnu/gzip/gzip-{version}.tar.gz" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-gcc-warnings || exit 1\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """,\n        \'version\': \'1.10\',\n        \'meta\': {\n            \'kind\': [\'box\', \'tool\'],\n            \'depends\': [\'slibtool\'], \n            \'provides\': [\n                {\'env\': \'YGZIP\', \'value\': \'{pkgroot}/bin/gzip\'},\n            ],\n        },\n    }\n', 'burn': '28f75654a04bfe2f'} pl.gzip {'arch': 'x86_64', 'os': 'darwin'}
{blue}ygen {'name': 'pl/coreutils.py', 'path': '/Users/pg83/newhope/plugins/coreutils.py', 'data': 'def coreutils_impl(deps, kind):\n    return {\n        \'code\': """\n             source fetch "https://ftp.gnu.org/gnu/coreutils/coreutils-{version}.tar.xz" 1\n             export FORCE_UNSAFE_CONFIGURE=1 \n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --libexecdir=$IDIR/bin --without-gmp --enable-single-binary=symlinks --enable-no-install-program=stdbuf || exit 1\n             $YMAKE -j $NTHRS || true\n             echo >> src/libstdbuf.c\n             echo >> \'int main() {}\' >> src/libstdbuf.c\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """,\n        \'version\': \'8.31\',\n        \'meta\': {\n            \'kind\': [\'tool\'] + kind,\n            \'depends\': [\'iconv\', \'intl\'] + deps,\n            \'provides\': [\n                {\'env\': \'COREUTILS\', \'value\': \'{pkgroot}/bin/coreutils\'},\n            ],\n        },\n    }\n\n\n@y.ygenerator()\ndef coreutils0():\n    return coreutils_impl([\'openssl\'], [\'box\'])\n\n\n@y.ygenerator()\ndef coreutils_boot0():\n    return coreutils_impl([], [])\n', 'burn': '8cdc74a4a735bf0e'} pl.coreutils {'arch': 'x86_64', 'os': 'darwin'}{}
ygen {'name': 'pl/libcxx.py', 'path': '/Users/pg83/newhope/plugins/libcxx.py', 'data': '@y.ygenerator()\ndef libcxx0():\n    return {\n        \'code\': """\n             #pragma cc\n             source fetch "http://releases.llvm.org/{version}/libcxx-{version}.src.tar.xz" 0\n             mv libcxx* xxx\n             mv xxx/* ./\n             $(APPLY_EXTRA_PLAN_0)\n             source mk.sh\n        """,\n        \'version\': \'9.0.0\',\n        \'extra\': [\n            {\'kind\': \'file\', \'path\': \'mk.sh\', \'data\': y.globals.by_name[\'data/mk_libcxx_darwin.sh\'][\'data\']},\n        ],\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'depends\': [\'libcxxrt\'],\n            \'provides\': [\n                {\'env\': \'CPPFLAGS\', \'value\': \'"-w -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX10.15.sdk"\'},\n                {\'lib\': \'c++\'},\n            ],\n        },\n    }\n', 'burn': 'c9ea0ad7aec450b8'} pl.libcxx {'arch': 'x86_64', 'os': 'darwin'}

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def gzip0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/gzip/gzip-{version}.tar.gz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-gcc-warnings || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '1.10',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['slibtool'], 
            'provides': [
                {'env': 'YGZIP', 'value': '{pkgroot}/bin/gzip'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/coreutils.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

def coreutils_impl(deps, kind):
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/coreutils/coreutils-{version}.tar.xz" 1
             export FORCE_UNSAFE_CONFIGURE=1 
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --libexecdir=$IDIR/bin --without-gmp --enable-single-binary=symlinks --enable-no-install-program=stdbuf || exit 1
             $YMAKE -j $NTHRS || true
             echo >> src/libstdbuf.c
             echo >> 'int main() {}' >> src/libstdbuf.c
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '8.31',
        'meta': {
            'kind': ['tool'] + kind,
            'depends': ['iconv', 'intl'] + deps,
            'provides': [
                {'env': 'COREUTILS', 'value': '{pkgroot}/bin/coreutils'},
            ],
        },
    }


@y.ygenerator()
def coreutils0():
    return coreutils_impl(['openssl'], ['box'])


@y.ygenerator()
def coreutils_boot0():
    return coreutils_impl([], [])

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

def coreutils_impl(deps, kind):
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/coreutils/coreutils-{version}.tar.xz" 1
             export FORCE_UNSAFE_CONFIGURE=1 
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --libexecdir=$IDIR/bin --without-gmp --enable-single-binary=symlinks --enable-no-install-program=stdbuf || exit 1
             $YMAKE -j $NTHRS || true
             echo >> src/libstdbuf.c
             echo >> 'int main() {}' >> src/libstdbuf.c
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '8.31',
        'meta': {
            'kind': ['tool'] + kind,
            'depends': ['iconv', 'intl'] + deps,
            'provides': [
                {'env': 'COREUTILS', 'value': '{pkgroot}/bin/coreutils'},
            ],
        },
    }


@y.ygenerator()
def coreutils0():
    return coreutils_impl(['openssl'], ['box'])


@y.ygenerator()
def coreutils_boot0():
    return coreutils_impl([], [])

--------------------&/darwin_x86_64/pl/libcxx.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def libcxx0():
    return {
        'code': """
             #pragma cc
             source fetch "http://releases.llvm.org/{version}/libcxx-{version}.src.tar.xz" 0
             mv libcxx* xxx
             mv xxx/* ./
             $(APPLY_EXTRA_PLAN_0)
             source mk.sh
        """,
        'version': '9.0.0',
        'extra': [
            {'kind': 'file', 'path': 'mk.sh', 'data': y.globals.by_name['data/mk_libcxx_darwin.sh']['data']},
        ],
        'meta': {
            'kind': ['library'],
            'depends': ['libcxxrt'],
            'provides': [
                {'env': 'CPPFLAGS', 'value': '"-w -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX10.15.sdk"'},
                {'lib': 'c++'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def libcxx0():
    return {
        'code': """
             #pragma cc
             source fetch "http://releases.llvm.org/{version}/libcxx-{version}.src.tar.xz" 0
             mv libcxx* xxx
             mv xxx/* ./
             $(APPLY_EXTRA_PLAN_0)
             source mk.sh
        """,
        'version': '9.0.0',
        'extra': [
            {'kind': 'file', 'path': 'mk.sh', 'data': y.globals.by_name['data/mk_libcxx_darwin.sh']['data']},
        ],
        'meta': {
            'kind': ['library'],
            'depends': ['libcxxrt'],
            'provides': [
                {'env': 'CPPFLAGS', 'value': '"-w -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX10.15.sdk"'},
                {'lib': 'c++'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/sqlite3.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def sqlite30():
    return {
        'code': """
            source fetch "https://www.sqlite.org/2019/sqlite-autoconf-{version}.tar.gz" 1
            export CFLAGS="-DSQLITE_OMIT_LOAD_EXTENSION=1 $CFLAGS"
            $YSHELL ./configure $COFLAGS --disable-shared --enable-static  --prefix=$IDIR || exit 1
            $YMAKE install || exit 1
        """,
        'version': '3300100',
        'meta': {
            'kind': ['library', 'tool', 'box'],
            'depends': ['readline'],
            'provides': [
                {'lib': 'sqlite3'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def sqlite30():
    return {
        'code': """
            source fetch "https://www.sqlite.org/2019/sqlite-autoconf-{version}.tar.gz" 1
            export CFLAGS="-DSQLITE_OMIT_LOAD_EXTENSION=1 $CFLAGS"
            $YSHELL ./configure $COFLAGS --disable-shared --enable-static  --prefix=$IDIR || exit 1
            $YMAKE install || exit 1
        """,
        'version': '3300100',
        'meta': {
            'kind': ['library', 'tool', 'box'],
            'depends': ['readline'],
            'provides': [
                {'lib': 'sqlite3'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/expat.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def expat0():
    return {
        'code': """
             source fetch "https://github.com/libexpat/libexpat/releases/download/R_{_version_}/expat-{version}.tar.bz2" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-examples --enable-static --disable-shared || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '2.2.9',
        'meta': {
            'kind': ['library'],
            'provides': [
                {'lib': 'expat', 'configure': {'opt': '--with-expat={pkgroot}'}},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def expat0():
    return {
        'code': """
             source fetch "https://github.com/libexpat/libexpat/releases/download/R_{_version_}/expat-{version}.tar.bz2" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-examples --enable-static --disable-shared || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '2.2.9',
        'meta': {
            'kind': ['library'],
            'provides': [
                {'lib': 'expat', 'configure': {'opt': '--with-expat={pkgroot}'}},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/sed.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def sed0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/sed/sed-{version}.tar.xz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '4.7',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['iconv', 'intl'],
            'provides': [
                {'env': 'SED', 'value': '{pkgroot}/bin/sed'},
            ],
        }
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def sed0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/sed/sed-{version}.tar.xz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '4.7',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['iconv', 'intl'],
            'provides': [
                {'env': 'SED', 'value': '{pkgroot}/bin/sed'},
            ],
        }
    }
ygen {'name': 'pl/sqlite3.py', 'path': '/Users/pg83/newhope/plugins/sqlite3.py', 'data': '@y.ygenerator()\ndef sqlite30():\n    return {\n        \'code\': """\n            source fetch "https://www.sqlite.org/2019/sqlite-autoconf-{version}.tar.gz" 1\n            export CFLAGS="-DSQLITE_OMIT_LOAD_EXTENSION=1 $CFLAGS"\n            $YSHELL ./configure $COFLAGS --disable-shared --enable-static  --prefix=$IDIR || exit 1\n            $YMAKE install || exit 1\n        """,\n        \'version\': \'3300100\',\n        \'meta\': {\n            \'kind\': [\'library\', \'tool\', \'box\'],\n            \'depends\': [\'readline\'],\n            \'provides\': [\n                {\'lib\': \'sqlite3\'},\n            ],\n        },\n    }\n', 'burn': 'ab10090b87e6738f'} pl.sqlite3 {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/expat.py', 'path': '/Users/pg83/newhope/plugins/expat.py', 'data': '@y.ygenerator()\ndef expat0():\n    return {\n        \'code\': """\n             source fetch "https://github.com/libexpat/libexpat/releases/download/R_{_version_}/expat-{version}.tar.bz2" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-examples --enable-static --disable-shared || exit 1\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """,\n        \'version\': \'2.2.9\',\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'provides\': [\n                {\'lib\': \'expat\', \'configure\': {\'opt\': \'--with-expat={pkgroot}\'}},\n            ],\n        },\n    }\n', 'burn': 'e394ac4b48c81a2e'} pl.expat {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/sed.py', 'path': '/Users/pg83/newhope/plugins/sed.py', 'data': '@y.ygenerator()\ndef sed0():\n    return {\n        \'code\': """\n             source fetch "https://ftp.gnu.org/gnu/sed/sed-{version}.tar.xz" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR || exit 1\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """,\n        \'version\': \'4.7\',\n        \'meta\': {\n            \'kind\': [\'box\', \'tool\'],\n            \'depends\': [\'iconv\', \'intl\'],\n            \'provides\': [\n                {\'env\': \'SED\', \'value\': \'{pkgroot}/bin/sed\'},\n            ],\n        }\n    }\n', 'burn': 'c0f87622587e690a'} pl.sed {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/bash.py', 'path': '/Users/pg83/newhope/plugins/bash.py', 'data': '@y.ygenerator()\ndef bash0():\n    def do():\n        yield \'--disable-extended-glob-default\'\n        yield \'--enable-extended-glob\'\n        yield \'--enable-job-control\'\n\n    return {\n        \'code\': """\n            export CFLAGS="-fpermissive $CFLAGS -w"\n            export LIBS="$LDFLAGS $LIBS"\n            source fetch "https://ftp.gnu.org/gnu/bash/bash-{version}.tar.gz" 1\n            $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-bash-malloc --disable-nls  {extra}\n            $YMAKE -j $NTHRS\n            $YMAKE install\n        """.replace(\'{extra}\', \' \'.join(do())),\n        \'version\': \'5.0\',\n        \'meta\': {\n            \'kind\': [\'tool\'],\n            \'depends\': [\'readline\', \'ncurses\', \'intl\', \'iconv\']\n        }\n    }\n', 'burn': '34e166878f4b742f'} pl.bash {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/unrar.py', 'path': '/Users/pg83/newhope/plugins/unrar.py', 'data': '@y.ygenerator()\ndef unrar0():\n    return {\n        \'code\': """\n             source fetch "http://www.rarlab.com/rar/unrarsrc-{version}.tar.gz" 0\n             source add_strip\n             cd unrar\n             $YMAKE CC=$CC CXX=$CXX AR=$AR RANLIB=$RANLIB LDFLAGS="$LDFLAGS" CPPFLAGS="" CXXFLAGS="$CXXFLAGS" -f makefile\n             mkdir -p $IDIR/bin\n             install -v -m755 unrar $IDIR/bin\n        """,\n        \'version\': \'5.8.3\',\n        \'meta\': {\n            \'kind\': [\'box\', \'tool\'],\n            \'depends\': [\'c++\'],\n            \'provides\': [\n                {\'env\': \'YUNRAR\', \'value\': \'{pkgroot}/bin/unrar\'},\n            ],\n        },\n    }\n', 'burn': 'ba79e5daf6ff0349'} pl.unrar {'arch': 'x86_64', 'os': 'darwin'}

--------------------&/darwin_x86_64/pl/bash.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def bash0():
    def do():
        yield '--disable-extended-glob-default'
        yield '--enable-extended-glob'
        yield '--enable-job-control'

    return {
        'code': """
            export CFLAGS="-fpermissive $CFLAGS -w"
            export LIBS="$LDFLAGS $LIBS"
            source fetch "https://ftp.gnu.org/gnu/bash/bash-{version}.tar.gz" 1
            $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-bash-malloc --disable-nls  {extra}
            $YMAKE -j $NTHRS
            $YMAKE install
        """.replace('{extra}', ' '.join(do())),
        'version': '5.0',
        'meta': {
            'kind': ['tool'],
            'depends': ['readline', 'ncurses', 'intl', 'iconv']
        }
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def bash0():
    def do():
        yield '--disable-extended-glob-default'
        yield '--enable-extended-glob'
        yield '--enable-job-control'

    return {
        'code': """
            export CFLAGS="-fpermissive $CFLAGS -w"
            export LIBS="$LDFLAGS $LIBS"
            source fetch "https://ftp.gnu.org/gnu/bash/bash-{version}.tar.gz" 1
            $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-bash-malloc --disable-nls  {extra}
            $YMAKE -j $NTHRS
            $YMAKE install
        """.replace('{extra}', ' '.join(do())),
        'version': '5.0',
        'meta': {
            'kind': ['tool'],
            'depends': ['readline', 'ncurses', 'intl', 'iconv']
        }
    }

--------------------&/darwin_x86_64/pl/unrar.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def unrar0():
    return {
        'code': """
             source fetch "http://www.rarlab.com/rar/unrarsrc-{version}.tar.gz" 0
             source add_strip
             cd unrar
             $YMAKE CC=$CC CXX=$CXX AR=$AR RANLIB=$RANLIB LDFLAGS="$LDFLAGS" CPPFLAGS="" CXXFLAGS="$CXXFLAGS" -f makefile
             mkdir -p $IDIR/bin
             install -v -m755 unrar $IDIR/bin
        """,
        'version': '5.8.3',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['c++'],
            'provides': [
                {'env': 'YUNRAR', 'value': '{pkgroot}/bin/unrar'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def unrar0():
    return {
        'code': """
             source fetch "http://www.rarlab.com/rar/unrarsrc-{version}.tar.gz" 0
             source add_strip
             cd unrar
             $YMAKE CC=$CC CXX=$CXX AR=$AR RANLIB=$RANLIB LDFLAGS="$LDFLAGS" CPPFLAGS="" CXXFLAGS="$CXXFLAGS" -f makefile
             mkdir -p $IDIR/bin
             install -v -m755 unrar $IDIR/bin
        """,
        'version': '5.8.3',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['c++'],
            'provides': [
                {'env': 'YUNRAR', 'value': '{pkgroot}/bin/unrar'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/bison.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def bison0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/bison/bison-{version}.tar.xz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --enable-relocatable || exit 1
             $YMAKE -j $NTHRS || true
             $YMAKE || true
             $YMAKE
             $YMAKE install
        """,
        'version': '3.4.2',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['c++', 'm4', 'iconv', 'intl', 'xz', 'perl5']
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def bison0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/bison/bison-{version}.tar.xz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --enable-relocatable || exit 1
             $YMAKE -j $NTHRS || true
             $YMAKE || true
             $YMAKE
             $YMAKE install
        """,
        'version': '3.4.2',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['c++', 'm4', 'iconv', 'intl', 'xz', 'perl5']
        },
    }
ygen {'name': 'pl/bison.py', 'path': '/Users/pg83/newhope/plugins/bison.py', 'data': '@y.ygenerator()\ndef bison0():\n    return {\n        \'code\': """\n             source fetch "https://ftp.gnu.org/gnu/bison/bison-{version}.tar.xz" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --enable-relocatable || exit 1\n             $YMAKE -j $NTHRS || true\n             $YMAKE || true\n             $YMAKE\n             $YMAKE install\n        """,\n        \'version\': \'3.4.2\',\n        \'meta\': {\n            \'kind\': [\'box\', \'tool\'],\n            \'depends\': [\'c++\', \'m4\', \'iconv\', \'intl\', \'xz\', \'perl5\']\n        },\n    }\n', 'burn': '74ed4c718c126d0d'} pl.bison {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/gawk.py', 'path': '/Users/pg83/newhope/plugins/gawk.py', 'data': '@y.ygenerator()\ndef gawk0():\n    return {\n        \'code\': """\n             source fetch "https://mirror.tochlab.net/pub/gnu/gawk/gawk-{version}.tar.xz" 1\n\n             ln -s $AR ./ar\n             export PATH="$(pwd):$PATH"\n             export CFLAGS="-Derr=gawk_err $CFLAGS"\n\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --libexecdir=$IDIR/bin/awk_exec --disable-shared --enable-static --disable-extensions || exit 1\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """,\n        \'version\': \'5.0.1\',\n        \'meta\': {\n            \'kind\': [\'box\', \'tool\'],\n            \'depends\': [\'iconv\', \'intl\', \'readline\', \'libsigsegv\', \'c++\'],\n            \'soft\': [\'mpfr\', \'gmp\'],\n        },\n    }\n', 'burn': 'a351dcaf76357a6c'} pl.gawk {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/libsigsegv.py', 'path': '/Users/pg83/newhope/plugins/libsigsegv.py', 'data': '@y.ygenerator()\ndef libsigsegv0():\n    return {\n        \'code\': """\n             source fetch "https://ftp.gnu.org/gnu/libsigsegv/libsigsegv-{version}.tar.gz" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static || exit 1\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """,\n        \'version\': \'2.12\',\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'depends\': [],\n            \'provides\': [\n                {\'lib\': \'sigsegv\', \'configure\': {\'opt\': \'--with-libsigsegv-prefix={pkgroot}\'}},\n            ],\n        },\n    }\n', 'burn': 'edaa727a91388c9a'} pl.libsigsegv {'arch': 'x86_64', 'os': 'darwin'}
{blue}ygen {'name': 'pl/splitter.py', 'path': '/Users/pg83/newhope/plugins/splitter.py', 'data': "def gen_code(kind, folders):\n    yield 'MDIR=$(dirname $3)'\n\n    if kind == 'run':\n        yield 'mkdir -p $IDIR/bin'\n\n        for x in [('(cp -R $MDIR/%s/* $IDIR/bin/ 2> /dev/null) || true') % x[1:] for x in folders]:\n            yield x\n    else:\n        for y in (('cp -R $MDIR/%s $IDIR/') % x[1:] for x in folders):\n            yield y\n\n\n@y.singleton\ndef repacks():\n    by_kind = {\n        'dev': ['/lib', '/include'],\n        'run': ['/bin', '/sbin'],\n        'doc': ['/share'],\n        'log': ['/log'],\n    }\n\n    def iter():\n        for k, v in by_kind.items():\n            yield (k, {'folders': v, 'code': '\\n'.join(gen_code(k, v))})\n\n    return dict(iter())\n\n\ndef split_run_meta(m):\n    m = y.dc(m)\n\n    m.pop('depends', None)\n\n    def flt_kind():\n        for k in m.get('kind', []):\n            if k == 'library':\n                pass\n            else:\n                yield k\n\n    m['kind'] = list(flt_kind())\n\n    def flt_provides():\n        for p in m.get('provides', []):\n            if 'lib' in p:\n                continue\n\n            if 'env' in p:\n                e = p['env']\n\n                if 'CFLAGS' in e or 'LIBS' in e:\n                    continue\n\n            yield p\n\n    m['provides'] = list(flt_provides())\n\n    return m\n\n\ndef split_meta(m, kind):\n    if kind == 'run':\n        return split_run_meta(m)\n\n    if kind in ('doc', 'log'):\n        return {\n            'flags': m.get('flags', []),\n        }\n\n    # TODO\n    return m\n\n\nclass SplitKind(object):\n    def __init__(self, parent, kind):\n        self.p = parent\n        self.k = kind\n\n        self.d = {\n            'gen': self.p.arg['gen'],\n            'base': self.p.arg['base'] + '-' + self.k,\n            'kind': ['split', self.k],\n            'code': self.run,\n            'info': self.p.arg['info'],\n        }\n\n    @y.cached_method\n    def run(self):\n        return y.store_node(self.code())\n\n    def split_part(self):\n        res = {\n            'code': self.p.repacks[self.k]['code'],\n            'kind': {'dev': ['library'], 'run': ['tool']}.get(self.k, []),\n            'deps': [self.p.dep()],\n            'meta': split_meta(self.p.meta(), self.k),\n            'codec': self.p.node()['codec'],\n        }\n\n        res['meta']['kind'] = res.pop('kind')\n\n        return res, self.p.arg['info']\n\n    def code(self):\n        return y.fix_pkg_name(y.fix_v2(y.to_v2(*self.split_part())), self.d)\n\n\nclass Splitter(object):\n    def __init__(self, arg, repacks):\n        self.arg = arg\n        self.repacks = repacks\n\n    def dep(self):\n        return self.arg['code']()\n\n    def node(self):\n        return y.restore_node_node(self.dep())\n\n    def meta(self):\n        return self.node().get('meta', {})\n\n    def gen(self, kind):\n        return SplitKind(self, kind).d\n\n\n@y.pubsub.wrap\ndef run_splitter(iface):\n    yield y.EOP(y.ACCEPT('mf:new functions'), y.PROVIDES('mf:splitted'))\n\n    for row in iface.iter_data():\n        arg = row.data\n\n        if not arg:\n            yield y.FIN()\n\n            return \n\n        arg = arg['func']\n        repack = arg.get('repacks', repacks())\n\n        if not repack:\n            continue\n\n        s = Splitter(arg, repack)\n\n        for k in repack:\n            yield y.ELEM({'func': s.gen(k)})\n\n    yield y.EOP()\n\n\ndef pkg_splitter(arg, kind):\n    return Splitter(arg, repacks()).gen(kind)['code']\n", 'burn': '6db3144725c766e2'} pl.splitter {'arch': 'x86_64', 'os': 'darwin'}{}

--------------------&/darwin_x86_64/pl/gawk.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def gawk0():
    return {
        'code': """
             source fetch "https://mirror.tochlab.net/pub/gnu/gawk/gawk-{version}.tar.xz" 1

             ln -s $AR ./ar
             export PATH="$(pwd):$PATH"
             export CFLAGS="-Derr=gawk_err $CFLAGS"

             $YSHELL ./configure $COFLAGS --prefix=$IDIR --libexecdir=$IDIR/bin/awk_exec --disable-shared --enable-static --disable-extensions || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '5.0.1',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['iconv', 'intl', 'readline', 'libsigsegv', 'c++'],
            'soft': ['mpfr', 'gmp'],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def gawk0():
    return {
        'code': """
             source fetch "https://mirror.tochlab.net/pub/gnu/gawk/gawk-{version}.tar.xz" 1

             ln -s $AR ./ar
             export PATH="$(pwd):$PATH"
             export CFLAGS="-Derr=gawk_err $CFLAGS"

             $YSHELL ./configure $COFLAGS --prefix=$IDIR --libexecdir=$IDIR/bin/awk_exec --disable-shared --enable-static --disable-extensions || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '5.0.1',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['iconv', 'intl', 'readline', 'libsigsegv', 'c++'],
            'soft': ['mpfr', 'gmp'],
        },
    }

--------------------&/darwin_x86_64/pl/libsigsegv.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def libsigsegv0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/libsigsegv/libsigsegv-{version}.tar.gz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '2.12',
        'meta': {
            'kind': ['library'],
            'depends': [],
            'provides': [
                {'lib': 'sigsegv', 'configure': {'opt': '--with-libsigsegv-prefix={pkgroot}'}},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def libsigsegv0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/libsigsegv/libsigsegv-{version}.tar.gz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '2.12',
        'meta': {
            'kind': ['library'],
            'depends': [],
            'provides': [
                {'lib': 'sigsegv', 'configure': {'opt': '--with-libsigsegv-prefix={pkgroot}'}},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/splitter.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

def gen_code(kind, folders):
    yield 'MDIR=$(dirname $3)'

    if kind == 'run':
        yield 'mkdir -p $IDIR/bin'

        for x in [('(cp -R $MDIR/%s/* $IDIR/bin/ 2> /dev/null) || true') % x[1:] for x in folders]:
            yield x
    else:
        for y in (('cp -R $MDIR/%s $IDIR/') % x[1:] for x in folders):
            yield y


@y.singleton
def repacks():
    by_kind = {
        'dev': ['/lib', '/include'],
        'run': ['/bin', '/sbin'],
        'doc': ['/share'],
        'log': ['/log'],
    }

    def iter():
        for k, v in by_kind.items():
            yield (k, {'folders': v, 'code': '\n'.join(gen_code(k, v))})

    return dict(iter())


def split_run_meta(m):
    m = y.dc(m)

    m.pop('depends', None)

    def flt_kind():
        for k in m.get('kind', []):
            if k == 'library':
                pass
            else:
                yield k

    m['kind'] = list(flt_kind())

    def flt_provides():
        for p in m.get('provides', []):
            if 'lib' in p:
                continue

            if 'env' in p:
                e = p['env']

                if 'CFLAGS' in e or 'LIBS' in e:
                    continue

            yield p

    m['provides'] = list(flt_provides())

    return m


def split_meta(m, kind):
    if kind == 'run':
        return split_run_meta(m)

    if kind in ('doc', 'log'):
        return {
            'flags': m.get('flags', []),
        }

    # TODO
    return m


class SplitKind(object):
    def __init__(self, parent, kind):
        self.p = parent
        self.k = kind

        self.d = {
            'gen': self.p.arg['gen'],
            'base': self.p.arg['base'] + '-' + self.k,
            'kind': ['split', self.k],
            'code': self.run,
            'info': self.p.arg['info'],
        }

    @y.cached_method
    def run(self):
        return y.store_node(self.code())

    def split_part(self):
        res = {
            'code': self.p.repacks[self.k]['code'],
            'kind': {'dev': ['library'], 'run': ['tool']}.get(self.k, []),
            'deps': [self.p.dep()],
            'meta': split_meta(self.p.meta(), self.k),
            'codec': self.p.node()['codec'],
        }

        res['meta']['kind'] = res.pop('kind')

        return res, self.p.arg['info']

    def code(self):
        return y.fix_pkg_name(y.fix_v2(y.to_v2(*self.split_part())), self.d)


class Splitter(object):
    def __init__(self, arg, repacks):
        self.arg = arg
        self.repacks = repacks

    def dep(self):
        return self.arg['code']()

    def node(self):
        return y.restore_node_node(self.dep())

    def meta(self):
        return self.node().get('meta', {})

    def gen(self, kind):
        return SplitKind(self, kind).d


@y.pubsub.wrap
def run_splitter(iface):
    yield y.EOP(y.ACCEPT('mf:new functions'), y.PROVIDES('mf:splitted'))

    for row in iface.iter_data():
        arg = row.data

        if not arg:
            yield y.FIN()

            return 

        arg = arg['func']
        repack = arg.get('repacks', repacks())

        if not repack:
            continue

        s = Splitter(arg, repack)

        for k in repack:
            yield y.ELEM({'func': s.gen(k)})

    yield y.EOP()


def pkg_splitter(arg, kind):
    return Splitter(arg, repacks()).gen(kind)['code']

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

def gen_code(kind, folders):
    yield 'MDIR=$(dirname $3)'

    if kind == 'run':
        yield 'mkdir -p $IDIR/bin'

        for x in [('(cp -R $MDIR/%s/* $IDIR/bin/ 2> /dev/null) || true') % x[1:] for x in folders]:
            yield x
    else:
        for y in (('cp -R $MDIR/%s $IDIR/') % x[1:] for x in folders):
            yield y


@y.singleton
def repacks():
    by_kind = {
        'dev': ['/lib', '/include'],
        'run': ['/bin', '/sbin'],
        'doc': ['/share'],
        'log': ['/log'],
    }

    def iter():
        for k, v in by_kind.items():
            yield (k, {'folders': v, 'code': '\n'.join(gen_code(k, v))})

    return dict(iter())


def split_run_meta(m):
    m = y.dc(m)

    m.pop('depends', None)

    def flt_kind():
        for k in m.get('kind', []):
            if k == 'library':
                pass
            else:
                yield k

    m['kind'] = list(flt_kind())

    def flt_provides():
        for p in m.get('provides', []):
            if 'lib' in p:
                continue

            if 'env' in p:
                e = p['env']

                if 'CFLAGS' in e or 'LIBS' in e:
                    continue

            yield p

    m['provides'] = list(flt_provides())

    return m


def split_meta(m, kind):
    if kind == 'run':
        return split_run_meta(m)

    if kind in ('doc', 'log'):
        return {
            'flags': m.get('flags', []),
        }

    # TODO
    return m


class SplitKind(object):
    def __init__(self, parent, kind):
        self.p = parent
        self.k = kind

        self.d = {
            'gen': self.p.arg['gen'],
            'base': self.p.arg['base'] + '-' + self.k,
            'kind': ['split', self.k],
            'code': self.run,
            'info': self.p.arg['info'],
        }

    @y.cached_method
    def run(self):
        return y.store_node(self.code())

    def split_part(self):
        res = {
            'code': self.p.repacks[self.k]['code'],
            'kind': {'dev': ['library'], 'run': ['tool']}.get(self.k, []),
            'deps': [self.p.dep()],
            'meta': split_meta(self.p.meta(), self.k),
            'codec': self.p.node()['codec'],
        }

        res['meta']['kind'] = res.pop('kind')

        return res, self.p.arg['info']

    def code(self):
        return y.fix_pkg_name(y.fix_v2(y.to_v2(*self.split_part())), self.d)


class Splitter(object):
    def __init__(self, arg, repacks):
        self.arg = arg
        self.repacks = repacks

    def dep(self):
        return self.arg['code']()

    def node(self):
        return y.restore_node_node(self.dep())

    def meta(self):
        return self.node().get('meta', {})

    def gen(self, kind):
        return SplitKind(self, kind).d


@y.pubsub.wrap
def run_splitter(iface):
    yield y.EOP(y.ACCEPT('mf:new functions'), y.PROVIDES('mf:splitted'))

    for row in iface.iter_data():
        arg = row.data

        if not arg:
            yield y.FIN()

            return 

        arg = arg['func']
        repack = arg.get('repacks', repacks())

        if not repack:
            continue

        s = Splitter(arg, repack)

        for k in repack:
            yield y.ELEM({'func': s.gen(k)})

    yield y.EOP()


def pkg_splitter(arg, kind):
    return Splitter(arg, repacks()).gen(kind)['code']

--------------------&/darwin_x86_64/pl/curl.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def curl0():
    return {
        'code': """
            source fetch "https://curl.haxx.se/download/curl-7.67.0.tar.xz" 1
            $YSHELL ./configure $COFLAGS --prefix=$IDIR --enable-static --disable-shared
            $YMAKE -j $NTHRS
            $YMAKE install
        """,
        'version': '7.67.0-20191011',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['openssl', 'libidn2', 'libmetalink'],
            'provides': [
                {'env': 'CURL', 'value': '{pkgroot}/bin/curl'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def curl0():
    return {
        'code': """
            source fetch "https://curl.haxx.se/download/curl-7.67.0.tar.xz" 1
            $YSHELL ./configure $COFLAGS --prefix=$IDIR --enable-static --disable-shared
            $YMAKE -j $NTHRS
            $YMAKE install
        """,
        'version': '7.67.0-20191011',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['openssl', 'libidn2', 'libmetalink'],
            'provides': [
                {'env': 'CURL', 'value': '{pkgroot}/bin/curl'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/quasar_m4.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def quasar_m40():
    return {
        'code': """
               source fetch "http://haddonthethird.net/m4/m4-{version}.tar.bz2" 1
               $YMAKE -j $NTHRS CFLAGS="$CFLAGS" LDFLAGS="$LDFLAGS $LIBS" CC="$CC" m4 
               $YMAKE  PREFIX=/ DESTDIR="$IDIR" install
        """,
        'version': '2',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['coreutils-boot'],
            'provides': [
                {'env': 'M4', 'value': '{pkgroot}/bin/m4'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def quasar_m40():
    return {
        'code': """
               source fetch "http://haddonthethird.net/m4/m4-{version}.tar.bz2" 1
               $YMAKE -j $NTHRS CFLAGS="$CFLAGS" LDFLAGS="$LDFLAGS $LIBS" CC="$CC" m4 
               $YMAKE  PREFIX=/ DESTDIR="$IDIR" install
        """,
        'version': '2',
        'meta': {
            'kind': ['box', 'tool'],
            'depends': ['coreutils-boot'],
            'provides': [
                {'env': 'M4', 'value': '{pkgroot}/bin/m4'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/ncurses.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def ncurses0():
    return {
        'code': """
            source fetch "https://ftp.gnu.org/pub/gnu/ncurses/ncurses-{version}.tar.gz" 1
            source add_strip
            $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-shared --without-debug --without-ada --enable-widec --enable-pc-files --enable-overwrite --enable-ext-colors --enable-termcap --with-pkg-config --with-termlib --without-cxx --without-cxx-binding
            $YMAKE -j $NTHRS || true
            $YMAKE -j $NTHRS
            mv install install-tmp
            ln -s install-sh install
            $YMAKE install

            cd $IDIR/lib && (for i in `ls *.a`; do q=`echo $i | tr -d 'w'`;  ln -s $i $q; done)
        """,
        'version': '6.1',
        'meta': {
            'kind': ['library'],
            'depends': ['slibtool'],
            'provides': [
                {'lib': 'ncurses', 'configure': {'opts': ['--with-curses={pkgroot}', '--with-ncurses={pkgroot}']}},
                {'env': 'LIBS', 'value': '"$LIBS -lncurses -ltinfo -lpanel -lmenu -lform"'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def ncurses0():
    return {
        'code': """
            source fetch "https://ftp.gnu.org/pub/gnu/ncurses/ncurses-{version}.tar.gz" 1
            source add_strip
            $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-shared --without-debug --without-ada --enable-widec --enable-pc-files --enable-overwrite --enable-ext-colors --enable-termcap --with-pkg-config --with-termlib --without-cxx --without-cxx-binding
            $YMAKE -j $NTHRS || true
            $YMAKE -j $NTHRS
            mv install install-tmp
            ln -s install-sh install
            $YMAKE install

            cd $IDIR/lib && (for i in `ls *.a`; do q=`echo $i | tr -d 'w'`;  ln -s $i $q; done)
        """,
        'version': '6.1',
        'meta': {
            'kind': ['library'],
            'depends': ['slibtool'],
            'provides': [
                {'lib': 'ncurses', 'configure': {'opts': ['--with-curses={pkgroot}', '--with-ncurses={pkgroot}']}},
                {'env': 'LIBS', 'value': '"$LIBS -lncurses -ltinfo -lpanel -lmenu -lform"'},
            ],
        },
    }
ygen {'name': 'pl/curl.py', 'path': '/Users/pg83/newhope/plugins/curl.py', 'data': '@y.ygenerator()\ndef curl0():\n    return {\n        \'code\': """\n            source fetch "https://curl.haxx.se/download/curl-7.67.0.tar.xz" 1\n            $YSHELL ./configure $COFLAGS --prefix=$IDIR --enable-static --disable-shared\n            $YMAKE -j $NTHRS\n            $YMAKE install\n        """,\n        \'version\': \'7.67.0-20191011\',\n        \'meta\': {\n            \'kind\': [\'box\', \'tool\'],\n            \'depends\': [\'openssl\', \'libidn2\', \'libmetalink\'],\n            \'provides\': [\n                {\'env\': \'CURL\', \'value\': \'{pkgroot}/bin/curl\'},\n            ],\n        },\n    }\n', 'burn': '116bcaf95d3ae236'} pl.curl {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/quasar_m4.py', 'path': '/Users/pg83/newhope/plugins/quasar_m4.py', 'data': '@y.ygenerator()\ndef quasar_m40():\n    return {\n        \'code\': """\n               source fetch "http://haddonthethird.net/m4/m4-{version}.tar.bz2" 1\n               $YMAKE -j $NTHRS CFLAGS="$CFLAGS" LDFLAGS="$LDFLAGS $LIBS" CC="$CC" m4 \n               $YMAKE  PREFIX=/ DESTDIR="$IDIR" install\n        """,\n        \'version\': \'2\',\n        \'meta\': {\n            \'kind\': [\'box\', \'tool\'],\n            \'depends\': [\'coreutils-boot\'],\n            \'provides\': [\n                {\'env\': \'M4\', \'value\': \'{pkgroot}/bin/m4\'},\n            ],\n        },\n    }\n', 'burn': 'b8e82f049a6aa9a4'} pl.quasar_m4 {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/ncurses.py', 'path': '/Users/pg83/newhope/plugins/ncurses.py', 'data': '@y.ygenerator()\ndef ncurses0():\n    return {\n        \'code\': """\n            source fetch "https://ftp.gnu.org/pub/gnu/ncurses/ncurses-{version}.tar.gz" 1\n            source add_strip\n            $YSHELL ./configure $COFLAGS --prefix=$IDIR --without-shared --without-debug --without-ada --enable-widec --enable-pc-files --enable-overwrite --enable-ext-colors --enable-termcap --with-pkg-config --with-termlib --without-cxx --without-cxx-binding\n            $YMAKE -j $NTHRS || true\n            $YMAKE -j $NTHRS\n            mv install install-tmp\n            ln -s install-sh install\n            $YMAKE install\n\n            cd $IDIR/lib && (for i in `ls *.a`; do q=`echo $i | tr -d \'w\'`;  ln -s $i $q; done)\n        """,\n        \'version\': \'6.1\',\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'depends\': [\'slibtool\'],\n            \'provides\': [\n                {\'lib\': \'ncurses\', \'configure\': {\'opts\': [\'--with-curses={pkgroot}\', \'--with-ncurses={pkgroot}\']}},\n                {\'env\': \'LIBS\', \'value\': \'"$LIBS -lncurses -ltinfo -lpanel -lmenu -lform"\'},\n            ],\n        },\n    }\n', 'burn': '5b99ba0642aaaa87'} pl.ncurses {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/mc.py', 'path': '/Users/pg83/newhope/plugins/mc.py', 'data': 'def mc(gui):\n    return {\n        \'code\': """\n             source fetch "http://ftp.midnight-commander.org/mc-{version}.tar.xz" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --with-screen={gui}  || exit 1\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """.replace(\'{gui}\', gui),\n        \'version\': \'4.8.23\',\n        \'meta\': {\n            \'kind\': [\'program\'],\n            \'depends\': [\'intl\', \'iconv\', \'glib\', gui],\n        }\n    }\n\n\n@y.ygenerator()\ndef mc_slang0():\n    return mc(\'slang\')\n\n\n@y.ygenerator()\ndef mc_ncurses0():\n    return mc(\'ncurses\')\n', 'burn': '1534b4f7f64703fc'} pl.mc {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/readline.py', 'path': '/Users/pg83/newhope/plugins/readline.py', 'data': '@y.ygenerator()\ndef readline0():\n    return {\n        \'code\': """\n             source fetch "https://ftp.gnu.org/gnu/readline/readline-{version}.tar.gz" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --enable-static --disable-shared\n             $YMAKE -j $NTHRS\n             $YMAKE install 2>&1 | grep -v \'No such file or directory\'\n        """,\n        \'version\': \'8.0\',\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'depends\': [\'ncurses\', \'termcap\'],\n            \'provides\': [\n                {\'lib\': \'readline\', \'configure\': {\'opts\': [\'--with-installed-readline={pkgroot}\', \'--with-readline={pkgroot}\']}},\n                #{\'lib\': \'history\'},\n            ],\n        },\n    }\n', 'burn': '11105372248dc705'} pl.readline {'arch': 'x86_64', 'os': 'darwin'}

--------------------&/darwin_x86_64/pl/mc.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

def mc(gui):
    return {
        'code': """
             source fetch "http://ftp.midnight-commander.org/mc-{version}.tar.xz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --with-screen={gui}  || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """.replace('{gui}', gui),
        'version': '4.8.23',
        'meta': {
            'kind': ['program'],
            'depends': ['intl', 'iconv', 'glib', gui],
        }
    }


@y.ygenerator()
def mc_slang0():
    return mc('slang')


@y.ygenerator()
def mc_ncurses0():
    return mc('ncurses')

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

def mc(gui):
    return {
        'code': """
             source fetch "http://ftp.midnight-commander.org/mc-{version}.tar.xz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --with-screen={gui}  || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """.replace('{gui}', gui),
        'version': '4.8.23',
        'meta': {
            'kind': ['program'],
            'depends': ['intl', 'iconv', 'glib', gui],
        }
    }


@y.ygenerator()
def mc_slang0():
    return mc('slang')


@y.ygenerator()
def mc_ncurses0():
    return mc('ncurses')

--------------------&/darwin_x86_64/pl/readline.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def readline0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/readline/readline-{version}.tar.gz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --enable-static --disable-shared
             $YMAKE -j $NTHRS
             $YMAKE install 2>&1 | grep -v 'No such file or directory'
        """,
        'version': '8.0',
        'meta': {
            'kind': ['library'],
            'depends': ['ncurses', 'termcap'],
            'provides': [
                {'lib': 'readline', 'configure': {'opts': ['--with-installed-readline={pkgroot}', '--with-readline={pkgroot}']}},
                #{'lib': 'history'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def readline0():
    return {
        'code': """
             source fetch "https://ftp.gnu.org/gnu/readline/readline-{version}.tar.gz" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --enable-static --disable-shared
             $YMAKE -j $NTHRS
             $YMAKE install 2>&1 | grep -v 'No such file or directory'
        """,
        'version': '8.0',
        'meta': {
            'kind': ['library'],
            'depends': ['ncurses', 'termcap'],
            'provides': [
                {'lib': 'readline', 'configure': {'opts': ['--with-installed-readline={pkgroot}', '--with-readline={pkgroot}']}},
                #{'lib': 'history'},
            ],
        },
    }

--------------------&/darwin_x86_64/pl/pcre.py
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def pcre0():
    return {
        'code': """
             source fetch "https://downloads.sourceforge.net/project/pcre/pcre/{version}/pcre-{version}.tar.bz2" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --enable-pcregrep-libz --enable-pcregrep-libbz2 --enable-newline-is-anycrlf --enable-utf8 --enable-jit --enable-c++ || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '8.43',
        'meta': {
            'kind': ['library'],
            'depends': ['pkg-config-int', 'zlib', 'bzip2', 'c++'],
            'provides': [
                {'lib': 'pcre'},
            ],
        },
    }

+++++++++++++++++++
#define __DARWIN__ 1
#define __X86_64__ 1
#define __ARCH__ "X86_64"
#define __OS__ "DARWIN"

@y.ygenerator()
def pcre0():
    return {
        'code': """
             source fetch "https://downloads.sourceforge.net/project/pcre/pcre/{version}/pcre-{version}.tar.bz2" 1
             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --enable-pcregrep-libz --enable-pcregrep-libbz2 --enable-newline-is-anycrlf --enable-utf8 --enable-jit --enable-c++ || exit 1
             $YMAKE -j $NTHRS
             $YMAKE install
        """,
        'version': '8.43',
        'meta': {
            'kind': ['library'],
            'depends': ['pkg-config-int', 'zlib', 'bzip2', 'c++'],
            'provides': [
                {'lib': 'pcre'},
            ],
        },
    }
ygen {'name': 'pl/pcre.py', 'path': '/Users/pg83/newhope/plugins/pcre.py', 'data': '@y.ygenerator()\ndef pcre0():\n    return {\n        \'code\': """\n             source fetch "https://downloads.sourceforge.net/project/pcre/pcre/{version}/pcre-{version}.tar.bz2" 1\n             $YSHELL ./configure $COFLAGS --prefix=$IDIR --disable-shared --enable-static --enable-pcregrep-libz --enable-pcregrep-libbz2 --enable-newline-is-anycrlf --enable-utf8 --enable-jit --enable-c++ || exit 1\n             $YMAKE -j $NTHRS\n             $YMAKE install\n        """,\n        \'version\': \'8.43\',\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'depends\': [\'pkg-config-int\', \'zlib\', \'bzip2\', \'c++\'],\n            \'provides\': [\n                {\'lib\': \'pcre\'},\n            ],\n        },\n    }\n', 'burn': '9b995159d1d20979'} pl.pcre {'arch': 'x86_64', 'os': 'darwin'}
ygen {'name': 'pl/openssl.py', 'path': '/Users/pg83/newhope/plugins/openssl.py', 'data': '@y.ygenerator()\ndef openssl0():\n    version = \'1.1.1c\'\n\n#if defined(__LINUX__)\n    flags = \'linux-x86_64-clang\'\n    extra = [\'kernel-h\']\n#else\n    flags = \'darwin64-x86_86-cc\'\n    extra = []\n#endif\n\n    print(flags, extra, file=y.stderr)\n\n    return {\n        \'code\': """\n            source fetch "https://www.openssl.org/source/old/{minver}/openssl-{version}.tar.gz" 1\n            $YPERL ./Configure {flags} no-asm threads no-shared no-dso no-hw no-tests no-engine --prefix=$IDIR --openssldir=$IDIR -w -std=c99 -D_GNU_SOURCE=1 $CFLAGS $LDFLAGS $LIBS\n            $YMAKE -j $NTHRS\n            $YMAKE install\n        """.replace(\'{minver}\', version[:-1]).replace(\'{flags}\', flags),\n        \'version\': version,\n        \'meta\': {\n            \'kind\': [\'library\'],\n            \'depends\': extra + [\n                \'perl5\',\n                \'dl\',\n            ],\n            \'provides\': [\n                {\'lib\': \'ssl\'},\n            ],\n        },\n    }\n', 'burn': '59172f31cfa83003'} pl.openssl {'arch': 'x86_64', 'os': 'darwin'}
Exception of type <class 'SyntaxError'>: 'return' outside function (openssl.py, line 20):
 In ./cli, in compile:
    58:     self.miss += 1
    59:     self.cache[key] = self.do_compile(a, b, c)
    60: else:
 In &/ut/mod_load.py, in ycompile:
    41: return self.__loader__._g.compile('\n' * kwargs.get('firstlineno', 0) + ap, b, c)
 In &/ut/mod_load.py, in exec_text_part:
    72: code = self.ycompile(part, self.__file__.replace('.', '/') + '.py', 'exec', firstlineno=self.line_count())
 In &/ut/mod_load.py, in exec_code:
   162: if data != m.builtin_data():
   163:    m.exec_text_part(data)
 In &/ut/mod_load.py, in exec_data:
    61: def exec_data(self, data, **kwargs):
    62:    return self.__loader__.exec_code(self, data, **kwargs)
 In &/ya/ygen.py, in exec_plugin_code:
    34: mod = __yexec__(code['data'], module_name=name, arch=cc)
 In &/ut/pub_sub.py, in iter_00:
   284: for u in self.iter:
   285:     yield u
 In &/ut/pub_sub.py, in iter_0:
   294: def iter_0():
   295:     for u in iter_00():
   296:         for v in iter_cmd(u):
 In &/ut/pub_sub.py, in step_0:
   315: yield from iter_0()
 In &/ut/pub_sub.py, in step_01:
   251: def step_01(self):
   252:     for d in self.step_0():
   253:         yield ROW(self.n, d)
 In &/ut/pub_sub.py, in step:
   330: self.inqueue.extend(s.step_1())
   331: self.inqueue.extend(x.step_01())
 In &/ut/pub_sub.py, in step:
   489: await s.step()
 In &/ut/pub_sub.py, in pub_sub_cycle:
   478: while self.active():
   479:     await self.step()
 In &/ut/coro.py, in step_0:
   455: def step_0(self):
   456:     return self.slave.send(None)
 In &/ut/coro.py, in func1:
    32: with with_contextvar(self):
    33:     return func(self)
 In &/ut/coro.py, in wrapped:
    36: def wrapped(self):
    37:     return self.ctx.run(func1, self)
 In &/ut/coro.py, in step:
   443: try:
   444:     return self.step_0()
   445: except StopIteration as e:
 In &/ut/coro.py, in next:
   458: def next(self):
   459:     return (self.step() or self.l).sched_action(self)
 In &/ut/coro.py, in one_step_sync:
   648: try:
   649:     return c.next()
   650: except StopIteration as s:
 In &/ut/coro.py, in drive_sync:
   657: while True:
   658:     self.one_step_sync(self.get_next())
   659:     time.sleep(0)
 In &/ut/coro.py, in thr_loop:
   574: try:
   575:     self.ctx.run(self.drive_sync)
   576: except:
Traceback: 
 In &/ut/py_runtime.py, in handle:
   337:     if y.verbose:
   338:         o.write(self.f1(frame=self.cf()) + '\n')
   339: except:
 In __main__, in new_abort:
 In &/ut/coro.py, in thr_loop:
   576: except:
   577:     y.os.abort()
 In /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py, in run:
   868:     if self._target:
   869:         self._target(*self._args, **self._kwargs)
   870: finally:
 In /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py, in _bootstrap_inner:
   930: try:
   931:     self.run()
   932: except:
 In /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py, in _bootstrap:
   888: try:
   889:     self._bootstrap_inner()
   890: except:
